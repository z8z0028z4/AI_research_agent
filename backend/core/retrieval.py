"""
æª¢ç´¢æ¨¡çµ„
========

è² è²¬æ–‡æª”æª¢ç´¢å’Œå‘é‡æ•¸æ“šåº«ç®¡ç†
"""

from typing import List, Dict, Any, Optional
from langchain.schema import Document
from langchain.text_splitter import RecursiveCharacterTextSplitter

from backend.utils.logger import get_logger
from backend.utils.exceptions import VectorStoreError

logger = get_logger(__name__)


def load_paper_vectorstore():
    """
    è¼‰å…¥æ–‡ç»å‘é‡æ•¸æ“šåº«
    
    åŠŸèƒ½ï¼š
    1. ç²å–æˆ–å‰µå»ºæ–‡ç»å‘é‡æ•¸æ“šåº«å¯¦ä¾‹
    2. ä½¿ç”¨ç·©å­˜é¿å…é‡è¤‡å‰µå»º
    
    è¿”å›ï¼š
        Chroma: æ–‡ç»å‘é‡æ•¸æ“šåº«å°è±¡
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨ç·©å­˜çš„ Chroma å¯¦ä¾‹
    - æŒä¹…åŒ–å­˜å„²åœ¨paper_vectorç›®éŒ„
    - é›†åˆåç¨±ç‚º"paper"
    """
    try:
        # å»¶é²å°å…¥é¿å…å¾ªç’°ä¾è³´
        from backend.services.embedding_service import get_chroma_instance
        return get_chroma_instance("paper")
    except Exception as e:
        logger.error(f"è¼‰å…¥æ–‡ç»å‘é‡æ•¸æ“šåº«å¤±æ•—: {e}")
        raise VectorStoreError(f"è¼‰å…¥æ–‡ç»å‘é‡æ•¸æ“šåº«å¤±æ•—: {str(e)}")


def load_experiment_vectorstore():
    """
    è¼‰å…¥å¯¦é©—æ•¸æ“šå‘é‡æ•¸æ“šåº«
    
    åŠŸèƒ½ï¼š
    1. ç²å–æˆ–å‰µå»ºå¯¦é©—æ•¸æ“šå‘é‡æ•¸æ“šåº«å¯¦ä¾‹
    2. ä½¿ç”¨ç·©å­˜é¿å…é‡è¤‡å‰µå»º
    
    è¿”å›ï¼š
        Chroma: å¯¦é©—æ•¸æ“šå‘é‡æ•¸æ“šåº«å°è±¡
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨ç·©å­˜çš„ Chroma å¯¦ä¾‹
    - æŒä¹…åŒ–å­˜å„²åœ¨experiment_vectorç›®éŒ„
    - é›†åˆåç¨±ç‚º"experiment"
    """
    try:
        # å»¶é²å°å…¥é¿å…å¾ªç’°ä¾è³´
        from backend.services.embedding_service import get_chroma_instance
        return get_chroma_instance("experiment")
    except Exception as e:
        logger.error(f"è¼‰å…¥å¯¦é©—å‘é‡æ•¸æ“šåº«å¤±æ•—: {e}")
        raise VectorStoreError(f"è¼‰å…¥å¯¦é©—å‘é‡æ•¸æ“šåº«å¤±æ•—: {str(e)}")


def retrieve_chunks_multi_query(
    vectorstore, 
    query_list: List[str], 
    k: int = 10, 
    fetch_k: int = 20, 
    score_threshold: float = 0.35
) -> List[Document]:
    """
    å¤šæŸ¥è©¢æ–‡æª”æª¢ç´¢åŠŸèƒ½
    
    åŠŸèƒ½ï¼š
    1. å°å¤šå€‹æŸ¥è©¢é€²è¡Œä¸¦è¡Œæª¢ç´¢
    2. å»é‡å’Œæ’åºæª¢ç´¢çµæœ
    3. æä¾›è©³ç´°çš„æª¢ç´¢çµ±è¨ˆä¿¡æ¯
    
    åƒæ•¸ï¼š
        vectorstore: å‘é‡æ•¸æ“šåº«å°è±¡
        query_list (List[str]): æŸ¥è©¢åˆ—è¡¨
        k (int): è¿”å›çš„æ–‡æª”æ•¸é‡
        fetch_k (int): åˆå§‹æª¢ç´¢çš„æ–‡æª”æ•¸é‡
        score_threshold (float): ç›¸ä¼¼åº¦é–¾å€¼
    
    è¿”å›ï¼š
        List[Document]: æª¢ç´¢åˆ°çš„æ–‡æª”åˆ—è¡¨
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨MMRï¼ˆæœ€å¤§é‚Šéš›ç›¸é—œæ€§ï¼‰æœç´¢
    - è‡ªå‹•å»é‡é¿å…é‡è¤‡å…§å®¹
    - æä¾›è©³ç´°çš„æª¢ç´¢æ—¥èªŒ
    """
    try:
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": k, "fetch_k": fetch_k, "score_threshold": score_threshold}
        )

        # ä½¿ç”¨å­—å…¸é€²è¡Œå»é‡
        chunk_dict = {}
        logger.info(f"é–‹å§‹å¤šæŸ¥è©¢æª¢ç´¢ï¼ŒæŸ¥è©¢åˆ—è¡¨ï¼š{query_list}")
        
        # å°æ¯å€‹æŸ¥è©¢é€²è¡Œæª¢ç´¢
        for q in query_list:
            docs = retriever.get_relevant_documents(q)
            for doc in docs:
                # ä½¿ç”¨å”¯ä¸€æ¨™è­˜ç¬¦é€²è¡Œå»é‡
                key = doc.metadata.get("exp_id") or doc.metadata.get("source") or doc.page_content[:30]
                chunk_dict[key] = doc
        
        # é™åˆ¶è¿”å›çµæœæ•¸é‡ï¼Œä½¿ç”¨å‚³å…¥çš„ k åƒæ•¸
        result = list(chunk_dict.values())[:k]

        # æª¢ç´¢çµæœé©—è­‰
        if not result:
            logger.warning("æ²’æœ‰æª¢ç´¢åˆ°ä»»ä½•æ–‡æª”ï¼Œå»ºè­°æª¢æŸ¥æª¢ç´¢å™¨æˆ–åµŒå…¥æ ¼å¼")
        else:
            logger.info(f"å¤šæŸ¥è©¢æª¢ç´¢å®Œæˆï¼Œå…±æ‰¾åˆ° {len(result)} å€‹æ–‡æª”")
            # è¨˜éŒ„æª¢ç´¢åˆ°çš„æ–‡æª”é è¦½
            for i, doc in enumerate(result[:5], 1):
                meta = doc.metadata
                filename = meta.get("filename") or meta.get("source", "Unknown")
                page = meta.get("page_number") or meta.get("page", "?")
                preview = doc.page_content[:80].replace("\n", " ")
                logger.debug(f"æ–‡æª” {i}: {filename} (é ç¢¼ï¼š{page}) - {preview}")

        return result
        
    except Exception as e:
        logger.error(f"å¤šæŸ¥è©¢æª¢ç´¢å¤±æ•—: {e}")
        raise VectorStoreError(f"å¤šæŸ¥è©¢æª¢ç´¢å¤±æ•—: {str(e)}")


def retrieve_chunks_single_query(
    vectorstore, 
    query: str, 
    k: int = 10, 
    score_threshold: float = 0.35
) -> List[Document]:
    """
    å–®æŸ¥è©¢æ–‡æª”æª¢ç´¢åŠŸèƒ½
    
    åƒæ•¸ï¼š
        vectorstore: å‘é‡æ•¸æ“šåº«å°è±¡
        query (str): æŸ¥è©¢å­—ç¬¦ä¸²
        k (int): è¿”å›çš„æ–‡æª”æ•¸é‡
        score_threshold (float): ç›¸ä¼¼åº¦é–¾å€¼
    
    è¿”å›ï¼š
        List[Document]: æª¢ç´¢åˆ°çš„æ–‡æª”åˆ—è¡¨
    """
    try:
        retriever = vectorstore.as_retriever(
            search_type="mmr",
            search_kwargs={"k": k, "score_threshold": score_threshold}
        )
        
        result = retriever.get_relevant_documents(query)
        logger.info(f"å–®æŸ¥è©¢æª¢ç´¢å®Œæˆï¼ŒæŸ¥è©¢ï¼š{query}ï¼Œæ‰¾åˆ° {len(result)} å€‹æ–‡æª”")
        
        return result
        
    except Exception as e:
        logger.error(f"å–®æŸ¥è©¢æª¢ç´¢å¤±æ•—: {e}")
        raise VectorStoreError(f"å–®æŸ¥è©¢æª¢ç´¢å¤±æ•—: {str(e)}")


def preview_chunks(chunks: List[Document], title: str, max_preview: int = 5):
    """
    é è¦½æ–‡æª”å¡Šå…§å®¹
    
    åƒæ•¸ï¼š
        chunks: æ–‡æª”å¡Šåˆ—è¡¨
        title: é è¦½æ¨™é¡Œ
        max_preview: æœ€å¤§é è¦½æ•¸é‡
    """
    if not chunks:
        logger.warning(f"ã€{title}ã€‘æ²’æœ‰ä»»ä½•æ®µè½å¯é¡¯ç¤ºã€‚")
        return
    
    logger.info(f"\nğŸ“¦ã€{title}ã€‘å…±æ‰¾åˆ° {len(chunks)} å€‹æ–‡æª”å¡Š")
    
    for i, chunk in enumerate(chunks[:max_preview], 1):
        metadata = chunk.metadata
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        page = metadata.get("page_number") or metadata.get("page", "?")
        preview = chunk.page_content[:100].replace("\n", " ")
        
        logger.info(f"--- Chunk {i} ---")
        logger.info(f"ğŸ“„ Filename: {filename} | Page: {page}")
        logger.info(f"ğŸ“š Preview: {preview}")


def expand_query_with_llm_client(original_query: str, llm_client) -> List[str]:
    """
    ä½¿ç”¨ LLM å®¢æˆ¶ç«¯æ“´å±•æŸ¥è©¢è©
    
    åƒæ•¸ï¼š
        original_query: åŸå§‹æŸ¥è©¢
        llm_client: LLMå®¢æˆ¶ç«¯
        
    è¿”å›ï¼š
        List[str]: æ“´å±•å¾Œçš„æŸ¥è©¢è©åˆ—è¡¨
    """
    try:
        from .prompt_builder import build_expand_query_prompt
        
        prompt = build_expand_query_prompt(original_query)
        response = llm_client.invoke(prompt)
        
        # è§£ææ“´å±•çš„æŸ¥è©¢è©
        expanded_queries = [original_query]  # åŒ…å«åŸå§‹æŸ¥è©¢
        
        if response and hasattr(response, 'content'):
            content = response.content
            # æŒ‰è¡Œåˆ†å‰²ä¸¦æ¸…ç†
            lines = [line.strip() for line in content.split('\n') if line.strip()]
            expanded_queries.extend(lines)
        
        logger.info(f"æŸ¥è©¢æ“´å±•å®Œæˆï¼ŒåŸå§‹æŸ¥è©¢ï¼š{original_query}ï¼Œæ“´å±•ç‚º {len(expanded_queries)} å€‹æŸ¥è©¢")
        return expanded_queries
        
    except Exception as e:
        logger.error(f"æŸ¥è©¢æ“´å±•å¤±æ•—: {e}")
        # å¦‚æœæ“´å±•å¤±æ•—ï¼Œè¿”å›åŸå§‹æŸ¥è©¢
        return [original_query]


def get_vectorstore_stats(vectorstore_type: str = "paper") -> Dict[str, Any]:
    """
    ç²å–å‘é‡æ•¸æ“šåº«çµ±è¨ˆä¿¡æ¯
    
    åƒæ•¸ï¼š
        vectorstore_type: å‘é‡æ•¸æ“šåº«é¡å‹ ("paper" æˆ– "experiment")
        
    è¿”å›ï¼š
        Dict[str, Any]: çµ±è¨ˆä¿¡æ¯
    """
    try:
        # å»¶é²å°å…¥é¿å…å¾ªç’°ä¾è³´
        from backend.services.embedding_service import get_chroma_instance
        vectorstore = get_chroma_instance(vectorstore_type)
        collection = vectorstore._collection
        
        stats = {
            "total_documents": collection.count(),
            "vectorstore_type": vectorstore_type
        }
        
        logger.info(f"å‘é‡æ•¸æ“šåº«çµ±è¨ˆ - {vectorstore_type}: {stats['total_documents']} å€‹æ–‡æª”")
        return stats
        
    except Exception as e:
        logger.error(f"ç²å–å‘é‡æ•¸æ“šåº«çµ±è¨ˆå¤±æ•—: {e}")
        return {
            "total_documents": 0,
            "vectorstore_type": vectorstore_type,
            "error": str(e)
        }

"""
æ–‡å­—äº’å‹•æœå‹™
==========

è² è²¬è™•ç†æ–‡å­—åç™½äº’å‹•åŠŸèƒ½ï¼ŒåŒ…æ‹¬è§£é‡‹å’Œä¿®æ”¹åŠŸèƒ½
"""

import time
import uuid
import traceback
from typing import Dict, Any, List, Optional
from backend.services.knowledge_service import agent_answer
from backend.services.rag_service import generate_structured_revision_proposal
from backend.core.retrieval import load_paper_vectorstore, retrieve_chunks_multi_query
from backend.core.query_expander import expand_query
from backend.services.chemical_service import ChemicalService
from backend.utils.logger import get_logger

logger = get_logger(__name__)


def process_text_interaction(
    highlighted_text: str,
    context_paragraph: str,
    user_input: str,
    interaction_type: str,
    highlighted_area: str = "proposal",  # ğŸ” [NEW] åç™½å€åŸŸ
    proposal: Optional[str] = None,
    old_chunks: Optional[List] = None,
    mode: str = "make proposal"
) -> Dict[str, Any]:
    """
    è™•ç†æ–‡å­—åç™½äº’å‹•
    
    Args:
        highlighted_text: åç™½çš„æ–‡å­—
        context_paragraph: åç™½æ–‡å­—æ‰€åœ¨çš„æ®µè½
        user_input: ç”¨æˆ¶è¼¸å…¥çš„å•é¡Œæˆ–ä¿®æ”¹æ„è¦‹
        interaction_type: äº’å‹•é¡å‹ ("explain" æˆ– "revise")
        proposal: åŸå§‹ææ¡ˆï¼ˆä¿®æ”¹æ™‚éœ€è¦ï¼‰
        old_chunks: åŸå§‹æ–‡æª”å¡Šï¼ˆä¿®æ”¹æ™‚éœ€è¦ï¼‰
        mode: è™•ç†æ¨¡å¼
        
    Returns:
        Dict[str, Any]: åŒ…å«å›ç­”ã€å¼•ç”¨å’Œç›¸é—œæ–‡æª”å¡Šçš„å­—å…¸
    """
    
    # ç”Ÿæˆå”¯ä¸€çš„è«‹æ±‚ ID
    request_id = str(uuid.uuid4())[:8]
    start_time = time.time()
    
    # é©—è­‰è¼¸å…¥åƒæ•¸
    if not highlighted_text or not highlighted_text.strip():
        raise ValueError("åç™½æ–‡å­—ä¸èƒ½ç‚ºç©º")
    
    if not user_input or not user_input.strip():
        raise ValueError("ç”¨æˆ¶è¼¸å…¥ä¸èƒ½ç‚ºç©º")
    
    # ç²å–èª¿ç”¨å †ç–Šä¿¡æ¯
    stack_info = traceback.extract_stack()
    caller_info = stack_info[-2] if len(stack_info) > 1 else stack_info[-1]
    
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] ========== æ–‡å­—äº’å‹•è™•ç†é–‹å§‹ ==========")
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] æ™‚é–“æˆ³: {time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] èª¿ç”¨ä½ç½®: {caller_info.filename}:{caller_info.lineno}")
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] äº’å‹•é¡å‹: {interaction_type}")
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] åç™½å€åŸŸ: {highlighted_area}")  # ğŸ” [NEW]
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] åç™½æ–‡å­—: '{highlighted_text[:100]}...'")
    logger.info(f"ğŸ§  [TEXT-INTERACTION-{request_id}] ç”¨æˆ¶è¼¸å…¥: '{user_input[:100]}...'")
    
    try:
        if interaction_type == "explain":
            return _process_explanation(
                highlighted_text, context_paragraph, user_input, mode, request_id
            )
        elif interaction_type == "revise":
            return _process_revision(
                highlighted_text, context_paragraph, user_input, highlighted_area, proposal, old_chunks, request_id
            )
        else:
            raise ValueError(f"ä¸æ”¯æ´çš„äº’å‹•é¡å‹: {interaction_type}")
            
    except Exception as e:
        logger.error(f"âŒ [TEXT-INTERACTION-{request_id}] è™•ç†å¤±æ•—: {e}")
        raise e


def _process_explanation(
    highlighted_text: str,
    context_paragraph: str,
    user_input: str,
    mode: str,
    request_id: str
) -> Dict[str, Any]:
    """
    è™•ç†è§£é‡‹åŠŸèƒ½
    
    Args:
        highlighted_text: åç™½çš„æ–‡å­—
        context_paragraph: åç™½æ–‡å­—æ‰€åœ¨çš„æ®µè½
        user_input: ç”¨æˆ¶è¼¸å…¥çš„å•é¡Œ
        mode: è™•ç†æ¨¡å¼
        request_id: è«‹æ±‚ID
        
    Returns:
        Dict[str, Any]: è§£é‡‹çµæœ
    """
    logger.info(f"ğŸ” [TEXT-INTERACTION-{request_id}] é–‹å§‹è™•ç†è§£é‡‹åŠŸèƒ½")
    
    # æ§‹å»ºæŸ¥è©¢å•é¡Œ
    query = (
        f"Please explain the following text: {highlighted_text}\n\n"
        f"Context: {context_paragraph}\n\n"
        f"User question: {user_input}"
    )
    # è§£é‡‹åŠŸèƒ½å§‹çµ‚ä½¿ç”¨åš´è¬¹æ–‡ç»æº¯æºæ¨¡å¼
    mode = "åƒ…åš´è¬¹æ–‡ç»æº¯æº"
    
    # èª¿ç”¨ agent_answer å‡½æ•¸
    result = agent_answer(query, mode=mode)
    
    logger.info(f"âœ… [TEXT-INTERACTION-{request_id}] è§£é‡‹åŠŸèƒ½è™•ç†å®Œæˆ")
    
    # è½‰æ› chunks ç‚ºå­—å…¸æ ¼å¼
    chunks = result.get("chunks", [])
    chunks_dict = []
    for chunk in chunks:
        if hasattr(chunk, 'page_content') and hasattr(chunk, 'metadata'):
            chunks_dict.append({
                "page_content": chunk.page_content,
                "metadata": chunk.metadata
            })
        else:
            chunks_dict.append(chunk)
    
    return {
        "answer": result.get("answer", ""),
        "citations": result.get("citations", []),
        "chunks": chunks_dict,
        "interaction_type": "explain",
        "highlighted_text": highlighted_text,
        "user_input": user_input,
        "timestamp": time.time(),
        "request_id": request_id  # æ·»åŠ request_id
    }


def _process_revision(
    highlighted_text: str,
    context_paragraph: str,
    user_input: str,
    highlighted_area: str,  # ğŸ” [NEW] åç™½å€åŸŸ
    proposal: str,
    old_chunks: List,
    request_id: str
) -> Dict[str, Any]:
    """
    è™•ç†ä¿®æ”¹åŠŸèƒ½
    
    Args:
        highlighted_text: åç™½çš„æ–‡å­—
        context_paragraph: åç™½æ–‡å­—æ‰€åœ¨çš„æ®µè½
        user_input: ç”¨æˆ¶è¼¸å…¥çš„ä¿®æ”¹æ„è¦‹
        highlighted_area: åç™½å€åŸŸ ("proposal", "experiment", "chemical")
        proposal: åŸå§‹ææ¡ˆ
        old_chunks: åŸå§‹æ–‡æª”å¡Š
        request_id: è«‹æ±‚ID
        
    Returns:
        Dict[str, Any]: ä¿®æ”¹çµæœ
    """
    logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] é–‹å§‹è™•ç†ä¿®æ”¹åŠŸèƒ½")
    logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] åç™½å€åŸŸ: {highlighted_area}")
    
    # ğŸ” [NEW] æ ¹æ“šåç™½å€åŸŸé¸æ“‡ä¸åŒçš„ workflow
    if highlighted_area == "experiment":
        logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] ä½¿ç”¨å¯¦é©—ç´°ç¯€ä¿®æ”¹ workflow")
        return _process_experiment_revision(
            highlighted_text, context_paragraph, user_input, proposal, old_chunks, request_id
        )
    else:
        # é»˜èªä½¿ç”¨ææ¡ˆä¿®æ”¹ workflowï¼ˆåŒ…æ‹¬ chemical å€åŸŸï¼‰
        logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] ä½¿ç”¨ææ¡ˆä¿®æ”¹ workflow")
        return _process_proposal_revision(
            highlighted_text, context_paragraph, user_input, proposal, old_chunks, request_id
        )


def _process_proposal_revision(
    highlighted_text: str,
    context_paragraph: str,
    user_input: str,
    proposal: str,
    old_chunks: List,
    request_id: str
) -> Dict[str, Any]:
    """
    è™•ç†ææ¡ˆä¿®æ”¹åŠŸèƒ½ï¼ˆåŸæœ‰çš„ generate new idea workflowï¼‰
    
    Args:
        highlighted_text: åç™½çš„æ–‡å­—
        context_paragraph: åç™½æ–‡å­—æ‰€åœ¨çš„æ®µè½
        user_input: ç”¨æˆ¶è¼¸å…¥çš„ä¿®æ”¹æ„è¦‹
        proposal: åŸå§‹ææ¡ˆ
        old_chunks: åŸå§‹æ–‡æª”å¡Š
        request_id: è«‹æ±‚ID
        
    Returns:
        Dict[str, Any]: ä¿®æ”¹çµæœ
    """
    logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] é–‹å§‹è™•ç†ææ¡ˆä¿®æ”¹åŠŸèƒ½")
    
    # ä½¿ç”¨èˆ‡ "generate new idea" ç›¸åŒçš„é‚è¼¯
    paper_vectorstore = load_paper_vectorstore()
    logger.info(f"ğŸ“¦ Paper å‘é‡åº«ï¼š{paper_vectorstore._collection.count()}")
    
    # æ§‹å»ºæŸ¥è©¢å•é¡Œ
    query = (
        f"Please revise the relevant parts of the proposal according to the following feedback: {user_input}\n\n"
        f"Text to be revised: {highlighted_text}\n\n"
        f"Context: {context_paragraph}"
    )
    # èªç¾©æ“´å±•
    query_list = expand_query(query)
    
    # æª¢ç´¢æ–°çš„æ–‡æª”å¡Š
    k_new_chunks = 3  # æ¯å€‹æŸ¥è©¢æª¢ç´¢çš„chunksæ•¸é‡
    new_chunks = retrieve_chunks_multi_query(paper_vectorstore, query_list, k=k_new_chunks)
    
    # ä½¿ç”¨çµæ§‹åŒ–ä¿®è¨‚ææ¡ˆç”Ÿæˆ
    structured_data = generate_structured_revision_proposal(query, new_chunks, old_chunks, proposal)
    
    # è½‰æ›ç‚ºæ–‡æœ¬æ ¼å¼
    from backend.core.format_converter import structured_revision_proposal_to_text
    text_proposal = structured_revision_proposal_to_text(structured_data)
    
    # è½‰æ›æ–°æª¢ç´¢åˆ°çš„chunksç‚ºcitationsæ ¼å¼
    new_citations = []
    for i, doc in enumerate(new_chunks):
        if hasattr(doc, 'metadata'):
            metadata = doc.metadata
            page_content = doc.page_content
        else:
            metadata = doc.get('metadata', {})
            page_content = doc.get('page_content', '')
        
        title = metadata.get("title", "Untitled")
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        page = metadata.get("page_number") or metadata.get("page", "?")
        
        new_citations.append({
            "label": f"[{i+1}]",
            "title": title,
            "source": filename,
            "page": page
        })
    
    # è™•ç†åŒ–å­¸å“ä¿¡æ¯
    chemicals = []
    if structured_data and 'materials_list' in structured_data:
        logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] è™•ç†ææ–™åˆ—è¡¨: {structured_data['materials_list']}")
        
        # æå–åŒ–å­¸å“ä¿¡æ¯
        from backend.services.pubchem_service import extract_and_fetch_chemicals
        chemical_metadata_list, not_found_list = extract_and_fetch_chemicals(structured_data['materials_list'])
        
        # æ·»åŠ  SMILES ç¹ªè£½
        chemical_service = ChemicalService()
        chemicals = []
        for chemical in chemical_metadata_list:
            enhanced_chemical = chemical_service.add_smiles_drawing(chemical)
            chemicals.append(enhanced_chemical)
        
        logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] åŒ–å­¸å“è™•ç†å®Œæˆï¼Œæ•¸é‡: {len(chemicals)}")
    
    # è½‰æ› chunks ç‚ºå­—å…¸æ ¼å¼
    chunks_dict = []
    for doc in new_chunks + old_chunks:
        if hasattr(doc, 'metadata'):
            chunks_dict.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        else:
            chunks_dict.append(doc)
    
    logger.info(f"âœ… [TEXT-INTERACTION-{request_id}] ææ¡ˆä¿®æ”¹åŠŸèƒ½è™•ç†å®Œæˆ")
    
    return {
        "answer": text_proposal,
        "citations": new_citations,
        "chunks": chunks_dict,
        "interaction_type": "revise",
        "highlighted_text": highlighted_text,
        "user_input": user_input,
        "timestamp": time.time(),
        "request_id": request_id,  # æ·»åŠ request_id
        "structured_proposal": structured_data,
        "chemicals": chemicals
    }


def _process_experiment_revision(
    highlighted_text: str,
    context_paragraph: str,
    user_input: str,
    proposal: str,
    old_chunks: List,
    request_id: str
) -> Dict[str, Any]:
    """
    è™•ç†å¯¦é©—ç´°ç¯€ä¿®æ”¹åŠŸèƒ½
    
    Args:
        highlighted_text: åç™½çš„æ–‡å­—
        context_paragraph: åç™½æ–‡å­—æ‰€åœ¨çš„æ®µè½
        user_input: ç”¨æˆ¶è¼¸å…¥çš„ä¿®æ”¹æ„è¦‹
        proposal: åŸå§‹ææ¡ˆ
        old_chunks: åŸå§‹æ–‡æª”å¡Š
        request_id: è«‹æ±‚ID
        
    Returns:
        Dict[str, Any]: ä¿®æ”¹çµæœ
    """
    logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] é–‹å§‹è™•ç†å¯¦é©—ç´°ç¯€ä¿®æ”¹åŠŸèƒ½")
    
    # Construct user revision request in English
    user_prompt = (
        f"Please revise the relevant parts of the experimental details according to the following suggestion: {user_input}\n\n"
        f"Text to be revised: {highlighted_text}\n\n"
        f"Context: {context_paragraph}"
    )

    logger.info(f"ğŸ”§ [TEXT-INTERACTION-{request_id}] User revision request length: {len(user_prompt)}")
    # ç²å–åŸå§‹å¯¦é©—ç´°ç¯€ï¼ˆå¾ proposal ä¸­æå–ï¼‰
    # å˜—è©¦å¾ proposal ä¸­æå–å¯¦é©—æ¦‚è¿°ä½œç‚ºåŸå§‹å¯¦é©—ç´°ç¯€
    original_experimental_detail = ""
    if proposal:
        # ç°¡å–®çš„æå–é‚è¼¯ï¼šå°‹æ‰¾åŒ…å« "Experimental" æˆ– "experimental" çš„éƒ¨åˆ†
        lines = proposal.split('\n')
        experimental_lines = []
        in_experimental_section = False
        
        for line in lines:
            if 'experimental' in line.lower() or 'experiment' in line.lower():
                in_experimental_section = True
                experimental_lines.append(line)
            elif in_experimental_section and line.strip():
                experimental_lines.append(line)
            elif in_experimental_section and not line.strip():
                break
        
        original_experimental_detail = '\n'.join(experimental_lines) if experimental_lines else "No experimental details found in proposal"
    else:
        original_experimental_detail = "No proposal provided"
    
    # ç›´æ¥ä½¿ç”¨å¯¦é©—ç´°ç¯€ä¿®æ”¹åŠŸèƒ½ï¼Œå‚³å…¥ç”¨æˆ¶ä¿®æ”¹è«‹æ±‚
    # ä¸éœ€è¦èªç¾©æ“´å±•å’Œå‘é‡æª¢ç´¢ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹chunks
    from backend.services.rag_service import generate_structured_revision_experimental_detail
    structured_data = generate_structured_revision_experimental_detail(
        user_prompt, [], old_chunks, proposal, original_experimental_detail
    )
    
    # è½‰æ›ç‚ºæ–‡æœ¬æ ¼å¼
    from backend.core.format_converter import structured_revision_experimental_detail_to_text
    text_experiment = structured_revision_experimental_detail_to_text(structured_data)
    
    # è½‰æ›chunksç‚ºcitationsæ ¼å¼
    citations = []
    for i, doc in enumerate(old_chunks):
        if hasattr(doc, 'metadata'):
            metadata = doc.metadata
        else:
            metadata = doc.get('metadata', {})
        
        title = metadata.get("title", "Untitled")
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        page = metadata.get("page_number") or metadata.get("page", "?")
        
        citations.append({
            "label": f"[{i+1}]",
            "title": title,
            "source": filename,
            "page": page
        })
    
    # è½‰æ› chunks ç‚ºå­—å…¸æ ¼å¼
    chunks_dict = []
    for doc in old_chunks:
        if hasattr(doc, 'metadata'):
            chunks_dict.append({
                "content": doc.page_content,
                "metadata": doc.metadata
            })
        else:
            chunks_dict.append(doc)
    
    logger.info(f"âœ… [TEXT-INTERACTION-{request_id}] å¯¦é©—ç´°ç¯€ä¿®æ”¹åŠŸèƒ½è™•ç†å®Œæˆ")
    
    return {
        "answer": text_experiment,
        "citations": citations,
        "chunks": chunks_dict,
        "interaction_type": "revise",
        "highlighted_text": highlighted_text,
        "user_input": user_input,
        "timestamp": time.time(),
        "request_id": request_id,  # æ·»åŠ request_id
        "structured_experiment": structured_data,  # æ³¨æ„ï¼šé€™è£¡è¿”å› structured_experiment
        "chemicals": []  # å¯¦é©—ç´°ç¯€ä¿®æ”¹ä¸æ¶‰åŠåŒ–å­¸å“
    }





def extract_context_paragraph(text: str, highlighted_text: str, context_size: int = 200) -> str:
    """
    æå–åç™½æ–‡å­—é™„è¿‘çš„ä¸Šä¸‹æ–‡æ®µè½
    
    Args:
        text: å®Œæ•´æ–‡æœ¬
        highlighted_text: åç™½çš„æ–‡å­—
        context_size: ä¸Šä¸‹æ–‡å¤§å°ï¼ˆå­—ç¬¦æ•¸ï¼‰
        
    Returns:
        str: ä¸Šä¸‹æ–‡æ®µè½
    """
    try:
        # æ‰¾åˆ°åç™½æ–‡å­—åœ¨å®Œæ•´æ–‡æœ¬ä¸­çš„ä½ç½®
        start_pos = text.find(highlighted_text)
        if start_pos == -1:
            return text[:context_size]  # å¦‚æœæ‰¾ä¸åˆ°ï¼Œè¿”å›é–‹é ­éƒ¨åˆ†
        
        # è¨ˆç®—ä¸Šä¸‹æ–‡ç¯„åœ
        context_start = max(0, start_pos - context_size // 2)
        context_end = min(len(text), start_pos + len(highlighted_text) + context_size // 2)
        
        # å˜—è©¦æ‰¾åˆ°æ®µè½é‚Šç•Œ
        if context_start > 0:
            # å‘å‰æ‰¾åˆ°æ®µè½é–‹å§‹
            paragraph_start = text.rfind('\n\n', 0, context_start)
            if paragraph_start != -1:
                context_start = paragraph_start + 2
        
        if context_end < len(text):
            # å‘å¾Œæ‰¾åˆ°æ®µè½çµæŸ
            paragraph_end = text.find('\n\n', context_end)
            if paragraph_end != -1:
                context_end = paragraph_end
        
        # æå–ä¸Šä¸‹æ–‡æ®µè½ï¼ˆä¿®æ­£ï¼šé‡æ–°æå–æ–‡æœ¬ï¼‰
        context = text[context_start:context_end].strip()
        
        # å¦‚æœä¸Šä¸‹æ–‡å¤ªçŸ­ï¼Œæ“´å±•ç¯„åœ
        if len(context) < len(highlighted_text) + 50:
            # æ“´å±•åˆ°åŒ…å«æ›´å¤šä¸Šä¸‹æ–‡
            expanded_start = max(0, context_start - context_size // 4)
            expanded_end = min(len(text), context_end + context_size // 4)
            context = text[expanded_start:expanded_end].strip()
        
        return context
        
    except Exception as e:
        logger.error(f"æå–ä¸Šä¸‹æ–‡æ®µè½å¤±æ•—: {e}")
        return text[:context_size] 
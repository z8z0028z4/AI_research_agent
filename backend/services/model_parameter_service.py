"""
æ¨¡å‹åƒæ•¸æª¢æ¸¬å’Œé©é…å™¨
ç”¨æ–¼å‹•æ…‹æª¢æ¸¬ä¸åŒOpenAIæ¨¡å‹çš„æ”¯æ´åƒæ•¸ä¸¦é€²è¡Œé©é…
åŸºæ–¼GPT-5å®˜æ–¹cookbookçš„æœ€æ–°åƒæ•¸æ”¯æ´
"""

import json
import logging
from typing import Dict, Any, List, Optional
from openai import OpenAI
import time

logger = logging.getLogger(__name__)

class ModelParameterDetector:
    """æ¨¡å‹åƒæ•¸æª¢æ¸¬å™¨"""
    
    def __init__(self, api_key: str = None):
        self.client = OpenAI(api_key=api_key)
        self.cache = {}  # å¿«å–æª¢æ¸¬çµæœ
        
    def detect_model_parameters(self, model_name: str) -> Dict[str, Any]:
        """
        æª¢æ¸¬æŒ‡å®šæ¨¡å‹æ”¯æ´çš„åƒæ•¸
        
        Args:
            model_name: æ¨¡å‹åç¨±
            
        Returns:
            åŒ…å«æ”¯æ´åƒæ•¸è³‡è¨Šçš„å­—å…¸
        """
        # æª¢æŸ¥å¿«å–
        if model_name in self.cache:
            logger.info(f"ä½¿ç”¨å¿«å–çš„æ¨¡å‹åƒæ•¸: {model_name}")
            return self.cache[model_name]
        
        logger.info(f"é–‹å§‹æª¢æ¸¬æ¨¡å‹åƒæ•¸: {model_name}")
        
        # æ ¹æ“šcookbookï¼ŒGPT-5ç³»åˆ—ä½¿ç”¨Responses API
        if model_name.startswith('gpt-5'):
            # GPT-5ç³»åˆ—æ”¯æ´çš„åƒæ•¸ï¼ˆResponses APIï¼‰
            supported_params = {
                'max_tokens': {
                    'type': 'int', 
                    'range': [1, 32000], 
                    'default': 2000,
                    'api_name': 'max_output_tokens',  # ä¿®æ­£ï¼šResponses APIä½¿ç”¨max_output_tokens
                    'description': 'æ§åˆ¶å›æ‡‰çš„æœ€å¤§é•·åº¦'
                },
                'timeout': {
                    'type': 'int', 
                    'range': [10, 600], 
                    'default': 60,
                    'api_name': 'timeout',
                    'description': 'APIèª¿ç”¨è¶…æ™‚æ™‚é–“'
                },
                'reasoning_effort': {
                    'type': 'select', 
                    'options': ['minimal', 'low', 'medium', 'high'], 
                    'default': 'medium',
                    'api_name': 'reasoning.effort',
                    'description': 'æ§åˆ¶æ¨ç†å¯†åº¦å’Œæˆæœ¬'
                },
                'verbosity': {
                    'type': 'select', 
                    'options': ['low', 'medium', 'high'], 
                    'default': 'medium',
                    'api_name': 'text.verbosity',
                    'description': 'æ§åˆ¶å›æ‡‰çš„è©³ç´°ç¨‹åº¦'
                }
            }
            
            # å¦‚æœæ˜¯GPT-5å®Œæ•´ç‰ˆï¼Œé‚„æ”¯æ´temperature
            if model_name == 'gpt-5':
                supported_params['temperature'] = {
                    'type': 'float', 
                    'range': [0.0, 2.0], 
                    'default': 0.7,
                    'api_name': 'temperature',
                    'description': 'æ§åˆ¶å›æ‡‰çš„éš¨æ©Ÿæ€§'
                }
                
        else:
            # ä¸æ”¯æ´çš„æ¨¡å‹ç³»åˆ—
            raise ValueError(f"ä¸æ”¯æ´çš„æ¨¡å‹ï¼š{model_name}ï¼Œåƒ…æ”¯æ´ GPT-5 ç³»åˆ—")
        
        result = {
            'model_name': model_name,
            'supported_parameters': supported_params,
            'api_type': 'responses' if model_name.startswith('gpt-5') else 'chat_completions',
            'detection_time': time.time()
        }
        
        # å¿«å–çµæœ
        self.cache[model_name] = result
        logger.info(f"æ¨¡å‹åƒæ•¸æª¢æ¸¬å®Œæˆ: {model_name}")
        
        return result
    
    def adapt_parameters(self, model_name: str, user_params: Dict[str, Any]) -> Dict[str, Any]:
        """
        é©é…ç”¨æˆ¶åƒæ•¸åˆ°å¯¦éš›APIèª¿ç”¨æ ¼å¼
        
        Args:
            model_name: æ¨¡å‹åç¨±
            user_params: ç”¨æˆ¶æä¾›çš„åƒæ•¸
            
        Returns:
            é©é…å¾Œçš„åƒæ•¸å­—å…¸
        """
        # ç²å–æ¨¡å‹åƒæ•¸è³‡è¨Š
        model_info = self.detect_model_parameters(model_name)
        supported_params = model_info['supported_parameters']
        
        # é©é…åƒæ•¸
        adapted_params = {'model': model_name}
        
        # æ·»åŠ èª¿è©¦æ—¥èªŒ
        logger.info(f"ğŸ” [DEBUG] é–‹å§‹åƒæ•¸é©é…")
        logger.info(f"ğŸ” [DEBUG] æ¨¡å‹åç¨±: {model_name}")
        logger.info(f"ğŸ” [DEBUG] ç”¨æˆ¶åƒæ•¸: {user_params}")
        logger.info(f"ğŸ” [DEBUG] æ”¯æ´åƒæ•¸: {list(supported_params.keys())}")
        
        for param_name, param_value in user_params.items():
            logger.info(f"ğŸ” [DEBUG] è™•ç†åƒæ•¸: {param_name} = {param_value}")
            
            # ç‰¹æ®Šè™•ç†ï¼šå°‡ max_tokens æ˜ å°„åˆ° max_output_tokensï¼ˆGPT-5ç³»åˆ—ï¼‰
            if param_name == 'max_tokens' and model_name.startswith('gpt-5'):
                adapted_params['max_output_tokens'] = param_value
                logger.info(f"ğŸ” [DEBUG] æ˜ å°„ max_tokens -> max_output_tokens: {param_value}")
                continue
                
            if param_name not in supported_params:
                logger.warning(f"è·³éä¸æ”¯æ´çš„åƒæ•¸: {param_name}")
                continue
                
            param_config = supported_params[param_name]
            api_name = param_config['api_name']
            logger.info(f"ğŸ” [DEBUG] åƒæ•¸ {param_name} çš„ API åç¨±: {api_name}")
            
            # æ ¹æ“šAPIåç¨±é€²è¡Œé©é…
            if api_name == 'reasoning.effort':
                # æ­£ç¢ºè™•ç†reasoningåƒæ•¸
                adapted_params['reasoning'] = {'effort': param_value}
                logger.info(f"ğŸ” [DEBUG] è¨­ç½® reasoning.effort: {param_value}")
            elif api_name == 'max_output_tokens':
                adapted_params['max_output_tokens'] = param_value
                logger.info(f"ğŸ” [DEBUG] è¨­ç½® max_output_tokens: {param_value}")
            elif api_name == 'text.verbosity':
                # è™•ç† verbosity åƒæ•¸
                if 'text' not in adapted_params:
                    adapted_params['text'] = {}
                adapted_params['text']['verbosity'] = param_value
                logger.info(f"ğŸ” [DEBUG] è¨­ç½® text.verbosity: {param_value}")
            else:
                adapted_params[api_name] = param_value
                logger.info(f"ğŸ” [DEBUG] è¨­ç½® {api_name}: {param_value}")
                
        logger.info(f"ğŸ” [DEBUG] åƒæ•¸é©é…å®Œæˆ: {adapted_params}")
        return adapted_params
    
    def create_cfg_tool(self, grammar_definition: str, tool_name: str = "custom_grammar") -> Dict[str, Any]:
        """
        å‰µå»ºCFGå·¥å…·ï¼ˆContext-Free Grammarï¼‰
        
        Args:
            grammar_definition: èªæ³•å®šç¾©ï¼ˆLarkæˆ–Regexæ ¼å¼ï¼‰
            tool_name: å·¥å…·åç¨±
            
        Returns:
            CFGå·¥å…·é…ç½®
        """
        return {
            "type": "custom",
            "name": tool_name,
            "description": "Emit ONLY output valid under the specified grammar.",
            "format": {
                "type": "grammar",
                "syntax": "regex",  # æˆ– "lark"
                "definition": grammar_definition
            }
        }
    
    def create_response_format(self, format_type: str = "json_object") -> Dict[str, Any]:
        """
        å‰µå»ºå›æ‡‰æ ¼å¼é…ç½®
        
        Args:
            format_type: æ ¼å¼é¡å‹ï¼ˆjson_object, textç­‰ï¼‰
            
        Returns:
            å›æ‡‰æ ¼å¼é…ç½®
        """
        return {"type": format_type}
    
    def get_model_info_summary(self, model_name: str) -> Dict[str, Any]:
        """
        ç²å–æ¨¡å‹è³‡è¨Šæ‘˜è¦
        """
        model_info = self.detect_model_parameters(model_name)
        
        return {
            'model_name': model_name,
            'supported_parameters': list(model_info['supported_parameters'].keys()),
            'parameter_count': len(model_info['supported_parameters']),
            'api_type': model_info['api_type'],
            'is_gpt5_series': model_name.startswith('gpt-5'),
            'detection_time': model_info['detection_time']
        }
    
    def test_model_call(self, model_name: str, test_params: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        æ¸¬è©¦æ¨¡å‹èª¿ç”¨
        
        Args:
            model_name: æ¨¡å‹åç¨±
            test_params: æ¸¬è©¦åƒæ•¸
            
        Returns:
            æ¸¬è©¦çµæœ
        """
        if test_params is None:
            test_params = {
                'max_tokens': 100,
                'timeout': 30
            }
            
            if model_name.startswith('gpt-5'):
                test_params.update({
                    'reasoning_effort': 'medium',
                    'verbosity': 'low'
                })
        
        try:
            # é©é…åƒæ•¸
            adapted_params = self.adapt_parameters(model_name, test_params)
            
            # æ ¹æ“šAPIé¡å‹é¸æ“‡èª¿ç”¨æ–¹å¼
            if model_name.startswith('gpt-5'):
                # ä½¿ç”¨Responses API
                adapted_params['input'] = [
                    {'role': 'user', 'content': 'Hello, please respond with "Test successful"'}
                ]
                
                response = self.client.responses.create(**adapted_params)
                
                # ä¿®å¾©ï¼šæ ¹æ“šGPT-5 cookbookæ­£ç¢ºè™•ç†Responses APIçš„å›æ‡‰æ ¼å¼
                output = ""
                if hasattr(response, 'output') and response.output:
                    for item in response.output:
                        # è·³éResponseReasoningItemå°è±¡
                        if hasattr(item, 'type') and item.type == 'reasoning':
                            continue
                        
                        if hasattr(item, "content"):
                            for content in item.content:
                                if hasattr(content, "text"):
                                    output += content.text
                        elif hasattr(item, "text"):
                            # ç›´æ¥æ–‡æœ¬è¼¸å‡º
                            output += item.text
                        elif hasattr(item, "message"):
                            # messageå°è±¡
                            if hasattr(item.message, "content"):
                                output += item.message.content
                            else:
                                output += str(item.message)
                        else:
                            # å…¶ä»–æƒ…æ³ï¼Œå˜—è©¦è½‰æ›ç‚ºå­—ç¬¦ä¸²ï¼Œä½†éæ¿¾æ‰ResponseReasoningItem
                            item_str = str(item)
                            if not item_str.startswith('ResponseReasoningItem'):
                                output += item_str
                
                output = output.strip()
                
                result = {
                    'success': True,
                    'response': output,
                    'api_type': 'responses'
                }
            else:
                # ä½¿ç”¨Chat Completions API
                adapted_params['messages'] = [
                    {'role': 'user', 'content': 'Hello, please respond with "Test successful"'}
                ]
                
                response = self.client.chat.completions.create(**adapted_params)
                result = {
                    'success': True,
                    'response': response.choices[0].message.content,
                    'api_type': 'chat_completions'
                }
                
            return result
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'api_type': 'responses' if model_name.startswith('gpt-5') else 'chat_completions'
            }
    
    def clear_cache(self):
        """æ¸…é™¤å¿«å–"""
        self.cache.clear()
        logger.info("æ¨¡å‹åƒæ•¸å¿«å–å·²æ¸…é™¤")
    
    def export_cache(self, filepath: str):
        """åŒ¯å‡ºå¿«å–åˆ°æª”æ¡ˆ"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.cache, f, indent=2, ensure_ascii=False)
        logger.info(f"å¿«å–å·²åŒ¯å‡ºåˆ°: {filepath}")
    
    def import_cache(self, filepath: str):
        """å¾æª”æ¡ˆåŒ¯å…¥å¿«å–"""
        with open(filepath, 'r', encoding='utf-8') as f:
            self.cache = json.load(f)
        logger.info(f"å¿«å–å·²å¾æª”æ¡ˆåŒ¯å…¥: {filepath}")


# å…¨åŸŸæª¢æ¸¬å™¨å¯¦ä¾‹
_detector = None

def get_detector(api_key: str = None) -> ModelParameterDetector:
    """ç²å–å…¨åŸŸæª¢æ¸¬å™¨å¯¦ä¾‹"""
    global _detector
    if _detector is None:
        _detector = ModelParameterDetector(api_key)
    return _detector

def detect_model_parameters(model_name: str, api_key: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•¸ï¼šæª¢æ¸¬æ¨¡å‹åƒæ•¸"""
    detector = get_detector(api_key)
    return detector.detect_model_parameters(model_name)

def adapt_parameters(model_name: str, user_params: Dict[str, Any], api_key: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•¸ï¼šé©é…åƒæ•¸"""
    detector = get_detector(api_key)
    return detector.adapt_parameters(model_name, user_params)

def test_model_call(model_name: str, test_params: Dict[str, Any] = None, api_key: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•¸ï¼šæ¸¬è©¦æ¨¡å‹èª¿ç”¨"""
    detector = get_detector(api_key)
    return detector.test_model_call(model_name, test_params)

def create_cfg_tool(grammar_definition: str, tool_name: str = "custom_grammar", api_key: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•¸ï¼šå‰µå»ºCFGå·¥å…·"""
    detector = get_detector(api_key)
    return detector.create_cfg_tool(grammar_definition, tool_name)

def create_response_format(format_type: str = "json_object", api_key: str = None) -> Dict[str, Any]:
    """ä¾¿æ·å‡½æ•¸ï¼šå‰µå»ºå›æ‡‰æ ¼å¼é…ç½®"""
    detector = get_detector(api_key)
    return detector.create_response_format(format_type) 
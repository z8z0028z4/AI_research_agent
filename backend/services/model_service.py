"""
æ¨¡å‹é…ç½®æ©‹æ¥æ¨¡çµ„
==============

æ©‹æ¥appç›®éŒ„å’Œbackendç›®éŒ„çš„æ¨¡å‹é…ç½®
åŸºæ–¼GPT-5å®˜æ–¹cookbookçš„æœ€æ–°åƒæ•¸æ”¯æ´
"""

import os
import sys
from typing import Dict, Any

# æ·»åŠ backendç›®éŒ„åˆ°Pythonè·¯å¾‘
backend_path = os.path.join(os.path.dirname(__file__), "..", "backend")
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

try:
    # å…¼å®¹æ€§å°å…¥ï¼šæ”¯æŒç›¸å°å°å…¥å’Œçµ•å°å°å…¥
    from backend.core.settings_manager import settings_manager
    # å˜—è©¦å°å…¥åƒæ•¸æª¢æ¸¬å™¨
    try:
        from .model_parameter_service import adapt_parameters, detect_model_parameters
        HAS_PARAMETER_DETECTOR = True
    except ImportError:
        HAS_PARAMETER_DETECTOR = False
        print("è­¦å‘Šï¼šç„¡æ³•å°å…¥ model_parameter_detectorï¼Œå°‡ä½¿ç”¨åŸºç¤é…ç½®")
    
    def get_current_model():
        """ç²å–ç•¶å‰æ¨¡å‹åç¨±"""
        return settings_manager.get_current_model()
    
    def get_model_params(model_name=None):
        """ç²å–æ¨¡å‹åƒæ•¸"""
        if model_name is None:
            model_name = get_current_model()
        
        # å¾è¨­å®šç®¡ç†å™¨ç²å–å‹•æ…‹åƒæ•¸
        llm_params = settings_manager.get_llm_parameters()
        
        # ä½¿ç”¨æ–°çš„åƒæ•¸é©é…å™¨
        if HAS_PARAMETER_DETECTOR:
            try:
                adapted_params = adapt_parameters(model_name, llm_params)
                print(f"ğŸ”§ æ¨¡å‹åƒæ•¸é©é…å®Œæˆ: {adapted_params}")
                return adapted_params
            except Exception as e:
                print(f"âš ï¸ åƒæ•¸é©é…å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤åƒæ•¸: {e}")
        
        # å¦‚æœé©é…å¤±æ•—æˆ–æ²’æœ‰æª¢æ¸¬å™¨ï¼Œä½¿ç”¨åŸºç¤åƒæ•¸
        base_params = {
            "model": model_name,
            "max_tokens": llm_params.get("max_tokens", 2000),
            "timeout": llm_params.get("timeout", 60),
        }
        
        # å°æ–¼GPT-5ç³»åˆ—æ¨¡å‹ï¼Œæ·»åŠ verbosityå’Œreasoning_effortåƒæ•¸
        if model_name.startswith('gpt-5'):
            if "verbosity" in llm_params:
                base_params["verbosity"] = llm_params["verbosity"]
            if "reasoning_effort" in llm_params:
                base_params["reasoning_effort"] = llm_params["reasoning_effort"]
        
        return base_params
    
    def get_model_supported_parameters(model_name: str = None) -> Dict[str, Any]:
        """
        ç²å–æŒ‡å®šæ¨¡å‹æ”¯æ´çš„åƒæ•¸è³‡è¨Š
        
        Args:
            model_name: æ¨¡å‹åç¨±ï¼Œå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰æ¨¡å‹
            
        Returns:
            åŒ…å«æ”¯æ´åƒæ•¸è³‡è¨Šçš„å­—å…¸
        """
        if model_name is None:
            model_name = get_current_model()
        
        if HAS_PARAMETER_DETECTOR:
            try:
                # ä½¿ç”¨æ–°çš„åƒæ•¸æª¢æ¸¬å™¨
                model_info = detect_model_parameters(model_name)
                return model_info['supported_parameters']
            except Exception as e:
                print(f"âš ï¸ ç„¡æ³•æª¢æ¸¬æ¨¡å‹åƒæ•¸ï¼Œä½¿ç”¨é è¨­é…ç½®: {e}")
        
        # å¦‚æœæª¢æ¸¬å¤±æ•—æˆ–æ²’æœ‰æª¢æ¸¬å™¨ï¼Œä½¿ç”¨é è¨­é…ç½®
        base_params = {
            'max_tokens': {'type': 'int', 'range': [1, 32000], 'default': 2000},
            'timeout': {'type': 'int', 'range': [10, 600], 'default': 60}
        }
        
        if model_name.startswith('gpt-5'):
            base_params.update({
                'reasoning_effort': {
                    'type': 'select', 
                    'options': ['minimal', 'low', 'medium', 'high'], 
                    'default': 'medium'
                },
                'verbosity': {
                    'type': 'select', 
                    'options': ['low', 'medium', 'high'], 
                    'default': 'medium'
                }
            })
        
        return base_params
    
    def is_model_available(model_name):
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        valid_models = [
            "gpt-5",
            "gpt-5-nano",
            "gpt-5-mini"
        ]
        return model_name in valid_models

except ImportError as e:
    print(f"è­¦å‘Šï¼šç„¡æ³•å°å…¥backendè¨­å®šæ¨¡çµ„: {e}")
    # æä¾›fallbacké…ç½®
    def get_current_model():
        return "gpt-5-mini"
    
    def get_model_params(model_name=None):
        if model_name is None:
            model_name = get_current_model()
        return {
            "model": model_name,
            "max_tokens": 4000,
            "timeout": 120,
        }
    
    def get_model_supported_parameters(model_name: str = None) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹æ”¯æ´çš„åƒæ•¸ï¼ˆfallbackç‰ˆæœ¬ï¼‰"""
        if model_name is None:
            model_name = get_current_model()
        
        base_params = {
            'max_tokens': {'type': 'int', 'range': [1, 32000], 'default': 2000},
            'timeout': {'type': 'int', 'range': [10, 600], 'default': 60}
        }
        
        if model_name.startswith('gpt-5'):
            base_params.update({
                'reasoning_effort': {
                    'type': 'select', 
                    'options': ['minimal', 'low', 'medium', 'high'], 
                    'default': 'medium'
                },
                'verbosity': {
                    'type': 'select', 
                    'options': ['low', 'medium', 'high'], 
                    'default': 'medium'
                }
            })
        
        return base_params
    
    def is_model_available(model_name):
        valid_models = [
            "gpt-5",
            "gpt-5-nano",
            "gpt-5-mini"
        ]
        return model_name in valid_models

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œæä¾›èˆŠçš„é…ç½®æ¥å£
def get_llm_params():
    """ç²å–LLMåƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    return get_model_params()

def get_llm_model_name():
    """ç²å–LLMæ¨¡å‹åç¨±ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    return get_current_model() 
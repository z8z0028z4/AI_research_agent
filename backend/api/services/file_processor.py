"""
æ–‡ä»¶è™•ç†æœå‹™
============

è² è²¬è™•ç†ä¸Šå‚³çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬è«–æ–‡å’Œå¯¦é©—è³‡æ–™çš„è™•ç†
"""

import os
import sys
import time
import logging
import shutil
from typing import List, Dict, Any, Callable

# æ·»åŠ åŸé …ç›®è·¯å¾‘åˆ° sys.path
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../app'))

from file_upload import process_uploaded_files
from chunk_embedding import embed_documents_from_metadata, embed_experiment_txt_batch
from excel_to_txt_by_row import export_new_experiments_to_txt
from app.config import EXPERIMENT_DIR

from .file_classifier import FileClassifier
from .progress_tracker import progress_tracker

logger = logging.getLogger(__name__)


class FileProcessor:
    """æ–‡ä»¶è™•ç†å™¨"""
    
    def __init__(self):
        self.classifier = FileClassifier()
    
    async def process_files(self, task_id: str, file_paths: List[str], temp_dir: str) -> None:
        """
        è™•ç†æ–‡ä»¶çš„ä¸»è¦æ–¹æ³•
        
        Args:
            task_id: ä»»å‹™ ID
            file_paths: æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
            temp_dir: è‡¨æ™‚ç›®éŒ„
        """
        start_time = time.time()
        logger.info(f"ğŸš€ é–‹å§‹è™•ç†ä»»å‹™ {task_id}ï¼Œå…± {len(file_paths)} å€‹æ–‡ä»¶")
        
        try:
            # æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
            progress_tracker.update_task(task_id, status="processing", progress=0, message="é–‹å§‹è™•ç†...")
            
            # åˆ†é¡æ–‡ä»¶
            file_info = self.classifier.classify_files(file_paths)
            progress_tracker.update_task(task_id, progress=10, message="æ–‡ä»¶åˆ†é¡å®Œæˆ")
            
            # è™•ç†è«–æ–‡è³‡æ–™
            paper_results = await self._process_papers(task_id, file_info)
            
            # è™•ç†å¯¦é©—è³‡æ–™
            experiment_results = await self._process_experiments(task_id, file_info)
            
            # æ›´æ–°å‘é‡çµ±è¨ˆ
            vector_stats = await self._update_vector_stats()
            
            # å®Œæˆä»»å‹™
            results = {
                "paper_results": paper_results,
                "experiment_results": experiment_results,
                "file_info": file_info,
                "vector_stats": vector_stats
            }
            
            progress_tracker.complete_task(task_id, results)
            
        except Exception as e:
            logger.error(f"âŒ ä»»å‹™ {task_id} è™•ç†å¤±æ•—: {e}")
            progress_tracker.fail_task(task_id, str(e))
        finally:
            # æ¸…ç†è‡¨æ™‚ç›®éŒ„
            self._cleanup_temp_dir(temp_dir)
    
    async def _process_papers(self, task_id: str, file_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è™•ç†è«–æ–‡è³‡æ–™"""
        papers = file_info.get("papers", [])
        if not papers:
            return []
        
        logger.info(f"ğŸ“š é–‹å§‹è™•ç† {len(papers)} å€‹è«–æ–‡æ–‡ä»¶")
        
        # å‰µå»ºé€²åº¦å›èª¿
        progress_callback = progress_tracker.create_progress_callback(
            task_id, start_progress=10, end_progress=50
        )
        
        # æå–å…ƒæ•¸æ“š
        progress_callback("ğŸ“„ é–‹å§‹å…ƒæ•¸æ“šæå–...", 0)
        metadata_list = process_uploaded_files(papers, status_callback=progress_callback)
        
        # å‘é‡åµŒå…¥
        progress_callback("ğŸ”¢ é–‹å§‹å‘é‡åµŒå…¥...", 50)
        embed_progress_callback = progress_tracker.create_progress_callback(
            task_id, start_progress=50, end_progress=90
        )
        embed_documents_from_metadata(metadata_list, status_callback=embed_progress_callback)
        
        logger.info(f"âœ… è«–æ–‡è™•ç†å®Œæˆï¼Œå…±è™•ç† {len(metadata_list)} å€‹æ–‡ä»¶")
        return metadata_list
    
    async def _process_experiments(self, task_id: str, file_info: Dict[str, Any]) -> List[Dict[str, Any]]:
        """è™•ç†å¯¦é©—è³‡æ–™"""
        experiments = file_info.get("experiments", [])
        if not experiments:
            return []
        
        logger.info(f"ğŸ§ª é–‹å§‹è™•ç† {len(experiments)} å€‹å¯¦é©—æ–‡ä»¶")
        
        experiment_results = []
        progress_callback = progress_tracker.create_progress_callback(
            task_id, start_progress=90, end_progress=98
        )
        
        for i, file_path in enumerate(experiments):
            try:
                progress_callback(f"è™•ç†å¯¦é©—æ–‡ä»¶ {i+1}/{len(experiments)}: {os.path.basename(file_path)}")
                
                # è½‰æ› Excel ç‚º TXT
                df, txt_paths = export_new_experiments_to_txt(
                    excel_path=file_path,
                    output_dir=EXPERIMENT_DIR
                )
                
                # å‘é‡åµŒå…¥
                result = embed_experiment_txt_batch(txt_paths)
                
                experiment_results.append({
                    "file": file_path,
                    "txt_paths": txt_paths,
                    "embedded_count": len(txt_paths)
                })
                
            except Exception as e:
                logger.error(f"âŒ å¯¦é©—æ–‡ä»¶è™•ç†å¤±æ•— {os.path.basename(file_path)}: {e}")
                experiment_results.append({
                    "file": file_path,
                    "error": str(e)
                })
        
        logger.info(f"âœ… å¯¦é©—è™•ç†å®Œæˆï¼Œå…±è™•ç† {len(experiments)} å€‹æ–‡ä»¶")
        return experiment_results
    
    async def _update_vector_stats(self) -> Dict[str, int]:
        """æ›´æ–°å‘é‡çµ±è¨ˆç·©å­˜"""
        try:
            from main import update_vector_stats_cache, get_cached_vector_stats
            update_vector_stats_cache()
            cached_stats = get_cached_vector_stats()
            
            vector_stats = {
                "paper_vectors": cached_stats["paper_vectors"],
                "experiment_vectors": cached_stats["experiment_vectors"],
                "total_vectors": cached_stats["total_vectors"]
            }
            
            logger.info(f"ğŸ“Š å‘é‡çµ±è¨ˆæ›´æ–°å®Œæˆ: {vector_stats}")
            return vector_stats
            
        except Exception as e:
            logger.error(f"âš ï¸ ç„¡æ³•æ›´æ–°å‘é‡çµ±è¨ˆç·©å­˜: {e}")
            return {"paper_vectors": 0, "experiment_vectors": 0, "total_vectors": 0}
    
    def _cleanup_temp_dir(self, temp_dir: str) -> None:
        """æ¸…ç†è‡¨æ™‚ç›®éŒ„"""
        try:
            if os.path.exists(temp_dir):
                shutil.rmtree(temp_dir)
                logger.info(f"ğŸ§¹ æ¸…ç†è‡¨æ™‚ç›®éŒ„: {temp_dir}")
        except Exception as e:
            logger.warning(f"âš ï¸ æ¸…ç†è‡¨æ™‚ç›®éŒ„å¤±æ•—: {e}")


# å…¨å±€æ–‡ä»¶è™•ç†å™¨å¯¦ä¾‹
file_processor = FileProcessor()

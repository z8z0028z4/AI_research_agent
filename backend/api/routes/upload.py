"""
æ–‡ä»¶ä¸Šå‚³ API è·¯ç”±
================

è™•ç†æ–‡ä»¶ä¸Šå‚³ã€è™•ç†å’Œç‹€æ…‹æŸ¥è©¢åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import FileResponse
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import os
import sys
import tempfile
import shutil
from pathlib import Path

# æ·»åŠ åŸé …ç›®è·¯å¾‘åˆ° sys.path
sys.path.append(os.path.join(os.path.dirname(__file__), '../../../app'))

from file_upload import process_uploaded_files
from chunk_embedding import embed_documents_from_metadata, embed_experiment_txt_batch
from excel_to_txt_by_row import export_new_experiments_to_txt
from config import EXPERIMENT_DIR

router = APIRouter()

class FileUploadResponse(BaseModel):
    """æ–‡ä»¶ä¸Šå‚³éŸ¿æ‡‰æ¨¡å‹"""
    success: bool
    message: str
    file_info: Dict[str, Any]
    processing_status: str

class ProcessingStatus(BaseModel):
    """è™•ç†ç‹€æ…‹æ¨¡å‹"""
    task_id: str
    status: str  # pending, processing, completed, failed
    progress: int
    message: str
    results: Optional[Dict[str, Any]] = None

# å­˜å„²è™•ç†ä»»å‹™ç‹€æ…‹
processing_tasks = {}

@router.post("/upload/files", response_model=FileUploadResponse)
async def upload_files(
    background_tasks: BackgroundTasks,
    files: List[UploadFile] = File(...)
):
    """
    ä¸Šå‚³ä¸¦è™•ç†æ–‡ä»¶
    
    Args:
        background_tasks: å¾Œå°ä»»å‹™ç®¡ç†å™¨
        files: ä¸Šå‚³çš„æ–‡ä»¶åˆ—è¡¨
        
    Returns:
        ä¸Šå‚³çµæœå’Œè™•ç†ç‹€æ…‹
    """
    try:
        # å‰µå»ºè‡¨æ™‚ç›®éŒ„å­˜å„²ä¸Šå‚³çš„æ–‡ä»¶
        temp_dir = tempfile.mkdtemp()
        uploaded_files = []
        
        # ä¿å­˜ä¸Šå‚³çš„æ–‡ä»¶
        for file in files:
            if file.filename:
                file_path = os.path.join(temp_dir, file.filename)
                with open(file_path, "wb") as buffer:
                    shutil.copyfileobj(file.file, buffer)
                uploaded_files.append(file_path)
        
        # ç”Ÿæˆä»»å‹™ ID
        task_id = f"task_{len(processing_tasks) + 1}"
        
        # åˆå§‹åŒ–ä»»å‹™ç‹€æ…‹
        processing_tasks[task_id] = {
            "status": "pending",
            "progress": 0,
            "message": "æ–‡ä»¶ä¸Šå‚³å®Œæˆï¼Œé–‹å§‹è™•ç†...",
            "results": None
        }
        
        # åœ¨å¾Œå°è™•ç†æ–‡ä»¶
        background_tasks.add_task(
            process_files_background,
            task_id,
            uploaded_files,
            temp_dir
        )
        
        return FileUploadResponse(
            success=True,
            message="æ–‡ä»¶ä¸Šå‚³æˆåŠŸï¼Œé–‹å§‹è™•ç†",
            file_info={
                "task_id": task_id,
                "file_count": len(files),
                "file_names": [f.filename for f in files if f.filename]
            },
            processing_status="pending"
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸Šå‚³å¤±æ•—: {str(e)}")

def _classify_files_by_type(file_paths: List[str]) -> Dict[str, List[str]]:
    """æ ¹æ“šå‰¯æª”åå°‡æª”æ¡ˆåˆ†é¡ç‚ºè«–æ–‡æˆ–å¯¦é©—è³‡æ–™ã€‚"""
    papers: List[str] = []
    experiments: List[str] = []
    other: List[str] = []

    for path in file_paths:
        ext = os.path.splitext(path)[1].lower()
        if ext in [".pdf", ".docx"]:
            papers.append(path)
        elif ext in [".xlsx", ".xls"]:
            experiments.append(path)
        else:
            other.append(path)

    return {"type": "mixed", "papers": papers, "experiments": experiments, "others": other}


async def process_files_background(task_id: str, file_paths: List[str], temp_dir: str):
    """
    å¾Œå°è™•ç†æ–‡ä»¶
    
    Args:
        task_id: ä»»å‹™ ID
        file_paths: æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        temp_dir: è‡¨æ™‚ç›®éŒ„
    """
    try:
        # æ›´æ–°ç‹€æ…‹ç‚ºè™•ç†ä¸­
        processing_tasks[task_id]["status"] = "processing"
        processing_tasks[task_id]["progress"] = 10
        processing_tasks[task_id]["message"] = "åˆ†ææ–‡ä»¶é¡å‹..."
        
        # åˆ†ææ–‡ä»¶é¡å‹ï¼ˆä¾å‰¯æª”ååˆ†é¡ï¼‰
        file_info = _classify_files_by_type(file_paths)
        
        processing_tasks[task_id]["progress"] = 30
        processing_tasks[task_id]["message"] = "è™•ç†è«–æ–‡è³‡æ–™..."
        
        # è™•ç†è«–æ–‡è³‡æ–™ï¼ˆæå– metadata ä¸¦åµŒå…¥å‘é‡ï¼‰
        paper_results: List[Dict[str, Any]] = []
        if file_info.get("papers"):
            # å…ˆæ‰¹æ¬¡èƒå– metadata
            metadata_list: List[Dict[str, Any]] = process_uploaded_files(file_info["papers"])
            paper_results.extend(metadata_list)
            # é€²è¡ŒåµŒå…¥
            embed_documents_from_metadata(metadata_list)
        
        processing_tasks[task_id]["progress"] = 60
        processing_tasks[task_id]["message"] = "è™•ç†å¯¦é©—è³‡æ–™..."
        
        # è™•ç†å¯¦é©—è³‡æ–™ï¼ˆExcel -> txt -> å‘é‡åµŒå…¥ï¼‰
        experiment_results: List[Dict[str, Any]] = []
        if file_info.get("experiments"):
            for f in file_info["experiments"]:
                try:
                    df, txt_paths = export_new_experiments_to_txt(
                        excel_path=f,
                        output_dir=EXPERIMENT_DIR
                    )
                    result = embed_experiment_txt_batch(txt_paths)
                    experiment_results.append({
                        "file": f,
                        "txt_paths": txt_paths,
                        "embedded_count": len(txt_paths)
                    })
                except Exception as e:
                    experiment_results.append({
                        "file": f,
                        "error": str(e)
                    })
        
        processing_tasks[task_id]["progress"] = 90
        processing_tasks[task_id]["message"] = "å®Œæˆè™•ç†..."
        
        # æ›´æ–°æœ€çµ‚çµæœ
        processing_tasks[task_id]["status"] = "completed"
        processing_tasks[task_id]["progress"] = 100
        processing_tasks[task_id]["message"] = "è™•ç†å®Œæˆ"
        processing_tasks[task_id]["results"] = {
            "paper_results": paper_results,
            "experiment_results": experiment_results,
            "file_info": file_info
        }
        
    except Exception as e:
        processing_tasks[task_id]["status"] = "failed"
        processing_tasks[task_id]["message"] = f"è™•ç†å¤±æ•—: {str(e)}"
    finally:
        # æ¸…ç†è‡¨æ™‚ç›®éŒ„
        try:
            shutil.rmtree(temp_dir)
        except:
            pass

@router.get("/upload/status/{task_id}", response_model=ProcessingStatus)
async def get_processing_status(task_id: str):
    """
    ç²å–æ–‡ä»¶è™•ç†ç‹€æ…‹
    
    Args:
        task_id: ä»»å‹™ ID
        
    Returns:
        è™•ç†ç‹€æ…‹ä¿¡æ¯
    """
    if task_id not in processing_tasks:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    task = processing_tasks[task_id]
    return ProcessingStatus(
        task_id=task_id,
        status=task["status"],
        progress=task["progress"],
        message=task["message"],
        results=task["results"]
    )

@router.get("/upload/download/{task_id}")
async def download_processed_files(task_id: str):
    """
    ä¸‹è¼‰è™•ç†å¾Œçš„æ–‡ä»¶
    
    Args:
        task_id: ä»»å‹™ ID
        
    Returns:
        è™•ç†å¾Œçš„æ–‡ä»¶
    """
    if task_id not in processing_tasks:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    task = processing_tasks[task_id]
    if task["status"] != "completed":
        raise HTTPException(status_code=400, detail="ä»»å‹™å°šæœªå®Œæˆ")
    
    # TODO: å¯¦ç¾æ–‡ä»¶æ‰“åŒ…å’Œä¸‹è¼‰
    return {"message": "ä¸‹è¼‰åŠŸèƒ½å¾…å¯¦ç¾"}

@router.delete("/upload/cancel/{task_id}")
async def cancel_processing(task_id: str):
    """
    å–æ¶ˆæ–‡ä»¶è™•ç†ä»»å‹™
    
    Args:
        task_id: ä»»å‹™ ID
        
    Returns:
        å–æ¶ˆçµæœ
    """
    if task_id not in processing_tasks:
        raise HTTPException(status_code=404, detail="ä»»å‹™ä¸å­˜åœ¨")
    
    processing_tasks[task_id]["status"] = "cancelled"
    processing_tasks[task_id]["message"] = "ä»»å‹™å·²å–æ¶ˆ"
    
    return {"message": "ä»»å‹™å·²å–æ¶ˆ", "task_id": task_id}

@router.get("/documents/{filename:path}")
async def download_document(filename: str):
    """
    ä¸‹è¼‰æ–‡æª”æ–‡ä»¶
    
    Args:
        filename: æ–‡ä»¶åï¼ˆæ”¯æŒå­ç›®éŒ„è·¯å¾‘ï¼‰
        
    Returns:
        æ–‡ä»¶å…§å®¹
    """
    try:
        import os
        # ç²å–é …ç›®æ ¹ç›®éŒ„ï¼ˆå¾backendç›®éŒ„å‘ä¸Šå…©ç´šåˆ°é …ç›®æ ¹ç›®éŒ„ï¼‰
        current_file_dir = os.path.dirname(__file__)  # backend/api/routes/
        backend_dir = os.path.dirname(os.path.dirname(current_file_dir))  # backend/
        project_root = os.path.dirname(backend_dir)  # é …ç›®æ ¹ç›®éŒ„
        print(f"ğŸ” DEBUG: current_file_dir = {current_file_dir}")
        print(f"ğŸ” DEBUG: backend_dir = {backend_dir}")
        print(f"ğŸ” DEBUG: project_root = {project_root}")
        print(f"ğŸ” DEBUG: filename = {filename}")
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç›´æ¥æ–‡ä»¶åï¼ˆä¸åŒ…å«è·¯å¾‘ï¼‰
        if not os.path.dirname(filename):
            # å¦‚æœæ˜¯ç›´æ¥æ–‡ä»¶åï¼Œå‰‡å‡è¨­åœ¨papersç›®éŒ„ä¸­
            file_path = os.path.join(project_root, "experiment_data", "papers", filename)
        else:
            # å¦‚æœåŒ…å«è·¯å¾‘ï¼Œå‰‡ä½¿ç”¨å®Œæ•´è·¯å¾‘
            file_path = os.path.join(project_root, filename)
        
        # å®‰å…¨æª¢æŸ¥ï¼šç¢ºä¿æ–‡ä»¶è·¯å¾‘åœ¨å…è¨±çš„ç›®éŒ„å…§
        allowed_dirs = [
            os.path.join(project_root, "experiment_data", "papers"),
            os.path.join(project_root, "uploads")
        ]
        
        file_path_abs = os.path.abspath(file_path)
        is_allowed = any(file_path_abs.startswith(allowed_dir) for allowed_dir in allowed_dirs)
        
        if not is_allowed:
            print(f"âŒ è¨ªå•è¢«æ‹’çµ•: {file_path_abs}")
            print(f"âŒ å…è¨±çš„ç›®éŒ„: {allowed_dirs}")
            raise HTTPException(status_code=403, detail="è¨ªå•è¢«æ‹’çµ•")
        
        if not os.path.exists(file_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
        
        print(f"âœ… æä¾›æ–‡ä»¶: {file_path}")
        
        # è¨­ç½®MIMEé¡å‹æ˜ å°„
        mime_types = {
            '.pdf': 'application/pdf',
            '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
            '.doc': 'application/msword',
            '.txt': 'text/plain',
            '.html': 'text/html',
            '.htm': 'text/html'
        }
        
        # æ ¹æ“šæ–‡ä»¶é¡å‹è¨­ç½®æ­£ç¢ºçš„MIMEé¡å‹å’ŒéŸ¿æ‡‰é ­
        # ç‰¹æ®Šè™•ç†ï¼šæª¢æŸ¥æ–‡ä»¶åæ˜¯å¦ä»¥_SI.pdfçµå°¾ï¼Œä¹Ÿæ‡‰è©²è­˜åˆ¥ç‚ºPDF
        if filename.lower().endswith('_si.pdf'):
            file_extension = '.pdf'
        else:
            file_extension = os.path.splitext(filename)[1].lower()
        
        media_type = mime_types.get(file_extension, 'application/octet-stream')
        
        # å°æ–¼PDFæ–‡ä»¶ï¼Œè¨­ç½®éŸ¿æ‡‰é ­è®“ç€è¦½å™¨ç›´æ¥é¡¯ç¤ºè€Œä¸æ˜¯ä¸‹è¼‰
        headers = {}
        if file_extension == '.pdf':
            # å¼·åˆ¶è¨­ç½® PDF æ–‡ä»¶çš„éŸ¿æ‡‰é ­
            headers['Content-Disposition'] = 'inline'
            headers['Content-Type'] = 'application/pdf'
            # æ·»åŠ é¡å¤–çš„é ­ä¾†ç¢ºä¿ç€è¦½å™¨æ­£ç¢ºè™•ç†
            headers['X-Content-Type-Options'] = 'nosniff'
            headers['Cache-Control'] = 'public, max-age=3600'
            # å°æ–¼ SI æ–‡ä»¶ï¼Œæ·»åŠ ç‰¹æ®Šæ¨™è­˜
            if filename.lower().endswith('_si.pdf'):
                headers['X-File-Type'] = 'supplementary-information'
        else:
            headers['Content-Disposition'] = f'inline; filename="{os.path.basename(filename)}"'
        
        # è¿”å›æ–‡ä»¶
        return FileResponse(
            path=file_path,
            filename=os.path.basename(filename),
            media_type=media_type,
            headers=headers
        )
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ æ–‡ä»¶ä¸‹è¼‰å¤±æ•—: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ–‡ä»¶ä¸‹è¼‰å¤±æ•—: {str(e)}") 
"""
AI ç ”ç©¶åŠ©ç† - æŸ¥è©¢è§£æå™¨æ¨¡å¡Š
==========================

é€™å€‹æ¨¡å¡Šè² è²¬è§£æå’Œå„ªåŒ–ç”¨æˆ¶çš„æŸ¥è©¢ï¼Œæå–é—œéµè©ç”¨æ–¼æœç´¢ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æ™ºèƒ½é—œéµè©æå–
2. å¤šèªè¨€æŸ¥è©¢è™•ç†
3. ç§‘å­¸è¡“èªè­˜åˆ¥
4. æŸ¥è©¢å„ªåŒ–å’Œæ¨™æº–åŒ–

æ¶æ§‹èªªæ˜ï¼š
- ä½¿ç”¨OpenAI GPTæ¨¡å‹é€²è¡Œæ™ºèƒ½é—œéµè©æå–
- æ”¯æŒä¸­è‹±æ–‡æ··åˆæŸ¥è©¢
- å°ˆæ³¨æ–¼ç§‘å­¸æ–‡ç»ç›¸é—œçš„é—œéµè©è­˜åˆ¥
- æä¾›æ¨™æº–åŒ–çš„æŸ¥è©¢è™•ç†æµç¨‹
"""

from typing import List, Literal, Dict, Optional
import re
from openai import OpenAI
import os
from config import LLM_MODEL_NAME, LLM_PARAMS
import ast

# ==================== OpenAIå®¢æˆ¶ç«¯åˆå§‹åŒ– ====================
# å‰µå»ºOpenAI APIå®¢æˆ¶ç«¯ï¼Œç”¨æ–¼èª¿ç”¨GPTæ¨¡å‹é€²è¡Œé—œéµè©æå–
# ä½¿ç”¨ç’°å¢ƒè®Šé‡ä¸­çš„APIå¯†é‘°ç¢ºä¿å®‰å…¨æ€§
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

def extract_keywords(question: str) -> List[str]:
    """
    å¾ç”¨æˆ¶æŸ¥è©¢ä¸­æå–ç§‘å­¸é—œéµè©
    
    åŠŸèƒ½ï¼š
    1. åˆ†æç”¨æˆ¶çš„æŸ¥è©¢å…§å®¹
    2. è­˜åˆ¥ç§‘å­¸è¡“èªå’Œææ–™åç¨±
    3. å°‡éè‹±æ–‡æŸ¥è©¢ç¿»è­¯ç‚ºè‹±æ–‡é—œéµè©
    4. è¿”å›æ¨™æº–åŒ–çš„é—œéµè©åˆ—è¡¨
    
    åƒæ•¸ï¼š
        question (str): ç”¨æˆ¶çš„æŸ¥è©¢å•é¡Œï¼Œæ”¯æŒä¸­è‹±æ–‡
    
    è¿”å›ï¼š
        List[str]: æå–çš„è‹±æ–‡é—œéµè©åˆ—è¡¨
    
    ç¤ºä¾‹ï¼š
        >>> keywords = extract_keywords("å¦‚ä½•é€²è¡ŒäºŒæ°§åŒ–ç¢³æ•ç²ï¼Ÿ")
        >>> print(keywords)  # ['carbon dioxide capture', 'CO2', 'direct air capture']
    """
    
    # ==================== æç¤ºè©è¨­è¨ˆ ====================
    # è¨­è¨ˆå°ˆé–€çš„æç¤ºè©ï¼ŒæŒ‡å°GPTæ¨¡å‹æå–ç§‘å­¸é—œéµè©
    # å¼·èª¿åªè¿”å›å¯èƒ½åœ¨ç§‘å­¸è«–æ–‡æ‘˜è¦ä¸­å‡ºç¾çš„è‹±æ–‡é—œéµè©
    prompt = f"""
    You are an expert scientific assistant.  
    Extract only the most relevant **English** scientific keywords or material names from the following research question.

    - Only return keywords or entities that are likely to appear in scientific English papers' abstract.
    - If the input is in another language (e.g., Chinese), translate the scientific terms and return **only English keywords**.
    - Do not return explanations or extra formatting.

    Return the result as a valid Python list of quoted strings.  
    Example: ["direct air capture", "CO2", "MOFs"]

    Question: "{question}"
    """

    # ==================== GPTæ¨¡å‹èª¿ç”¨ ====================
    # ä½¿ç”¨OpenAI GPTæ¨¡å‹é€²è¡Œé—œéµè©æå–
    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çµ±ä¸€çš„LLMåƒæ•¸
    try:
        response = client.chat.completions.create(
            model=LLM_PARAMS["model"],  # ä½¿ç”¨ "model" è€Œä¸æ˜¯ "model_name"
            messages=[{"role": "user", "content": prompt}],
            max_tokens=LLM_PARAMS.get("max_tokens", 4000),  # ä½¿ç”¨ "max_tokens" è€Œä¸æ˜¯ "max_completion_tokens"
            timeout=LLM_PARAMS.get("timeout", 120),
        )
        
        # ç²å–æ¨¡å‹è¿”å›çš„åŸå§‹æ–‡æœ¬
        raw = response.choices[0].message.content.strip()
        print("ğŸ§  GPTæ¨¡å‹åŸå§‹è¿”å›ï¼š", raw)
        
    except Exception as e:
        print(f"âŒ GPTæ¨¡å‹èª¿ç”¨å¤±æ•—ï¼š{e}")
        return []

    # ==================== çµæœè§£æ ====================
    # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æå–Pythonåˆ—è¡¨æ ¼å¼çš„çµæœ
    # ç„¶å¾Œä½¿ç”¨ast.literal_evalå®‰å…¨åœ°è§£æåˆ—è¡¨
    try:
        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼åŒ¹é…ç¬¬ä¸€å€‹é¡ä¼¼listçš„[]ç‰‡æ®µ
        # re.DOTALL å…è¨±.åŒ¹é…æ›è¡Œç¬¦
        match = re.search(r'\[.*\]', raw, re.DOTALL)
        
        if match:
            # ä½¿ç”¨ast.literal_evalå®‰å…¨åœ°è§£æå­—ç¬¦ä¸²ç‚ºPythonåˆ—è¡¨
            # é€™æ¯”eval()æ›´å®‰å…¨ï¼Œåªå…è¨±å­—é¢é‡è¡¨é”å¼
            keywords = ast.literal_eval(match.group(0))
            
            # é©—è­‰çµæœæ˜¯å¦ç‚ºå­—ç¬¦ä¸²åˆ—è¡¨
            if isinstance(keywords, list) and all(isinstance(k, str) for k in keywords):
                print(f"âœ… æˆåŠŸæå– {len(keywords)} å€‹é—œéµè©ï¼š{keywords}")
                return keywords
            else:
                print("âš ï¸ è§£æçµæœæ ¼å¼ä¸æ­£ç¢º")
                return []
        else:
            print("âš ï¸ æ²’æœ‰æª¢æ¸¬åˆ°åˆæ³•çš„Pythonåˆ—è¡¨æ ¼å¼")
            return []
            
    except Exception as e:
        print(f"âŒ é—œéµè©è§£æå¤±æ•—ï¼š{e}")
        return []


def parse_query_intent(query: str) -> Dict[str, any]:
    """
    è§£ææŸ¥è©¢æ„åœ–å’Œé¡å‹
    
    åŠŸèƒ½ï¼š
    1. è­˜åˆ¥æŸ¥è©¢çš„é¡å‹ï¼ˆæœç´¢ã€åˆ†æã€æ¯”è¼ƒç­‰ï¼‰
    2. æå–æŸ¥è©¢çš„æ„åœ–å’Œç›®æ¨™
    3. è­˜åˆ¥æŸ¥è©¢ä¸­çš„å¯¦é«”å’Œé—œä¿‚
    
    åƒæ•¸ï¼š
        query (str): ç”¨æˆ¶æŸ¥è©¢
    
    è¿”å›ï¼š
        Dict[str, any]: åŒ…å«æŸ¥è©¢æ„åœ–ä¿¡æ¯çš„å­—å…¸
    """
    prompt = f"""
    Analyze the following research query and extract its intent and components.
    
    Return a JSON object with the following structure:
    {{
        "intent": "search|analyze|compare|synthesize",
        "entities": ["entity1", "entity2"],
        "relationships": ["relationship1"],
        "domain": "chemistry|biology|physics|materials",
        "complexity": "simple|moderate|complex"
    }}
    
    Query: "{query}"
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_PARAMS["model"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=LLM_PARAMS.get("max_tokens", 4000),
            timeout=LLM_PARAMS.get("timeout", 120),
        )
        
        # è§£æJSONçµæœ
        import json
        result = json.loads(response.choices[0].message.content.strip())
        return result
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢æ„åœ–è§£æå¤±æ•—ï¼š{e}")
        return {
            "intent": "search",
            "entities": [],
            "relationships": [],
            "domain": "general",
            "complexity": "simple"
        }


def optimize_search_query(original_query: str, context: List[str] = None) -> str:
    """
    å„ªåŒ–æœç´¢æŸ¥è©¢ä»¥æé«˜æœç´¢æ•ˆæœ
    
    åŠŸèƒ½ï¼š
    1. åŸºæ–¼åŸå§‹æŸ¥è©¢ç”Ÿæˆæ›´ç²¾ç¢ºçš„æœç´¢è©
    2. è€ƒæ…®ä¸Šä¸‹æ–‡ä¿¡æ¯é€²è¡ŒæŸ¥è©¢å„ªåŒ–
    3. æ·»åŠ ç›¸é—œçš„ç§‘å­¸è¡“èªå’ŒåŒç¾©è©
    
    åƒæ•¸ï¼š
        original_query (str): åŸå§‹æŸ¥è©¢
        context (List[str]): ç›¸é—œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
    
    è¿”å›ï¼š
        str: å„ªåŒ–å¾Œçš„æŸ¥è©¢å­—ç¬¦ä¸²
    """
    context_text = ""
    if context:
        context_text = f"\nContext: {', '.join(context)}"
    
    prompt = f"""
    Optimize the following research query for better search results.
    
    Original query: "{original_query}"{context_text}
    
    Return only the optimized query string, no explanations.
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_PARAMS["model"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=LLM_PARAMS.get("max_tokens", 4000),
            timeout=LLM_PARAMS.get("timeout", 120),
        )
        
        optimized_query = response.choices[0].message.content.strip()
        print(f"ğŸ” æŸ¥è©¢å„ªåŒ–ï¼š'{original_query}' â†’ '{optimized_query}'")
        return optimized_query
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å„ªåŒ–å¤±æ•—ï¼š{e}")
        return original_query


def extract_chemical_entities(query: str) -> List[str]:
    """
    å¾æŸ¥è©¢ä¸­æå–åŒ–å­¸å¯¦é«”ï¼ˆåŒ–åˆç‰©ã€ææ–™ç­‰ï¼‰
    
    åŠŸèƒ½ï¼š
    1. è­˜åˆ¥åŒ–å­¸å“åç¨±
    2. è­˜åˆ¥ææ–™åç¨±
    3. è­˜åˆ¥åŒ–å­¸åæ‡‰é¡å‹
    4. è­˜åˆ¥å¯¦é©—æ–¹æ³•
    
    åƒæ•¸ï¼š
        query (str): ç”¨æˆ¶æŸ¥è©¢
    
    è¿”å›ï¼š
        List[str]: åŒ–å­¸å¯¦é«”åˆ—è¡¨
    """
    prompt = f"""
    Extract chemical entities from the following query.
    Focus on:
    - Chemical compounds and materials
    - Reaction types
    - Experimental methods
    - Physical properties
    
    Return as a Python list of strings.
    
    Query: "{query}"
    """
    
    try:
        response = client.chat.completions.create(
            model=LLM_PARAMS["model"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=LLM_PARAMS.get("max_tokens", 4000),
            timeout=LLM_PARAMS.get("timeout", 120),
        )
        
        raw = response.choices[0].message.content.strip()
        match = re.search(r'\[.*\]', raw, re.DOTALL)
        
        if match:
            entities = ast.literal_eval(match.group(0))
            print(f"ğŸ§ª æå–åŒ–å­¸å¯¦é«”ï¼š{entities}")
            return entities
        else:
            return []
            
    except Exception as e:
        print(f"âŒ åŒ–å­¸å¯¦é«”æå–å¤±æ•—ï¼š{e}")
        return []


# ==================== è¼”åŠ©å‡½æ•¸ ====================
def validate_query(query: str) -> bool:
    """
    é©—è­‰æŸ¥è©¢æ˜¯å¦æœ‰æ•ˆ
    
    åƒæ•¸ï¼š
        query (str): ç”¨æˆ¶æŸ¥è©¢
    
    è¿”å›ï¼š
        bool: æŸ¥è©¢æ˜¯å¦æœ‰æ•ˆ
    """
    if not query or not query.strip():
        return False
    
    # æª¢æŸ¥æŸ¥è©¢é•·åº¦
    if len(query.strip()) < 2:
        return False
    
    # æª¢æŸ¥æ˜¯å¦åŒ…å«æœ‰æ•ˆå­—ç¬¦
    if not re.search(r'[a-zA-Z\u4e00-\u9fff]', query):
        return False
    
    return True


def clean_query(query: str) -> str:
    """
    æ¸…ç†å’Œæ¨™æº–åŒ–æŸ¥è©¢
    
    åƒæ•¸ï¼š
        query (str): åŸå§‹æŸ¥è©¢
    
    è¿”å›ï¼š
        str: æ¸…ç†å¾Œçš„æŸ¥è©¢
    """
    # ç§»é™¤å¤šé¤˜çš„ç©ºç™½å­—ç¬¦
    cleaned = re.sub(r'\s+', ' ', query.strip())
    
    # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼ˆä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•¸å­—å’ŒåŸºæœ¬æ¨™é»ï¼‰
    cleaned = re.sub(r'[^\w\s\u4e00-\u9fff.,?!;:()\[\]{}]', '', cleaned)
    
    return cleaned


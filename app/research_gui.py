import streamlit as st
from perplexity_search_fallback import ask_perplexity
from search_agent import search_and_download_only
import os
import tempfile
import re
from knowledge_agent import agent_answer
from browser import select_files
from file_upload import process_uploaded_files
from chunk_embedding import embed_documents_from_metadata, embed_experiment_txt_batch
import pandas as pd
from excel_to_txt_by_row import export_new_experiments_to_txt
from config import EXPERIMENT_DIR
from pubchem_handler import chemical_metadata_extractor
from rag_core import build_detail_experimental_plan_prompt

st.set_page_config(page_title="ç ”ç©¶åŠ©ç†ç³»çµ±", layout="wide")
st.title("ğŸ§ª AI ç ”ç©¶åŠ©ç†ç³»çµ±")

tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“˜ çŸ¥è­˜åº«åŠ©ç†",
    "ğŸ” æœå°‹å¤–éƒ¨æ–‡ç»ä¸¦ä¸‹è¼‰ PDF",
    "ğŸ“¥ è«–æ–‡/å¯¦é©—è³‡æ–™ä¸Šå‚³",
    "ğŸŒ ä½¿ç”¨ Perplexity æœå°‹"
])

def format_references_block(text):
    refs = []
    in_reference = False
    for line in text.splitlines():
        if line.strip().lower().startswith("reference") or line.strip().lower().startswith("references"):
            in_reference = True
            continue
        if in_reference and line.strip():
            refs.append(line.strip())
    markdown_links = []
    for ref in refs:
        match = re.match(r"\[(\d+)\]\s*(.*?)(https?://\S+)", ref)
        if match:
            idx, title, url = match.groups()
            markdown_links.append(f"[{idx}] [{title.strip()}]({url.strip()})")
        else:
            markdown_links.append(ref)
    return markdown_links
def render_chemical_table(chemical_metadata_list):
    st.markdown("## ğŸ§ª Chemical Summary Table")

    for chem in chemical_metadata_list:
        cols = st.columns([2, 2, 3, 3])

        # Chemical Name
        with cols[0]:
            url = chem.get("pubchem_url")
            if url:
                st.markdown(f"[**{chem.get('name', 'Unknown')}**]({url})")
            else:
                st.markdown(f"**{chem.get('name', 'Unknown')}**")
            

        # Structure Image
        with cols[1]:
            st.image(chem.get("image_url", ""), width=200)

        # Properties block
        with cols[2]:
            st.markdown("**Properties**")
            st.markdown(f"- **Formula**: `{chem.get('formula', '-')}`")
            st.markdown(f"- **MW**: `{chem.get('weight', '-')}`")
            st.markdown(f"- **Boiling Point**: `{chem.get('boiling_point_c', '-')}`")
            st.markdown(f"- **Melting Point**: `{chem.get('melting_point_c', '-')}`")
            st.markdown(f"- **CAS No.**: `{chem.get('cas', '-')}`")
            st.markdown(f"- **SMILES**: `{chem.get('smiles', '-')}`")

        # Safety block (GHS + NFPA)
        with cols[3]:
            st.markdown("**Handling Safety**")
            if chem.get("safety_icons", {}).get("nfpa_image"):
                st.image(chem["safety_icons"]["nfpa_image"], width=60)

            ghs = chem.get("safety_icons", {}).get("ghs_icons", [])
            if ghs:
                st.image(ghs, width=50)

        st.markdown("---")

with tab1:
    st.subheader("ğŸ“˜ åŠŸèƒ½ 1ï¼šåˆ©ç”¨çŸ¥è­˜åº«å›ç­”å•é¡Œ")
    st.markdown("### âš™ï¸ é¸æ“‡å›ç­”æ¨¡å¼")
    answer_mode = st.radio(
        "è«‹é¸æ“‡ç³»çµ±å›ç­”å•é¡Œçš„æ–¹å¼ï¼š",
        options=[
            "åƒ…åš´è¬¹æ–‡ç»æº¯æº",
            "å…è¨±å»¶ä¼¸èˆ‡æ¨è«–",
            "ç´å…¥å¯¦é©—è³‡æ–™ï¼Œé€²è¡Œæ¨è«–èˆ‡å»ºè­°",
            "make proposal"
        ],
        index=0,
        key="mode_selector"
    )

    q1 = st.text_area("è«‹è¼¸å…¥ç ”ç©¶å•é¡Œï¼š", height=100, key="search1")

    if st.button("ç”±çŸ¥è­˜åº«å›ç­”", key="knowledgebtn"):
        with st.spinner("æŸ¥è©¢çŸ¥è­˜åº«ä¸­..."):
            result = agent_answer(q1, mode = answer_mode)
            #ç”¢ç”Ÿä¹¾æ·¨ç­”æ¡ˆ (åˆ†é›¢LLMç­”æ¡ˆä¸­çš„json)
            if answer_mode == "make proposal":
                chemical_metadata_list, not_found_list, proposal_answer = chemical_metadata_extractor(result["answer"])
                st.session_state["proposal_chunks"] = result.get("chunks", [])
                st.session_state["proposal_answer"] = proposal_answer
                st.session_state["not_found_list"] = not_found_list
                st.session_state["chemical_metadata_list"] = chemical_metadata_list
                st.session_state["result"] = result
    
    has_proposal = (
    "proposal_answer" in st.session_state and
    "chemical_metadata_list" in st.session_state
    )

    if has_proposal:
        st.markdown("### ğŸ¤– å›ç­”")
        st.markdown(st.session_state["proposal_answer"])

        if st.session_state.get("chemical_metadata_list"):
            render_chemical_table(st.session_state["chemical_metadata_list"])
        if st.session_state.get("not_found_list"):
            st.markdown("### âš ï¸ ä»¥ä¸‹åŒ–å­¸å“æœªèƒ½æŸ¥è©¢æˆåŠŸ")
            for name in st.session_state["not_found_list"]:
                st.markdown(f"- {name}")      
            
        
        st.markdown("### ğŸ’¡ Don't like the proposalï¼Ÿ Provide your opinion here")
        user_reason = st.text_input("How you want to revise?", key="revise_reason")
        if st.button("ğŸ’¡ Generate New Idea", key="new_idea_btn"):
            with st.spinner("ğŸ”„ æ ¹æ“šæ‚¨çš„ç†ç”±é‡æ–°æª¢ç´¢æ–‡ç»ä¸¦ç”Ÿæˆææ¡ˆ..."):
                old_chunks = st.session_state.get("proposal_chunks", [])
                past_proposal = st.session_state.get("proposal_answer", "")

                result = agent_answer(
                    user_reason,
                    mode="generate new idea",
                    chunks=old_chunks,
                    proposal=past_proposal
                )

                # âœ… ç›´æ¥è¦†è“‹ session_stateï¼Œç¹¼çºŒå…±ç”¨é¡¯ç¤ºå€å¡Š
                st.session_state["proposal_chunks"] = result.get("chunks", [])
                st.session_state["proposal_answer"] = result["answer"]
                print(result["answer"])
                print(result.get("chunks", []))

                chemical_metadata_list, not_found_list, _ = chemical_metadata_extractor(result["answer"])
                st.session_state["chemical_metadata_list"] = chemical_metadata_list
                st.session_state["not_found_list"] = not_found_list

                st.rerun()

        if st.button("âœ… Accept & Generate Experiment Detail", key="accept_btn"): #æŒ‰éˆ•ç”Ÿæˆå¯¦é©—ç´°ç¯€
            with st.spinner("ğŸ§ª æ­£åœ¨åˆ†æå¯¦é©—ç´°ç¯€..."):
                chunks = st.session_state.get("proposal_chunks", [])
                proposal = st.session_state["result"]["answer"]
                result = agent_answer(
                    "",  # å•é¡Œä¸é‡è¦ï¼Œçµ¦ç©ºä¹Ÿå¯ä»¥
                    mode="expand to experiment detail",
                    chunks=chunks,
                    proposal=proposal
                )
                st.markdown("### ğŸ”¬ å»ºè­°å¯¦é©—ç´°ç¯€")
                st.markdown(result["answer"])


        # ğŸ“š å¼•ç”¨è³‡æ–™ï¼ˆæ”¯æ´åŸå§‹æˆ–æ”¹å¯«çš†å¯ï¼‰
        st.markdown("### ğŸ“š å¼•ç”¨è³‡æ–™")
        for i, citation in enumerate(st.session_state.get("result", {}).get("citations", []), start=1):
            title = citation.get("title", "æœªçŸ¥")
            page = citation.get("page", "?")
            snippet = citation.get("snippet", "...")
            st.markdown(f"**[{i}]** {title} | é ç¢¼ï¼š{page} | æ®µè½é–‹é ­ï¼š{snippet}")

            

with tab2:
    st.subheader("ğŸ” åŠŸèƒ½ 2ï¼šä½¿ç”¨é—œéµå­—æœå°‹å¤–éƒ¨æ–‡ç»ä¸¦ä¸‹è¼‰ PDF")
    q2 = st.text_area("è«‹è¼¸å…¥æŸ¥è©¢å•é¡Œï¼ˆå°‡è‡ªå‹•èƒå–é—œéµå­—ï¼‰ï¼š", height=100, key="search_pdf")
    if st.button("åŸ·è¡ŒæŸ¥è©¢èˆ‡ä¸‹è¼‰", key="downloadbtn"):
        with st.spinner("ğŸ” æŸ¥è©¢ä¸¦ä¸‹è¼‰ä¸­..."):
            pdfs = search_and_download_only(q2, top_k=5, storage_dir="data/paper")
            if pdfs:
                st.success(f"âœ… å…±ä¸‹è¼‰ {len(pdfs)} ç¯‡ PDF")
                for path in pdfs:
                    st.markdown(f"- `{os.path.basename(path)}`")
            else:
                st.warning("âš ï¸ æœªæˆåŠŸä¸‹è¼‰ä»»ä½• PDF")



with tab3:
    if "processed_files" not in st.session_state:
        st.session_state.processed_files = set()


    file_info = select_files() 
    if file_info:
        file_type = file_info["type"] 
        
        st.markdown(f"ğŸ” è³‡æ–™é¡å‹ï¼š{file_type}")
        for f in file_info["files"]:
            st.write(f"ğŸ“„ {f.name}")

        if file_type == "ğŸ“„ è«–æ–‡è³‡æ–™":
            new_files = [f for f in file_info["files"] if f.name not in st.session_state.processed_files]

            if not new_files:
                st.info("âœ… æ‰€æœ‰æª”æ¡ˆéƒ½å·²è™•ç†éï¼Œä¸é‡è¤‡è™•ç†ã€‚")
            else:
                with st.spinner("ğŸ“¥ è™•ç†è«–æ–‡è³‡æ–™ä¸­..."):
                    new_file_paths = []
                    messages = []

                    def update_status(msg):
                        messages.append(msg)

                    for f in new_files:
                        suffix = os.path.splitext(f.name)[1]
                        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                            tmp.write(f.read())
                            tmp_path = tmp.name
                            new_file_paths.append(tmp_path)
                            st.session_state.processed_files.add(f.name)

                    metadata_list = process_uploaded_files(new_file_paths, status_callback=update_status)
                    embed_documents_from_metadata(metadata_list)

                    if messages:
                        with st.expander("ğŸ“‹ è™•ç†ç´€éŒ„", expanded=True):
                            for m in messages:
                                st.markdown(f"- {m}")

        elif file_type == "ğŸ§ª å¯¦é©—æ•¸æ“š":
            with st.spinner("ğŸ“¥ é–‹å§‹è™•ç†å¯¦é©—è³‡æ–™..."):
                for f in file_info["files"]:  # æ¯æ¬¡éƒ½è™•ç†ï¼Œä¸è·³é
                    temp_path = os.path.join("uploaded", f.name)
                    os.makedirs("uploaded", exist_ok=True)
                    with open(temp_path, "wb") as tmp:
                        tmp.write(f.read())

                    result_df, txt_paths = export_new_experiments_to_txt(
                        excel_path=temp_path,
                        output_dir=EXPERIMENT_DIR
                    )

                    

                embed_experiment_txt_batch(txt_paths)
                st.success(f"âœ… å·²è™•ç†ï¼š{f.name}ï¼Œå…± {len(txt_paths)} ç­†")
                st.dataframe(result_df)


with tab4:
    st.subheader("ğŸŒ åŠŸèƒ½ 4ï¼šä½¿ç”¨ Perplexity æœå°‹æ–‡ç»")
    q4 = st.text_area("è«‹è¼¸å…¥è¦æœå°‹çš„æ–‡ç»å•é¡Œï¼š", height=100, key="search4")
    if st.button("ä½¿ç”¨ Perplexity æœå°‹", key="perplexitybtn"):
        with st.spinner("ä½¿ç”¨ Perplexity æœå°‹ä¸­..."):
            result = ask_perplexity(q4)
            if result["success"]:
                st.markdown("### ğŸ¤– æ–‡ç»æ‘˜è¦")
                st.write(result["answer"])

                st.markdown("### ğŸ”— å¼•ç”¨ä¾†æº")
                links = format_references_block(result["answer"])
                if links:
                    for link in links:
                        st.markdown(f"- {link}")
                else:
                    st.info("æœªåµæ¸¬åˆ°çµæ§‹åŒ– Reference å€å¡Šã€‚")
            else:
                st.error("âŒ æœå°‹å¤±æ•—ï¼š" + result["error"])
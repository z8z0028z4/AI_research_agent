import streamlit as st
from perplexity_search_fallback import ask_perplexity
from search_agent import search_and_download_only
import os
import tempfile
import re
from knowledge_agent import agent_answer, load_experiment_log
from browser import select_files
from file_upload import process_uploaded_files
from chunk_embedding import embed_documents_from_metadata, embed_experiment_txt_batch
import pandas as pd
from excel_to_txt_by_row import export_new_experiments_to_txt
from config import EXPERIMENT_DIR

st.set_page_config(page_title="ç ”ç©¶åŠ©ç†ç³»çµ±", layout="wide")
st.title("ğŸ§ª AI ç ”ç©¶åŠ©ç†ç³»çµ±")

tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ“˜ çŸ¥è­˜åº«åŠ©ç†",
    "ğŸ” æœå°‹å¤–éƒ¨æ–‡ç»ä¸¦ä¸‹è¼‰ PDF",
    "ğŸ“¥ è«–æ–‡/å¯¦é©—è³‡æ–™ä¸Šå‚³",
    "ğŸŒ ä½¿ç”¨ Perplexity æœå°‹"
])

def format_references_block(text):
    refs = []
    in_reference = False
    for line in text.splitlines():
        if line.strip().lower().startswith("reference") or line.strip().lower().startswith("references"):
            in_reference = True
            continue
        if in_reference and line.strip():
            refs.append(line.strip())
    markdown_links = []
    for ref in refs:
        match = re.match(r"\[(\d+)\]\s*(.*?)(https?://\S+)", ref)
        if match:
            idx, title, url = match.groups()
            markdown_links.append(f"[{idx}] [{title.strip()}]({url.strip()})")
        else:
            markdown_links.append(ref)
    return markdown_links

with tab1:
    st.subheader("ğŸ“˜ åŠŸèƒ½ 1ï¼šåˆ©ç”¨çŸ¥è­˜åº«å›ç­”å•é¡Œ")
    st.markdown("### âš™ï¸ é¸æ“‡å›ç­”æ¨¡å¼")
    answer_mode = st.radio(
        "è«‹é¸æ“‡ç³»çµ±å›ç­”å•é¡Œçš„æ–¹å¼ï¼š",
        options=[
            "åƒ…åš´è¬¹æ–‡ç»æº¯æº",
            "å…è¨±å»¶ä¼¸èˆ‡æ¨è«–",
            "ç´å…¥å¯¦é©—è³‡æ–™ï¼Œé€²è¡Œæ¨è«–èˆ‡å»ºè­°"
        ],
        index=0,
        key="mode_selector"
    )

    q1 = st.text_area("è«‹è¼¸å…¥ç ”ç©¶å•é¡Œï¼š", height=100, key="search1")

    if st.button("ç”±çŸ¥è­˜åº«å›ç­”", key="knowledgebtn"):
        with st.spinner("æŸ¥è©¢çŸ¥è­˜åº«ä¸­..."):
            use_inference = answer_mode != "åƒ…åš´è¬¹æ–‡ç»æº¯æº"
            use_experiment = answer_mode == "ç´å…¥å¯¦é©—è³‡æ–™ï¼Œé€²è¡Œæ¨è«–èˆ‡å»ºè­°"
            df = load_experiment_log() if use_experiment else pd.DataFrame()

            result = agent_answer(q1, df, inference=use_inference, use_experiment=use_experiment)

            st.markdown("### ğŸ¤– å›ç­”")
            st.markdown(result["answer"])

            st.markdown("### ğŸ“š å¼•ç”¨è³‡æ–™")
            for i, citation in enumerate(result["citations"], start=1):
                title = citation.get("title", "æœªçŸ¥")
                page = citation.get("page", "?")
                snippet = citation.get("snippet", "...")
                st.markdown(f"**[{i}]** `{title}` | é ç¢¼ï¼š{page} | æ®µè½é–‹é ­ï¼š{snippet}")

with tab2:
    st.subheader("ğŸ” åŠŸèƒ½ 2ï¼šä½¿ç”¨é—œéµå­—æœå°‹å¤–éƒ¨æ–‡ç»ä¸¦ä¸‹è¼‰ PDF")
    q2 = st.text_area("è«‹è¼¸å…¥æŸ¥è©¢å•é¡Œï¼ˆå°‡è‡ªå‹•èƒå–é—œéµå­—ï¼‰ï¼š", height=100, key="search_pdf")
    if st.button("åŸ·è¡ŒæŸ¥è©¢èˆ‡ä¸‹è¼‰", key="downloadbtn"):
        with st.spinner("ğŸ” æŸ¥è©¢ä¸¦ä¸‹è¼‰ä¸­..."):
            pdfs = search_and_download_only(q2, top_k=5, storage_dir="data/chemrxiv")
            if pdfs:
                st.success(f"âœ… å…±ä¸‹è¼‰ {len(pdfs)} ç¯‡ PDF")
                for path in pdfs:
                    st.markdown(f"- `{os.path.basename(path)}`")
            else:
                st.warning("âš ï¸ æœªæˆåŠŸä¸‹è¼‰ä»»ä½• PDF")



with tab3:
    if "processed_files" not in st.session_state:
        st.session_state.processed_files = set()


    file_info = select_files() 
    if file_info:
        file_type = file_info["type"] 
        
        st.markdown(f"ğŸ” è³‡æ–™é¡å‹ï¼š{file_type}")
        for f in file_info["files"]:
            st.write(f"ğŸ“„ {f.name}")

        if file_type == "ğŸ“„ è«–æ–‡è³‡æ–™":
            new_files = [f for f in file_info["files"] if f.name not in st.session_state.processed_files]

            if not new_files:
                st.info("âœ… æ‰€æœ‰æª”æ¡ˆéƒ½å·²è™•ç†éï¼Œä¸é‡è¤‡è™•ç†ã€‚")
            else:
                with st.spinner("ğŸ“¥ è™•ç†è«–æ–‡è³‡æ–™ä¸­..."):
                    new_file_paths = []
                    messages = []

                    def update_status(msg):
                        messages.append(msg)

                    for f in new_files:
                        suffix = os.path.splitext(f.name)[1]
                        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                            tmp.write(f.read())
                            tmp_path = tmp.name
                            new_file_paths.append(tmp_path)
                            st.session_state.processed_files.add(f.name)

                    metadata_list = process_uploaded_files(new_file_paths, status_callback=update_status)
                    embed_documents_from_metadata(metadata_list)

                    if messages:
                        with st.expander("ğŸ“‹ è™•ç†ç´€éŒ„", expanded=True):
                            for m in messages:
                                st.markdown(f"- {m}")

        elif file_type == "ğŸ§ª å¯¦é©—æ•¸æ“š":
            with st.spinner("ğŸ“¥ é–‹å§‹è™•ç†å¯¦é©—è³‡æ–™..."):
                for f in file_info["files"]:  # æ¯æ¬¡éƒ½è™•ç†ï¼Œä¸è·³é
                    temp_path = os.path.join("uploaded", f.name)
                    os.makedirs("uploaded", exist_ok=True)
                    with open(temp_path, "wb") as tmp:
                        tmp.write(f.read())

                    result_df, txt_paths = export_new_experiments_to_txt(
                        excel_path=temp_path,
                        output_dir=EXPERIMENT_DIR
                    )

                    

                embed_experiment_txt_batch(txt_paths)
                st.success(f"âœ… å·²è™•ç†ï¼š{f.name}ï¼Œå…± {len(txt_paths)} ç­†")
                st.dataframe(result_df)


with tab4:
    st.subheader("ğŸŒ åŠŸèƒ½ 4ï¼šä½¿ç”¨ Perplexity æœå°‹æ–‡ç»")
    q4 = st.text_area("è«‹è¼¸å…¥è¦æœå°‹çš„æ–‡ç»å•é¡Œï¼š", height=100, key="search4")
    if st.button("ä½¿ç”¨ Perplexity æœå°‹", key="perplexitybtn"):
        with st.spinner("ä½¿ç”¨ Perplexity æœå°‹ä¸­..."):
            result = ask_perplexity(q4)
            if result["success"]:
                st.markdown("### ğŸ¤– æ–‡ç»æ‘˜è¦")
                st.write(result["answer"])

                st.markdown("### ğŸ”— å¼•ç”¨ä¾†æº")
                links = format_references_block(result["answer"])
                if links:
                    for link in links:
                        st.markdown(f"- {link}")
                else:
                    st.info("æœªåµæ¸¬åˆ°çµæ§‹åŒ– Reference å€å¡Šã€‚")
            else:
                st.error("âŒ æœå°‹å¤±æ•—ï¼š" + result["error"])
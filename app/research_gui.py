import streamlit as st
from perplexity_search_fallback import ask_perplexity
import os
import pandas as pd
import re
from knowledge_agent import agent_answer, load_experiment_log
from config import OPENAI_API_KEY
from browser import select_files  # â† åŠ åœ¨ import å€åŸŸ
from file_upload import process_uploaded_files
import tempfile
from file_upload import process_uploaded_files
from chunk_embedding import embed_documents_from_metadata

def format_references_block(text):
    refs = []
    in_reference = False
    for line in text.splitlines():
        if line.strip().lower().startswith("reference") or line.strip().lower().startswith("references"):
            in_reference = True
            continue
        if in_reference and line.strip():
            refs.append(line.strip())
    markdown_links = []
    for ref in refs:
        match = re.match(r"\[(\d+)\]\s*(.*?)(https?://\S+)", ref)
        if match:
            idx, title, url = match.groups()
            markdown_links.append(f"[{idx}] [{title.strip()}]({url.strip()})")
        else:
            markdown_links.append(ref)
    return markdown_links

st.set_page_config(page_title="ç ”ç©¶åŠ©ç†ç³»çµ±", layout="wide")
st.title("ğŸ§ª AI ç ”ç©¶åŠ©ç†ç³»çµ±")
tab1, tab2, tab3 = st.tabs(["ğŸ“˜ çŸ¥è­˜åº«åŠ©ç†", "ğŸ” æœå°‹å¤–éƒ¨æ–‡ç»", "ğŸ“¥ è«–æ–‡/å¯¦é©—è³‡æ–™ä¸Šå‚³"])

with tab1:
    st.subheader("ğŸ“˜ åŠŸèƒ½ 1ï¼šåˆ©ç”¨çŸ¥è­˜åº«å›ç­”å•é¡Œ")
    q1 = st.text_area("è«‹è¼¸å…¥ç ”ç©¶å•é¡Œï¼š", height=100, key="search1")

    if st.button("ç”±çŸ¥è­˜åº«å›ç­”", key="knowledgebtn"):
        with st.spinner("æŸ¥è©¢çŸ¥è­˜åº«ä¸­..."):
            df = load_experiment_log()
            result = agent_answer(q1, df)

            # é¡¯ç¤ºå›ç­”å€
            st.markdown("### ğŸ¤– å›ç­”")
            st.markdown(result["answer"])

            # é¡¯ç¤ºå¼•ç”¨å€
            st.markdown("### ğŸ“š å¼•ç”¨è³‡æ–™")
            for i, citation in enumerate(result["citations"], start=1):
                title = citation.get("title", "æœªçŸ¥")
                page = citation.get("page", "?")
                snippet = citation.get("snippet", "...")

                st.markdown(f"**[{i}]** `{title}` | é ç¢¼ï¼š{page} | æ®µè½é–‹é ­ï¼š\"{snippet}\"")


with tab2:
    st.subheader("ğŸ” åŠŸèƒ½ 2ï¼šä½¿ç”¨ Perplexity æœå°‹æ–‡ç»")
    q2 = st.text_area("è«‹è¼¸å…¥è¦æœå°‹çš„æ–‡ç»å•é¡Œï¼š", height=100, key="search2")
    if st.button("æœå°‹æ–‡ç»", key="searchbtn"):
        with st.spinner("ä½¿ç”¨ Perplexity æœå°‹ä¸­..."):
            result = ask_perplexity(q2)
            if result["success"]:
                st.markdown("### ğŸ¤– æ–‡ç»æ‘˜è¦")
                st.write(result["answer"])

                st.markdown("### ğŸ”— å¼•ç”¨ä¾†æº")
                links = format_references_block(result["answer"])
                if links:
                    for link in links:
                        st.markdown(f"- {link}")
                else:
                    st.info("æœªåµæ¸¬åˆ°çµæ§‹åŒ– Reference å€å¡Šã€‚")
            else:
                st.error("âŒ æœå°‹å¤±æ•—ï¼š" + result["error"])

if "processed_files" not in st.session_state:
    st.session_state.processed_files = set()

with tab3:
    file_info = select_files()
    if file_info:
        st.markdown(f"ğŸ” è³‡æ–™é¡å‹ï¼š{file_info['type']}")
        for f in file_info["files"]:
            st.write(f"ğŸ“„ {f.name}")

        # ğŸ§  éæ¿¾æ‰å·²è™•ç†çš„æª”æ¡ˆï¼ˆä¾æª”åï¼‰
        new_streamlit_files = [f for f in file_info["files"] if f.name not in st.session_state.processed_files]

        if new_streamlit_files:
            new_file_paths = []
            messages = []

            with st.spinner("ğŸ“¥ è™•ç†ä¸Šå‚³çš„è³‡æ–™ä¸­..."):
                def update_status(msg):
                    messages.append(msg)

                # å°‡ UploadedFile å¯«å…¥æš«å­˜æª”ï¼Œå–å¾—å¯¦éš›è·¯å¾‘
                for f in new_streamlit_files:
                    suffix = os.path.splitext(f.name)[1]
                    with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                        tmp.write(f.read())
                        tmp_path = tmp.name
                        new_file_paths.append(tmp_path)
                        st.session_state.processed_files.add(f.name)  # âœ… åƒ…è¨˜éŒ„æª”åé¿å…é‡è¤‡

                # é–‹å§‹è™•ç†è³‡æ–™
                metadata_list = process_uploaded_files(new_file_paths, status_callback=update_status)
                print("ğŸ§¾ æœ¬æ¬¡è™•ç†æª”æ¡ˆï¼š", new_file_paths)
                embed_documents_from_metadata(metadata_list)

            if messages:
                with st.expander("ğŸ“‹ è™•ç†ç´€éŒ„", expanded=True):
                    for m in messages:
                        st.markdown(f"- {m}")
        else:
            st.info("âœ… æ‰€æœ‰æª”æ¡ˆéƒ½å·²è™•ç†éï¼Œä¸é‡è¤‡è™•ç†ã€‚")
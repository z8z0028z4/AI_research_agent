"""
æ¨¡å‹é…ç½®æ©‹æ¥æ¨¡çµ„
==============

æ©‹æ¥appç›®éŒ„å’Œbackendç›®éŒ„çš„æ¨¡å‹é…ç½®
åŸºæ–¼GPT-5å®˜æ–¹cookbookçš„æœ€æ–°åƒæ•¸æ”¯æ´
"""

import os
import sys
from typing import Dict, Any

# æ·»åŠ backendç›®éŒ„åˆ°Pythonè·¯å¾‘
backend_path = os.path.join(os.path.dirname(__file__), "..", "backend")
if backend_path not in sys.path:
    sys.path.insert(0, backend_path)

try:
    from core.settings_manager import settings_manager
    from model_parameter_detector import adapt_parameters, detect_model_parameters
    
    def get_current_model():
        """ç²å–ç•¶å‰æ¨¡å‹åç¨±"""
        return settings_manager.get_current_model()
    
    def get_model_params(model_name=None):
        """ç²å–æ¨¡å‹åƒæ•¸"""
        if model_name is None:
            model_name = get_current_model()
        
        # å¾è¨­å®šç®¡ç†å™¨ç²å–å‹•æ…‹åƒæ•¸
        llm_params = settings_manager.get_llm_parameters()
        
        # ä½¿ç”¨æ–°çš„åƒæ•¸é©é…å™¨
        try:
            adapted_params = adapt_parameters(model_name, llm_params)
            print(f"ğŸ”§ æ¨¡å‹åƒæ•¸é©é…å®Œæˆ: {adapted_params}")
            return adapted_params
        except Exception as e:
            print(f"âš ï¸ åƒæ•¸é©é…å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤åƒæ•¸: {e}")
            # å¦‚æœé©é…å¤±æ•—ï¼Œä½¿ç”¨åŸºç¤åƒæ•¸
            return {
                "model": model_name,
                "max_tokens": llm_params.get("max_tokens", 2000),
                "timeout": llm_params.get("timeout", 60),
            }
    
    def get_model_supported_parameters(model_name: str = None) -> Dict[str, Any]:
        """
        ç²å–æŒ‡å®šæ¨¡å‹æ”¯æ´çš„åƒæ•¸è³‡è¨Š
        
        Args:
            model_name: æ¨¡å‹åç¨±ï¼Œå¦‚æœç‚ºNoneå‰‡ä½¿ç”¨ç•¶å‰æ¨¡å‹
            
        Returns:
            åŒ…å«æ”¯æ´åƒæ•¸è³‡è¨Šçš„å­—å…¸
        """
        if model_name is None:
            model_name = get_current_model()
        
        try:
            # ä½¿ç”¨æ–°çš„åƒæ•¸æª¢æ¸¬å™¨
            model_info = detect_model_parameters(model_name)
            return model_info['supported_parameters']
        except Exception as e:
            print(f"âš ï¸ ç„¡æ³•æª¢æ¸¬æ¨¡å‹åƒæ•¸ï¼Œä½¿ç”¨é è¨­é…ç½®: {e}")
            # å¦‚æœæª¢æ¸¬å¤±æ•—ï¼Œä½¿ç”¨é è¨­é…ç½®
            base_params = {
                'max_tokens': {'type': 'int', 'range': [1, 32000], 'default': 2000},
                'timeout': {'type': 'int', 'range': [10, 600], 'default': 60}
            }
            
            if model_name.startswith('gpt-5'):
                base_params.update({
                    'reasoning_effort': {
                        'type': 'select', 
                        'options': ['minimal', 'low', 'medium', 'high'], 
                        'default': 'medium'
                    },
                    'verbosity': {
                        'type': 'select', 
                        'options': ['low', 'medium', 'high'], 
                        'default': 'medium'
                    }
                })
            
            return base_params
    
    def is_model_available(model_name):
        """æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨"""
        valid_models = [
            "gpt-5",
            "gpt-5-nano",
            "gpt-5-mini"
        ]
        return model_name in valid_models

except ImportError as e:
    print(f"è­¦å‘Šï¼šç„¡æ³•å°å…¥backendè¨­å®šæ¨¡çµ„: {e}")
    # æä¾›fallbacké…ç½®
    def get_current_model():
        return "gpt-5-mini"
    
    def get_model_params(model_name=None):
        if model_name is None:
            model_name = get_current_model()
        return {
            "model": model_name,
            "max_tokens": 4000,
            "timeout": 120,
        }
    
    def get_model_supported_parameters(model_name: str = None) -> Dict[str, Any]:
        """ç²å–æ¨¡å‹æ”¯æ´çš„åƒæ•¸ï¼ˆfallbackç‰ˆæœ¬ï¼‰"""
        if model_name is None:
            model_name = get_current_model()
        
        base_params = {
            'max_tokens': {'type': 'int', 'range': [1, 32000], 'default': 2000},
            'timeout': {'type': 'int', 'range': [10, 600], 'default': 60}
        }
        
        if model_name.startswith('gpt-5'):
            base_params.update({
                'reasoning_effort': {
                    'type': 'select', 
                    'options': ['minimal', 'low', 'medium', 'high'], 
                    'default': 'medium'
                },
                'verbosity': {
                    'type': 'select', 
                    'options': ['low', 'medium', 'high'], 
                    'default': 'medium'
                }
            })
        
        return base_params
    
    def is_model_available(model_name):
        valid_models = [
            "gpt-5",
            "gpt-5-nano",
            "gpt-5-mini"
        ]
        return model_name in valid_models

# ç‚ºäº†å‘å¾Œå…¼å®¹ï¼Œæä¾›èˆŠçš„é…ç½®æ¥å£
def get_llm_params():
    """ç²å–LLMåƒæ•¸ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    return get_model_params()

def get_llm_model_name():
    """ç²å–LLMæ¨¡å‹åç¨±ï¼ˆå‘å¾Œå…¼å®¹ï¼‰"""
    return get_current_model() 
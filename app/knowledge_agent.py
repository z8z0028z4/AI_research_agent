
import os
import pandas as pd
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from config import OPENAI_API_KEY, VECTOR_INDEX_DIR, EXPERIMENT_CSV_DIR
from sentence_transformers import SentenceTransformer
from langchain.embeddings import HuggingFaceEmbeddings

def load_experiment_log():
    if not os.path.exists(EXPERIMENT_CSV_DIR):
        return pd.DataFrame()
    csv_files = [f for f in os.listdir(EXPERIMENT_CSV_DIR) if f.endswith(".csv")]
    dfs = []
    for file in csv_files:
        try:
            df = pd.read_csv(os.path.join(EXPERIMENT_CSV_DIR, file))
            dfs.append(df)
        except:
            continue
    if dfs:
        return pd.concat(dfs, ignore_index=True)
    return pd.DataFrame()

def agent_answer(question: str, df: pd.DataFrame):
    embedding_model = HuggingFaceEmbeddings(
    model_name="nomic-ai/nomic-embed-text-v1.5",
    model_kwargs={"trust_remote_code": True}
    )

    vectorstore = Chroma(
    persist_directory=VECTOR_INDEX_DIR,
    embedding_function=embedding_model,
    collection_name="default"
    )

    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={
            "k": 10, #å¢åŠ  context è¦†è“‹ç‡
            "fetch_k": 30, #æé«˜ MMR çš„åˆé¸å€™è£œæ•¸é‡
            "score_threshold": 0.35  # å–æ±ºæ–¼ä½  embedding scaleï¼Œå¯å¾®èª¿
        }
    )
    context_docs = retriever.get_relevant_documents(question)
    
    if not context_docs:
        print("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•æ®µè½ï¼Œå»ºè­°æª¢æŸ¥ retriever æˆ–åµŒå…¥æ ¼å¼")

    print("ğŸ” Retriever æŠ“åˆ°çš„æ®µè½ï¼š")
    for i, doc in enumerate(context_docs, 1):
        print(f"\n--- Chunk {i} ---")
        print(f"ğŸ“„ {doc.metadata.get('title')} | Page {doc.metadata.get('page_number')}")
        print(doc.page_content[:500])  # å‰ 500 å­—é è¦½

    # å»ºç«‹ citation map
    citations = []
    citation_map = {}
    for i, doc in enumerate(context_docs):
        label = f"[{i+1}]"
        snippet = " ".join(doc.page_content.strip().split()[:5]) + "..."
        citation = {
            "label": label,
            "title": doc.metadata.get("title", "æœªçŸ¥"),
            "page": doc.metadata.get("page_number", "?"),
            "snippet": snippet
        }
        citations.append(citation)
        citation_map[id(doc)] = label

    # æ’å…¥è¿½è¹¤è³‡è¨Š + snippet
    context = "\n---\n".join(
        f"{citation_map[id(doc)]} [ä¾†æº: {doc.metadata.get('title', '')} | é ç¢¼: {doc.metadata.get('page_number')} | æ®µè½é–‹é ­: \"{' '.join(doc.page_content.strip().split()[:5])}...\"]\n{doc.page_content}"
        for doc in context_docs
    )

    past_exp = df.head(10).to_string(index=False) if not df.empty else "ï¼ˆç„¡ç´€éŒ„ï¼‰"


    system_prompt = f"""
    You are a scientific research assistant. Answer rigorously and only based on the provided documents and experimental records.
    You must cite sources in your response using numbered references (e.g., [1], [2]). Do not list the sources again at the end.

    If available, include specific experimental conditions (e.g., temperature, time, concentration) in your answer to enhance credibility.
    è«‹ä»¥å°ˆæ¥­åŠ©ç†çš„èº«ä»½ä½œç­”ï¼Œåƒ…æ ¹æ“šä¸‹åˆ—æ–‡ç»å…§å®¹èˆ‡ç´€éŒ„å›ç­”ã€‚è«‹åœ¨å›ç­”ä¸­ä½¿ç”¨ [1], [2] ç·¨è™Ÿæ¨™è¨»å‡ºè™•ï¼Œä¸è¦é¡å¤–åˆ—å‡ºä¾†æºã€‚
    å¦‚æ–‡ä¸­æœ‰æåŠï¼Œè«‹å‹™å¿…åŠ å…¥å…·é«”å¯¦é©—æ¢ä»¶ï¼ˆä¾‹å¦‚ï¼šæº«åº¦ã€æ™‚é–“ã€æ¿ƒåº¦ç­‰ï¼‰ä»¥æå‡ç­”æ¡ˆå¯ä¿¡åº¦èˆ‡å®Œæ•´æ€§ã€‚

    --- æ–‡ç»æ‘˜è¦ ---
    {context}

    --- å¯¦é©—ç´€éŒ„ ---
    {past_exp}

    --- å•é¡Œ ---
    {question}
        """


    #llm = ChatOpenAI(model="gpt-4")
    llm = ChatOpenAI(model_name="gpt-4-1106-preview", temperature=0)
    response = llm.predict(system_prompt)
    return {
        "answer": response,
        "citations": citations
    }

import pandas as pd
from rag_core import load_paper_vectorstore, load_experiment_vectorstore, preview_chunks, retrieve_chunks_multi_query, build_prompt, call_llm, build_inference_prompt, build_dual_inference_prompt, expand_query
from config import EXPERIMENT_DIR
import os


def agent_answer(question: str, df: pd.DataFrame, inference=False, use_experiment=False):
    
    if use_experiment:
        print("ğŸ§ª å•Ÿç”¨æ¨¡å¼ï¼šç´å…¥å¯¦é©—è³‡æ–™ + æ¨è«–")
        # ğŸ§  Dual retriever å•Ÿç”¨
        paper_vectorstore = load_paper_vectorstore()  # æ–‡ç»å‘é‡åº«
        experiment_vectorstore = load_experiment_vectorstore()  # å¯¦é©—å‘é‡åº«
        print("ğŸ“¦ Paper å‘é‡åº«ï¼š", paper_vectorstore._collection.count())
        print("ğŸ“¦ Experiment å‘é‡åº«ï¼š", experiment_vectorstore._collection.count())

        # ğŸ” èªæ„æ‹“å±•
        query_list = expand_query(question) #çµ¦ chunks_paperçš„èªæ„æ‹“å±•ç”¨
        #çµ¦ chunks_experimentçš„èªæ„æ‹“å±•ç”¨

        # åˆ†åˆ¥å¬å›
        chunks_paper = retrieve_chunks_multi_query(paper_vectorstore, query_list, k=5)
        chunks_experiment = retrieve_chunks_multi_query(experiment_vectorstore, [question], k=5) #question å•ï¼Œèªæ„æœªæ‹“å±•
        preview_chunks(chunks_paper, title="æ–‡ç»å‘é‡åº«")
        preview_chunks(chunks_experiment, title="å¯¦é©—å‘é‡åº«")

        # ğŸ§  åˆä½µé¤µå…¥ dual prompt injection
        prompt, citations = build_dual_inference_prompt(
            chunks_paper, df, question, experiment_chunks=chunks_experiment
        )

    else:
        # ä¸€èˆ¬æ¨¡å¼ä½¿ç”¨å–®ä¸€ retriever
        paper_vectorstore = load_paper_vectorstore()
        chunks = retrieve_chunks_multi_query(paper_vectorstore, [question])
        print("ğŸ“¦ Paper å‘é‡åº«ï¼š", paper_vectorstore._collection.count())

        if inference:
            
            print("ğŸ§  å•Ÿç”¨æ¨¡å¼ï¼šæ¨è«–æ¨¡å¼ï¼ˆä¸ç´å…¥å¯¦é©—è³‡æ–™ï¼‰")
            prompt, citations = build_inference_prompt(chunks, df, [question])
        else:
            print("ğŸ“š å•Ÿç”¨æ¨¡å¼ï¼šåš´è¬¹æ¨¡å¼ï¼ˆåƒ…æ–‡ç»ï¼Œç„¡æ¨è«–ï¼‰")
            prompt, citations = build_prompt(chunks, df, [question])

    response = call_llm(prompt)

    return {
        "answer": response,
        "citations": citations
    }
    
    
    
    
    vectorstore = load_paper_vectorstore()
    if use_experiment:
        # âœ… å•Ÿç”¨èªæ„æ‹“å±•åš multi-query search
        query_list = expand_query(question)
        chunks = retrieve_chunks(vectorstore, query_list)
    else:
        # âœ… ä¸€èˆ¬åš´è¬¹ / æ¨è«–æ¨¡å¼ï¼Œç›´æ¥æŸ¥åŸå§‹ question
        chunks = retrieve_chunks(vectorstore, question)

    # æ ¹æ“šæ¨¡å¼åˆ‡æ›ä¸åŒ prompt injection
    if inference and use_experiment:
        queries = expand_query(question)
        chunks = retrieve_chunks(vectorstore, queries)
        prompt, citations = build_dual_inference_prompt(chunks, df, question)  # ç´å…¥å¯¦é©—è³‡æ–™æ¨¡å¼
    elif inference:
        prompt, citations = build_inference_prompt(chunks, df, question) #æ¨è«–æ¨¡å¼
    else:
        prompt, citations = build_prompt(chunks, df, question) #åš´è¬¹æ¨¡å¼

    response = call_llm(prompt)

    return {
        "answer": response,
        "citations": citations
    }


def load_experiment_log(): ##########################################
    if not os.path.exists(EXPERIMENT_DIR):
        return pd.DataFrame()
    csv_files = [f for f in os.listdir(EXPERIMENT_DIR) if f.endswith(".csv")]
    dfs = []
    for file in csv_files:
        try:
            df = pd.read_csv(os.path.join(EXPERIMENT_DIR, file))
            dfs.append(df)
        except:
            continue
    if dfs:
        df_all = pd.concat(dfs, ignore_index=True)
        print(f"[DEBUG] å¯¦é©—è³‡æ–™ç¸½åˆ—æ•¸ï¼š{df_all.shape[0]}, æ¬„ä½æ•¸ï¼š{df_all.shape[1]}")
        print(f"[DEBUG] å°‡è¼¸å…¥ prompt çš„ dataframe é è¦½ï¼š\n{df_all.head(5)}")
        return df_all

    return pd.DataFrame()
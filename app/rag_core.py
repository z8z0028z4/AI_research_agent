"""
AI ç ”ç©¶åŠ©ç† - RAGæ ¸å¿ƒæ¨¡å¡Š
========================

é€™å€‹æ¨¡å¡Šæ˜¯æ•´å€‹ç³»çµ±çš„RAGï¼ˆæª¢ç´¢å¢å¼·ç”Ÿæˆï¼‰æ ¸å¿ƒï¼Œè² è²¬ï¼š
1. å‘é‡æ•¸æ“šåº«ç®¡ç†
2. æ–‡æª”æª¢ç´¢å’Œç›¸ä¼¼åº¦æœç´¢
3. æç¤ºè©æ§‹å»ºå’Œå„ªåŒ–
4. LLMèª¿ç”¨å’Œå›ç­”ç”Ÿæˆ

æ¶æ§‹èªªæ˜ï¼š
- ä½¿ç”¨Chromaä½œç‚ºå‘é‡æ•¸æ“šåº«
- æ”¯æŒå¤šæŸ¥è©¢æª¢ç´¢
- æä¾›å¤šç¨®æç¤ºè©æ¨¡æ¿
- é›†æˆOpenAI GPTæ¨¡å‹

âš ï¸ æ³¨æ„ï¼šæ­¤æ¨¡å¡Šæ˜¯ç³»çµ±çš„æ ¸å¿ƒçµ„ä»¶ï¼Œæ‰€æœ‰çŸ¥è­˜è™•ç†éƒ½ä¾è³´æ–¼æ­¤æ¨¡å¡Š
"""

from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain.chat_models import ChatOpenAI
from config import VECTOR_INDEX_DIR, EMBEDDING_MODEL_NAME, LLM_MODEL_NAME
import pandas as pd
from typing import List, Tuple, Dict
import os
from collections import defaultdict

# Embedding model configuration

# ==================== å‘é‡æ•¸æ“šåº«ç®¡ç† ====================

def load_paper_vectorstore():
    """
    è¼‰å…¥æ–‡ç»å‘é‡æ•¸æ“šåº«
    
    åŠŸèƒ½ï¼š
    1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    2. é€£æ¥æ–‡ç»å‘é‡å­˜å„²
    3. è¿”å›å¯ç”¨çš„å‘é‡æ•¸æ“šåº«å°è±¡
    
    è¿”å›ï¼š
        Chroma: æ–‡ç»å‘é‡æ•¸æ“šåº«å°è±¡
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨HuggingFaceåµŒå…¥æ¨¡å‹
    - æŒä¹…åŒ–å­˜å„²åœ¨paper_vectorç›®éŒ„
    - é›†åˆåç¨±ç‚º"paper"
    """
    # Load Nomic embedding model
    try:
        print(f"ğŸ”§ Loading Nomic embedding model: {EMBEDDING_MODEL_NAME}")
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"trust_remote_code": True},
            encode_kwargs={"normalize_embeddings": True}
        )
        print("âœ… Nomic embedding model loaded successfully")
    except Exception as e:
        print(f"âŒ Nomic embedding failed: {e}")
        raise e
    
    paper_vector_dir = os.path.join(VECTOR_INDEX_DIR, "paper_vector")
    vectorstore = Chroma(
        persist_directory=paper_vector_dir,
        embedding_function=embedding_model, 
        collection_name="paper"
        )
    return vectorstore


def load_experiment_vectorstore():
    """
    è¼‰å…¥å¯¦é©—æ•¸æ“šå‘é‡æ•¸æ“šåº«
    
    åŠŸèƒ½ï¼š
    1. åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
    2. é€£æ¥å¯¦é©—æ•¸æ“šå‘é‡å­˜å„²
    3. è¿”å›å¯ç”¨çš„å‘é‡æ•¸æ“šåº«å°è±¡
    
    è¿”å›ï¼š
        Chroma: å¯¦é©—æ•¸æ“šå‘é‡æ•¸æ“šåº«å°è±¡
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹ç¢ºä¿ä¸€è‡´æ€§
    - æŒä¹…åŒ–å­˜å„²åœ¨experiment_vectorç›®éŒ„
    - é›†åˆåç¨±ç‚º"experiment"
    """
    # Load Nomic embedding model
    try:
        print(f"ğŸ”§ Loading Nomic embedding model: {EMBEDDING_MODEL_NAME}")
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"trust_remote_code": True},
            encode_kwargs={"normalize_embeddings": True}
        )
        print("âœ… Nomic embedding model loaded successfully")
    except Exception as e:
        print(f"âŒ Nomic embedding failed: {e}")
        raise e
    experiment_vector_dir = os.path.join(VECTOR_INDEX_DIR, "experiment_vector")
    vectorstore = Chroma(
        persist_directory=experiment_vector_dir, 
        embedding_function=embedding_model, 
        collection_name="experiment"
        )
    return vectorstore


# ==================== æ–‡æª”æª¢ç´¢åŠŸèƒ½ ====================

def retrieve_chunks_multi_query(
    vectorstore, query_list: List[str], k: int = 10, fetch_k: int = 20, score_threshold: float = 0.35
    ) -> List[Document]:
    """
    å¤šæŸ¥è©¢æ–‡æª”æª¢ç´¢åŠŸèƒ½
    
    åŠŸèƒ½ï¼š
    1. å°å¤šå€‹æŸ¥è©¢é€²è¡Œä¸¦è¡Œæª¢ç´¢
    2. å»é‡å’Œæ’åºæª¢ç´¢çµæœ
    3. æä¾›è©³ç´°çš„æª¢ç´¢çµ±è¨ˆä¿¡æ¯
    
    åƒæ•¸ï¼š
        vectorstore: å‘é‡æ•¸æ“šåº«å°è±¡
        query_list (List[str]): æŸ¥è©¢åˆ—è¡¨
        k (int): è¿”å›çš„æ–‡æª”æ•¸é‡
        fetch_k (int): åˆå§‹æª¢ç´¢çš„æ–‡æª”æ•¸é‡
        score_threshold (float): ç›¸ä¼¼åº¦é–¾å€¼
    
    è¿”å›ï¼š
        List[Document]: æª¢ç´¢åˆ°çš„æ–‡æª”åˆ—è¡¨
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨MMRï¼ˆæœ€å¤§é‚Šéš›ç›¸é—œæ€§ï¼‰æœç´¢
    - è‡ªå‹•å»é‡é¿å…é‡è¤‡å…§å®¹
    - æä¾›è©³ç´°çš„æª¢ç´¢æ—¥èªŒ
    """
    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": k, "fetch_k": fetch_k, "score_threshold": score_threshold}
    )

    # ä½¿ç”¨å­—å…¸é€²è¡Œå»é‡
    chunk_dict = defaultdict(float)
    print("ğŸ” æŸ¥è©¢åˆ—è¡¨ï¼š", query_list)
    
    # å°æ¯å€‹æŸ¥è©¢é€²è¡Œæª¢ç´¢
    for q in query_list:
        docs = retriever.get_relevant_documents(q)
        for doc in docs:
            # ä½¿ç”¨å”¯ä¸€æ¨™è­˜ç¬¦é€²è¡Œå»é‡
            key = doc.metadata.get("exp_id") or doc.metadata.get("source") or doc.page_content[:30]
            chunk_dict[key] = doc
    
    # é™åˆ¶è¿”å›çµæœæ•¸é‡ï¼Œä½¿ç”¨å‚³å…¥çš„ k åƒæ•¸
    result = list(chunk_dict.values())[:k]

    # æª¢ç´¢çµæœé©—è­‰
    if not result:
        print("âš ï¸ æ²’æœ‰æª¢ç´¢åˆ°ä»»ä½•æ–‡æª”ï¼Œå»ºè­°æª¢æŸ¥æª¢ç´¢å™¨æˆ–åµŒå…¥æ ¼å¼")
    else:
        print(f"ğŸ” å¤šæŸ¥è©¢æª¢ç´¢å…±æ‰¾åˆ° {len(result)} å€‹æ–‡æª”ï¼š")
        print("ğŸ” æª¢ç´¢åˆ°çš„æ–‡æª”é è¦½ï¼š")
        for i, doc in enumerate(result[:5], 1):
            meta = doc.metadata
            filename = meta.get("filename") or meta.get("source", "Unknown")
            page = meta.get("page_number") or meta.get("page", "?")
            preview = doc.page_content[:80].replace("\n", " ")
            print(f"--- æ–‡æª” {i} ---")
            print(f"ğŸ“„ {filename} | é ç¢¼ {page}")
            print(f"ğŸ“ å…§å®¹é è¦½ï¼š{preview}")
            print()

    return result


def preview_chunks(chunks: List[Document], title: str, max_preview: int = 5):
    """
    é è¦½æ–‡æª”å¡Šå…§å®¹
    
    åŠŸèƒ½ï¼š
    1. é¡¯ç¤ºæ–‡æª”å¡Šçš„åŸºæœ¬ä¿¡æ¯
    2. æä¾›å…§å®¹é è¦½
    3. å¹«åŠ©èª¿è©¦å’Œé©—è­‰æª¢ç´¢çµæœ
    
    åƒæ•¸ï¼š
        chunks (List[Document]): æ–‡æª”å¡Šåˆ—è¡¨
        title (str): é è¦½æ¨™é¡Œ
        max_preview (int): æœ€å¤§é è¦½æ•¸é‡
    """
    print(f"\nğŸ“¦ã€{title}ã€‘å…±æ‰¾åˆ° {len(chunks)} å€‹æ–‡æª”å¡Š")

    if not chunks:
        print("âš ï¸ æ²’æœ‰ä»»ä½•æ®µè½å¯é¡¯ç¤ºã€‚")
        return

    # é¡¯ç¤ºå‰å¹¾å€‹æ–‡æª”å¡Šçš„è©³ç´°ä¿¡æ¯
    for i, doc in enumerate(chunks[:max_preview], 1):
        meta = doc.metadata
        filename = meta.get("filename") or meta.get("source", "Unknown")
        page = meta.get("page_number") or meta.get("page", "?")
        preview = doc.page_content[:100].replace("\n", " ")
        print(f"--- Chunk {i} ---")
        print(f"ğŸ“„ Filename: {filename} | Page: {page}")
        print(f"ğŸ“š Preview: {preview}")


# ==================== æç¤ºè©æ§‹å»ºåŠŸèƒ½ ====================

def build_prompt(chunks: List[Document], question: str) -> Tuple[str, List[Dict]]:
    # æª¢æŸ¥ï¼šchunks å¿…é ˆæ˜¯ List[Document]ï¼Œquestion æ‡‰ç‚º str
    context_text = ""
    citations = []
    citation_map = {}
    
    for i, doc in enumerate(chunks):
        # æª¢æŸ¥ï¼šdoc æ‡‰æœ‰ metadata å±¬æ€§ï¼Œä¸”ç‚º dict
        metadata = doc.metadata
        title = metadata.get("title", "Untitled")
        # æª¢æŸ¥ï¼šfilename ä¾†æºæ–¼ "filename" æˆ– "source"ï¼Œè‹¥éƒ½ç„¡å‰‡ç‚º "Unknown"
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        # æª¢æŸ¥ï¼špage ä¾†æºæ–¼ "page_number" æˆ– "page"ï¼Œè‹¥éƒ½ç„¡å‰‡ç‚º "?"
        page = metadata.get("page_number") or metadata.get("page", "?")
        # é è¦½ç‰‡æ®µï¼Œå–å‰ 80 å­—å…ƒï¼Œä¸¦å°‡æ›è¡Œæ›¿æ›ç‚ºç©ºæ ¼
        snippet = doc.page_content[:80].replace("\n", " ")

        # æª¢æŸ¥ï¼šé¿å…é‡è¤‡çš„ (filename, page) çµ„åˆ
        citation_key = f"{filename}_p{page}"
        if citation_key not in citation_map:
            label = f"[{len(citations) + 1}]"
            citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })
            citation_map[citation_key] = label
        else:
            label = citation_map[citation_key]

        # context_text ç´¯åŠ æ¯å€‹ chunk çš„å…§å®¹ï¼Œæ ¼å¼ç‚º [n] title | Page n
        context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    # system_prompt is the final prompt containing context_text and question
    system_prompt = f"""

    You are a research literature search assistant. Please answer questions based only on the provided literature excerpts.
    Please use [1], [2], etc. to cite paragraph sources in your answers, and do not repeat the sources at the end.
    If the paragraphs mention specific experimental conditions (temperature, time, etc.), please be sure to include them in your answer.
    Important: You can only cite the provided literature excerpts. The current literature excerpt numbers are [1] to [{len(chunks)}] (total {len(chunks)} excerpts)

    --- Literature Summary ---
    {context_text}


    --- Question ---
    {question}
    """
    # Check: return system_prompt with trimmed whitespace and citations list
    return system_prompt.strip(), citations


def call_llm(prompt: str) -> str:
    print(f"ğŸ” èª¿ç”¨ LLMï¼Œæç¤ºè©é•·åº¦ï¼š{len(prompt)} å­—ç¬¦")
    print(f"ğŸ” DEBUG: prompt é¡å‹: {type(prompt)}")
    print(f"ğŸ” DEBUG: prompt å‰100å­—ç¬¦: {prompt[:100]}...")
    
    # ç²å–ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹ä¿¡æ¯å’Œåƒæ•¸
    try:
        from model_config_bridge import get_current_model, get_model_params
        current_model = get_current_model()
        llm_params = get_model_params()
        print(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹ï¼š{current_model}")
        print(f"ğŸ”§ æ¨¡å‹åƒæ•¸ï¼š{llm_params}")
        print(f"ğŸ” DEBUG: current_model é¡å‹: {type(current_model)}")
        print(f"ğŸ” DEBUG: current_model.startswith('gpt-5'): {current_model.startswith('gpt-5')}")
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–æ¨¡å‹ä¿¡æ¯ï¼š{e}")
        # ä½¿ç”¨fallbacké…ç½®
        llm_params = {
            "model": "gpt-4-1106-preview",
            "temperature": 0.3,
            "max_tokens": 4000,
            "timeout": 120,
        }
    
    try:
        # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡ä¸åŒçš„API
        if current_model.startswith('gpt-5'):
            # GPT-5ç³»åˆ—ä½¿ç”¨Responses API
            from openai import OpenAI
            client = OpenAI()
            
            # æº–å‚™Responses APIçš„åƒæ•¸
            # å°æ–¼è¤‡é›œçš„proposal promptï¼Œä½¿ç”¨æ›´é«˜çš„tokené™åˆ¶
            base_max_tokens = llm_params.get('max_output_tokens', 2000)
            if len(prompt) > 1000:  # è¤‡é›œprompt
                max_tokens = max(base_max_tokens, 8000)  # å¤§å¹…æé«˜åˆ°8000 tokens
                print(f"ğŸ”§ æª¢æ¸¬åˆ°è¤‡é›œpromptï¼Œå¤§å¹…æé«˜max_output_tokensåˆ°: {max_tokens}")
            else:
                max_tokens = base_max_tokens
            
            responses_params = {
                'model': current_model,
                'input': [{'role': 'user', 'content': prompt}],
                'max_output_tokens': max_tokens
            }
            
            # æ·»åŠ å…¶ä»–åƒæ•¸ï¼ˆæ’é™¤modelã€inputå’Œmax_output_tokensï¼‰
            for key, value in llm_params.items():
                if key not in ['model', 'input', 'max_output_tokens']:
                    responses_params[key] = value
            
            print(f"ğŸ”§ ä½¿ç”¨Responses APIï¼Œåƒæ•¸ï¼š{responses_params}")
            print(f"ğŸ” DEBUG: æº–å‚™èª¿ç”¨ client.responses.create")
            

            
            # è™•ç†GPT-5çš„incompleteç‹€æ…‹
            max_retries = 3
            retry_count = 0
            
            while retry_count < max_retries:
                response = client.responses.create(**responses_params)
                
                print(f"ğŸ” DEBUG: APIèª¿ç”¨å®Œæˆ (å˜—è©¦ {retry_count + 1}/{max_retries})")
                print(f"ğŸ” DEBUG: response é¡å‹: {type(response)}")
                print(f"ğŸ” DEBUG: response.status: {getattr(response, 'status', 'N/A')}")
                
                # æª¢æŸ¥æ•´é«”responseç‹€æ…‹
                if hasattr(response, 'status') and response.status == 'incomplete':
                    print(f"âš ï¸ æª¢æ¸¬åˆ°incompleteç‹€æ…‹ï¼Œç­‰å¾…å¾Œé‡è©¦...")
                    print(f"ğŸ’¡ æç¤ºï¼šå¦‚æœæŒçºŒé‡åˆ°incompleteç‹€æ…‹ï¼Œå»ºè­°åœ¨è¨­ç½®é é¢æé«˜max_output_tokensåƒæ•¸")
                    print(f"ğŸ’¡ ç•¶å‰max_output_tokens: {max_tokens}ï¼Œå»ºè­°æé«˜åˆ°8000-12000")
                    retry_count += 1
                    if retry_count < max_retries:
                        import time
                        time.sleep(2)  # ç­‰å¾…2ç§’å¾Œé‡è©¦
                        continue
                    else:
                        print(f"âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ï¼Œä½¿ç”¨incompleteçš„çµæœ")
                
                # æå–æ–‡æœ¬å…§å®¹ï¼ˆå„ªå…ˆä½¿ç”¨output_textï¼Œå¾Œå‚™è§£æoutputé™£åˆ—ï¼‰
                output = ""
                
                # 1) å„ªå…ˆå˜—è©¦å®˜æ–¹ä¾¿æ·å±¬æ€§ output_text
                try:
                    if getattr(response, "output_text", None):
                        txt = response.output_text.strip()
                        if txt:
                            print(f"âœ… ä½¿ç”¨ output_text: {len(txt)} å­—ç¬¦")
                            output = txt
                except Exception as e:
                    print(f"âš ï¸ output_text æå–å¤±æ•—: {e}")
                
                # 2) å¦‚æœoutput_textç‚ºç©ºï¼Œå¾Œå‚™è§£æoutputé™£åˆ—
                if not output:
                    if hasattr(response, 'output') and response.output:
                        print(f"ğŸ” DEBUG: é–‹å§‹è§£æ output é™£åˆ—ï¼Œå…± {len(response.output)} å€‹é …ç›®")
                        
                        for i, item in enumerate(response.output):
                            item_type = getattr(item, "type", None)
                            item_status = getattr(item, "status", None)
                            print(f"  - [{i}] type={item_type}, status={item_status}")
                            
                            # æœ€çµ‚ç­”æ¡ˆé€šå¸¸åœ¨ type="message"
                            if item_type == "message":
                                content = getattr(item, "content", []) or []
                                print(f"    ğŸ“ message æœ‰ {len(content)} å€‹ content é …ç›®")
                                
                                for j, c in enumerate(content):
                                    # content ç‰©ä»¶é€šå¸¸æœ‰ .text
                                    textval = getattr(c, "text", None)
                                    if textval:
                                        print(f"    âœ… content[{j}] æå–åˆ°æ–‡æœ¬: {len(textval)} å­—ç¬¦")
                                        output += textval
                                    else:
                                        print(f"    âš ï¸ content[{j}] æ²’æœ‰ text å±¬æ€§")
                    else:
                        print(f"ğŸ” DEBUG: response æ²’æœ‰ output å±¬æ€§æˆ– output ç‚ºç©º")

                output = output.strip()
                print(f"ğŸ” DEBUG: æœ€çµ‚ output é•·åº¦: {len(output)}")
                print(f"ğŸ” DEBUG: æœ€çµ‚ output å…§å®¹: {output[:200]}...")

                # æª¢æŸ¥æ•´é«”responseç‹€æ…‹
                response_status = getattr(response, 'status', None)
                if response_status == 'incomplete':
                    print(f"âš ï¸ æ•´é«”éŸ¿æ‡‰ç‹€æ…‹ç‚º incomplete")
                    if output:
                        print(f"âœ… å³ä½¿incompleteç‹€æ…‹ï¼Œä»æˆåŠŸæå–æ–‡æœ¬: {len(output)} å­—ç¬¦")
                        print(f"âœ… LLM èª¿ç”¨æˆåŠŸï¼Œå›æ‡‰é•·åº¦ï¼š{len(output)} å­—ç¬¦")
                        print(f"ğŸ“ LLM å›æ‡‰é è¦½ï¼š{output[:200]}...")
                        return output
                    else:
                        print(f"âŒ incompleteç‹€æ…‹ä¸”ç„¡æ³•æå–æ–‡æœ¬")
                        retry_count += 1
                        if retry_count < max_retries:
                            import time
                            time.sleep(2)  # ç­‰å¾…2ç§’å¾Œé‡è©¦
                            continue
                        else:
                            print(f"âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸")
                            print(f"ğŸ’¡ å»ºè­°ï¼šè«‹åœ¨è¨­ç½®é é¢å°‡max_output_tokensæé«˜åˆ°8000-12000ï¼Œæˆ–é™ä½verbosityè¨­ç½®")
                            return ""
                else:
                    # æ­£å¸¸ç‹€æ…‹
                    if output:
                        print(f"âœ… æˆåŠŸæå–æ–‡æœ¬: {len(output)} å­—ç¬¦")
                        print(f"âœ… LLM èª¿ç”¨æˆåŠŸï¼Œå›æ‡‰é•·åº¦ï¼š{len(output)} å­—ç¬¦")
                        print(f"ğŸ“ LLM å›æ‡‰é è¦½ï¼š{output[:200]}...")
                        return output
                    else:
                        print(f"âŒ ç„¡æ³•æå–æ–‡æœ¬")
                        retry_count += 1
                        if retry_count < max_retries:
                            import time
                            time.sleep(2)
                            continue
                        else:
                            print(f"âŒ é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸")
                            print(f"ğŸ’¡ å»ºè­°ï¼šè«‹åœ¨è¨­ç½®é é¢å°‡max_output_tokensæé«˜åˆ°8000-12000ï¼Œæˆ–é™ä½verbosityè¨­ç½®")
                            return ""

            print(f"âŒ æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²")
            return ""
            
        else:
            # GPT-4ç³»åˆ—ä½¿ç”¨Chat Completions API (LangChain)
            llm = ChatOpenAI(**llm_params)
            response = llm.invoke(prompt)
            print(f"âœ… LLM èª¿ç”¨æˆåŠŸï¼Œå›æ‡‰é•·åº¦ï¼š{len(response.content)} å­—ç¬¦")
            print(f"ğŸ“ LLM å›æ‡‰é è¦½ï¼š{response.content[:200]}...")
            return response.content
            
    except Exception as e:
        print(f"âŒ LLM èª¿ç”¨å¤±æ•—ï¼š{e}")
        return ""

def build_inference_prompt(chunks: List[Document], question: str) -> Tuple[str, List[Dict]]:
    context_text = ""
    citations = []
    citation_map = {}
    
    for i, doc in enumerate(chunks):
        meta = doc.metadata
        title = meta.get("title", "Untitled")
        filename = meta.get("filename") or meta.get("source", "Unknown")
        page = meta.get("page_number") or meta.get("page", "?")
        snippet = doc.page_content[:80].replace("\n", " ")
        
        # æª¢æŸ¥ï¼šé¿å…é‡è¤‡çš„ (filename, page) çµ„åˆ
        citation_key = f"{filename}_p{page}"
        if citation_key not in citation_map:
            label = f"[{len(citations) + 1}]"
            citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })
            citation_map[citation_key] = label
        else:
            label = citation_map[citation_key]

        context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    system_prompt = f"""
    You are a materials synthesis consultant who understands and excels at comparing the chemical and physical properties of materials. You can propose innovative suggestions based on known experimental conditions for situations where there is no clear literature.

    Please conduct extended thinking based on the following literature and experimental data:
    - You can propose new combinations, temperatures, times, or pathways.
    - Even combinations not yet documented in the literature can be suggested, but you must provide reasonable reasoning.
    - When making inferences and extended thinking, please try to mention "what literature clues this idea originates from" to support your explanation. The current literature excerpt numbers are [1] to [{len(chunks)}] (total {len(chunks)} excerpts)

    --- Literature Summary ---
    {context_text}

    --- Question ---
    {question}
    """
    return system_prompt.strip(), citations

def build_dual_inference_prompt(
    chunks_paper: List[Document],
    question: str,
    experiment_chunks: List[Document]
    ) -> Tuple[str, List[Dict]]:

    paper_context_text = ""
    exp_context_text = ""
    citations = []
    label_index = 1

    # --- Literature Summary ---
    paper_context_text += "--- Literature Summary ---\n"
    for doc in chunks_paper:
        meta = doc.metadata
        title = meta.get("title", "Untitled")
        filename = meta.get("filename") or meta.get("source", "Unknown")
        page = meta.get("page_number") or meta.get("page", "?")
        snippet = doc.page_content[:80].replace("\n", " ")
        label = f"[{label_index}]"

        citations.append({
            "label": label,
            "title": title,
            "source": filename,
            "page": page,
            "snippet": snippet,
            "type": "paper"
        })

        paper_context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"
        label_index += 1

    # --- Experiment Summary ---
    exp_context_text += "--- Similar Experiment Summary ---\n"
    for doc in experiment_chunks:
        meta = doc.metadata
        filename = meta.get("filename") or meta.get("source", "Unknown")
        exp_id = meta.get("exp_id", "unknown_exp")
        snippet = doc.page_content[:80].replace("\n", " ")
        label = f"[{label_index}]"

        citations.append({
            "label": label,
            "title": exp_id,
            "source": filename,
            "page": "-",  # æ²’æœ‰é æ•¸
            "snippet": snippet,
            "type": "experiment"
        })

        exp_context_text += f"{label} Experiment {exp_id}\n{doc.page_content}\n\n"
        label_index += 1
        
    # --- Prompt Injection ---
    system_prompt = f"""
    You are a materials synthesis consultant who understands and excels at comparing the chemical and physical properties of materials.

    You will see three parts of information. Please conduct comprehensive analysis and provide specific inferences and innovative suggestions for experiments:
    1. Literature summary (with source annotations [1], [2])
    2. Similar experiment summary (from vector database)
    3. Experiment records (tables)

    Please propose new suggestions for the research question, including:
    - Adjusted synthesis pathways and conditions (such as temperature, time, ratios)
    - Factors that may affect synthesis success rate
    - Reasoning behind the causes, citing literature ([1], [2]...) or similar experiment results when necessary
    Important: You can only cite the provided literature excerpts. The current literature excerpt numbers are [1] to [{len(chunks_paper) + len(experiment_chunks)}] (total {len(chunks_paper) + len(experiment_chunks)} excerpts)

    --- Literature Knowledge Sources ---
    {paper_context_text}

    --- Experiment Records ---
    {exp_context_text}

    --- Research Question ---
    {question}
    """
    return system_prompt.strip(), citations



def expand_query(user_prompt: str) -> List[str]:
    """
    Convert user input natural language questions into multiple semantic search query statements.
    The returned English statements can be used for literature vector retrieval.
    """
    # Get dynamic model parameters
    try:
        from model_config_bridge import get_current_model, get_model_params
        current_model = get_current_model()
        llm_params = get_model_params()
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•ç²å–æ¨¡å‹åƒæ•¸ï¼š{e}")
        current_model = "gpt-4-1106-preview"
        llm_params = {
            "model": "gpt-4-1106-preview",
            "temperature": 0.3,
            "max_tokens": 4000,
            "timeout": 120,
        }

    system_prompt = """You are a scientific assistant helping expand a user's synthesis question into multiple semantic search queries. 
    Each query should be precise, relevant, and useful for retrieving related technical documents. 
    Only return a list of 3 to 6 search queries in English. Do not explain, do not include numbering if not needed."""

    full_prompt = f"{system_prompt}\n\nUser question:\n{user_prompt}"

    try:
        # æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡ä¸åŒçš„API
        if current_model.startswith('gpt-5'):
            # GPT-5ç³»åˆ—ä½¿ç”¨Responses API
            from openai import OpenAI
            client = OpenAI()
            
            # æº–å‚™Responses APIçš„åƒæ•¸
            responses_params = {
                'model': current_model,
                'input': [{'role': 'user', 'content': full_prompt}]
            }
            
            # æ·»åŠ å…¶ä»–åƒæ•¸ï¼ˆæ’é™¤modelå’Œinputï¼‰
            for key, value in llm_params.items():
                if key not in ['model', 'input']:
                    responses_params[key] = value
            
            # ä¿®å¾©ï¼šç§»é™¤reasoningåƒæ•¸ï¼Œé¿å…è¿”å›ResponseReasoningItem
            if 'reasoning' in responses_params:
                del responses_params['reasoning']
            
            # ç¢ºä¿ç§»é™¤reasoningåƒæ•¸
            if 'reasoning' in responses_params:
                print(f"ğŸ” DEBUG: ç§»é™¤ reasoning åƒæ•¸: {responses_params['reasoning']}")
                del responses_params['reasoning']
                print(f"ğŸ” DEBUG: æ›´æ–°å¾Œçš„åƒæ•¸: {responses_params}")
            
            response = client.responses.create(**responses_params)
            
            # ä¿®å¾©ï¼šæ ¹æ“šGPT-5 cookbookæ­£ç¢ºè™•ç†Responses APIçš„å›æ‡‰æ ¼å¼
            output = ""
            if hasattr(response, 'output') and response.output:
                for item in response.output:
                    # è·³éResponseReasoningItemå°è±¡
                    if hasattr(item, 'type') and item.type == 'reasoning':
                        continue
                    
                    if hasattr(item, "content"):
                        for content in item.content:
                            if hasattr(content, "text"):
                                output += content.text
                    elif hasattr(item, "text"):
                        # ç›´æ¥æ–‡æœ¬è¼¸å‡º
                        output += item.text
                    elif hasattr(item, "message"):
                        # messageå°è±¡
                        if hasattr(item.message, "content"):
                            output += item.message.content
                        else:
                            output += str(item.message)
                    else:
                        # å…¶ä»–æƒ…æ³ï¼Œå˜—è©¦è½‰æ›ç‚ºå­—ç¬¦ä¸²ï¼Œä½†éæ¿¾æ‰ResponseReasoningItem
                        item_str = str(item)
                        if not item_str.startswith('ResponseReasoningItem'):
                            output += item_str
            
            output = output.strip()
            
        else:
            # GPT-4ç³»åˆ—ä½¿ç”¨Chat Completions API (LangChain)
            llm = ChatOpenAI(**llm_params)
            output = llm.predict(full_prompt).strip()

        # Try to parse into query list
        if output.startswith("[") and output.endswith("]"):
            try:
                return eval(output)
            except Exception:
                pass  # fall back

        queries = [line.strip("-â€¢ ").strip() for line in output.split("\n") if line.strip()]
        return [q for q in queries if len(q) > 4]
        
    except Exception as e:
        print(f"âŒ æŸ¥è©¢æ“´å±•å¤±æ•—ï¼š{e}")
        # è¿”å›åŸå§‹æŸ¥è©¢ä½œç‚ºfallback
        return [user_prompt]


def build_proposal_prompt(chunks: List[Document], question: str) -> Tuple[str, List[Dict]]:
    paper_context_text = ""
    citations = []
    citation_map = {}

    for i, doc in enumerate(chunks):
        
        meta = doc.metadata
        title = meta.get("title", "Untitled")
        filename = meta.get("filename") or meta.get("source", "Unknown")
        page = meta.get("page_number") or meta.get("page", "?")
        snippet = doc.page_content[:80].replace("\n", " ")
        
        # æª¢æŸ¥ï¼šé¿å…é‡è¤‡çš„ (filename, page) çµ„åˆ
        citation_key = f"{filename}_p{page}"
        if citation_key not in citation_map:
            label = f"[{len(citations) + 1}]"
            citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })
            citation_map[citation_key] = label
        else:
            label = citation_map[citation_key]

        paper_context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    system_prompt = f"""
    You are a scientific research expert who excels at proposing innovative and feasible research proposals based on literature summaries and research objectives.
Your expertise covers materials science, chemistry, physics, and engineering, and you are capable of deriving new ideas grounded in experimental evidence and theoretical principles.

If possible, propose new components, structures, or mechanisms (e.g., new ligands, frameworks, catalysts, processing techniques) based on the literature, and clearly explain their structural or functional advantages and potential reactivity/performance.

Write a structured proposal based on the provided literature excerpts and research objectives in the following format (complete each section):

Proposal: (Automatically generate a proposal title summarizing research objectives and innovation points)

Need:

Briefly describe the research objectives and current limitations in existing solutions

Clearly identify the pain points or technical bottlenecks that need to be addressed at industry, academic, or global level

Solution:

Propose specific design and development strategies

Suggest new structures, compositions, or methods, clearly naming the proposed elements (e.g., chemical names, material systems, fabrication methods)

Explain the logic behind the proposed design (e.g., structure-property relationship, mechanism of action, processing advantages)

Differentiation:

Compare with existing literature or technologies

Emphasize breakthroughs in structure, performance, or implementation

Benefit:

Expected improvements in performance or application scope

Provide quantitative estimates if possible (e.g., % improvement, target metrics)

Based Literature:

Use paragraph labels to cite sources, with labels from [1] to [{len(chunks)}] (total {len(chunks)} excerpts)

Ensure every claim is supported by a cited source or reasonable extension from the literature

Experimental overview:

Starting materials/components and conditions (e.g., temperature, duration, environment)

Instruments/equipment description and list

Step-by-step description of the procedure (highlighting key logic and rationale)

Finally, list all materials/chemicals used in this proposal (including metals, ligands, solvents, or other relevant reagents) in JSON format at the end of your answer. Use IUPAC names where applicable.
Example:

```json
["formic acid", "N,N-dimethylformamide", "copper;dinitrate;trihydrate"]
Notes:

All proposed designs must have a logical basis â€” avoid inventing unreasonable structures without justification

Maintain scientific rigor, clarity, and avoid vague descriptions

Use only the provided literature labels ([1], [2], etc.) for citations, and do not fabricate sources

    --- Literature Excerpts ---
    {paper_context_text}

    --- Research Objectives ---
    {question}"""
    
    return system_prompt.strip(), citations

def build_detail_experimental_plan_prompt(chunks: List[Document], proposal_text: str) -> Tuple[str, List[Dict]]:
    context_text = ""
    citations = []
    citation_map = {}
    
    for i, doc in enumerate(chunks):
        # æª¢æŸ¥ï¼šdoc æ‡‰æœ‰ metadata å±¬æ€§ï¼Œä¸”ç‚º dict
        metadata = doc.metadata
        title = metadata.get("title", "Untitled")
        # æª¢æŸ¥ï¼šfilename ä¾†æºæ–¼ "filename" æˆ– "source"ï¼Œè‹¥éƒ½ç„¡å‰‡ç‚º "Unknown"
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        # æª¢æŸ¥ï¼špage ä¾†æºæ–¼ "page_number" æˆ– "page"ï¼Œè‹¥éƒ½ç„¡å‰‡ç‚º "?"
        page = metadata.get("page_number") or metadata.get("page", "?")
        # é è¦½ç‰‡æ®µï¼Œå–å‰ 80 å­—å…ƒï¼Œä¸¦å°‡æ›è¡Œæ›¿æ›ç‚ºç©ºæ ¼
        snippet = doc.page_content[:80].replace("\n", " ")

        # æª¢æŸ¥ï¼šé¿å…é‡è¤‡çš„ (filename, page) çµ„åˆ
        citation_key = f"{filename}_p{page}"
        if citation_key not in citation_map:
            label = f"[{len(citations) + 1}]"
            citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })
            citation_map[citation_key] = label
        else:
            label = citation_map[citation_key]

        # context_text ç´¯åŠ æ¯å€‹ chunk çš„å…§å®¹ï¼Œæ ¼å¼ç‚º [n] title | Page n
        context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    system_prompt = f"""
    You are an experienced consultant in materials experiment design. Based on the following research proposal and related literature excerpts, please provide the researcher with a detailed set of recommended experimental procedures.

    IMPORTANT: Please provide your response in plain text format only. Do NOT use any markdown formatting, bold text, or special formatting. Use simple text with clear section headers and bullet points.

    Please include the following sections:

    SYNTHESIS PROCESS:
    Provide a step-by-step description of each experimental operation, including sequence, logic, and purpose.
    Guidelines for synthesis process:
    - Suggest specific ranges of experimental conditions (temperature, time, pressure, etc.)
    - For each reaction condition and step mentioned in the literature, cite the source ([1], [2], etc.)
    - For suggested conditions not based on literature, explain your logic clearly

    MATERIALS AND CONDITIONS:
    List the required raw materials for each step (including proportions) and the reaction conditions (temperature, time, containers).

    ANALYTICAL METHODS:
    Suggest characterization tools (such as XRD, BET, TGA) and explain the purpose of each.

    PRECAUTIONS:
    Highlight key points or parameter limitations mentioned in the literature.

    Format your response with clear section headers in CAPITAL LETTERS, followed by detailed explanations. Use simple bullet points (-) for lists.
    Use [1], [2], etc. to cite the literature sources in your response. Only cite the provided literature excerpts, numbered [1] to [{len(chunks)}] (total {len(chunks)} excerpts).

    --- literature chunks ---
    {context_text}

    --- User's Proposal ---
    {proposal_text}
    """
    return system_prompt.strip(), citations



def build_iterative_proposal_prompt(
    question: str,
    new_chunks: List[Document],
    old_chunks: List[Document],
    past_proposal: str
) -> Tuple[str, List[Dict]]:
    """
    Build a new research proposal prompt that combines user feedback, newly retrieved literature, old literature, and the original proposal.
    Also returns citation list.
    """
    citations = []

    def format_chunks(chunks: List[Document], label_offset=0) -> Tuple[str, List[Dict]]:
        text = ""
        local_citations = []
        for i, doc in enumerate(chunks):
            meta = doc.metadata
            title = meta.get("title", "Untitled")
            filename = meta.get("filename") or meta.get("source", "Unknown")
            page = meta.get("page_number") or meta.get("page", "?")
            snippet = doc.page_content[:80].replace("\n", " ")
            label = f"[{label_offset + i + 1}]"

            local_citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })

            text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

        return text, local_citations

    old_text, old_citations = format_chunks(old_chunks)
    new_text, new_citations = format_chunks(new_chunks, label_offset=len(old_citations))
    citations.extend(old_citations + new_citations)

    system_prompt = f"""
    You are an experienced materials experiment design consultant. Please help modify parts of the research proposal based on user feedback, original proposal, and literature content.

    Please follow these guidelines:
    1. Prioritize the areas that the user wants to modify and look for possible improvement directions from the literature.
    2. Except for the areas that the user is dissatisfied with, other parts (NSDB) should maintain the original proposal content without changes, output directly.
    3. Maintain the proposal format consistent with the original proposal content, and please briefly explain the direction of changes in the first paragraph, including the following sections:
    - revision explanation: Briefly explain the differences between this proposal and the previous proposal
    - Need
    - Solution
    - Differentiation
    - Benefit
    - Based Literature
    - Experimental overview
    Important: You can only cite the provided literature excerpts. The current literature excerpt numbers are [1] to [{len(old_chunks) + len(new_chunks)}] (total {len(old_chunks) + len(new_chunks)} excerpts)

    Finally, please list all chemicals used in this proposal (including metal salts, organic ligands, solvents, etc.) in JSON format at the end of your answer. Answer with IUPAC names, format and example as follows:

    ```json
    ["formic acid", "N,N-dimethylformamide", "copper;dinitrate;trihydrate"]
    --- User Feedback ---
    {question}

    --- Original Proposal Content ---
    {past_proposal}

    --- Literature Excerpts Based on Original Proposal ---
    {old_text}

    --- New Retrieved Excerpts Based on Feedback ---
    {new_text}
    """
    return system_prompt.strip(), citations


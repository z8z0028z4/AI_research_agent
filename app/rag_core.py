from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document
from langchain.chat_models import ChatOpenAI
from config import VECTOR_INDEX_DIR, EMBEDDING_MODEL_NAME, LLM_MODEL_NAME
import pandas as pd
from typing import List, Tuple, Dict
import re


def load_vectorstore():
    embedding_model = HuggingFaceEmbeddings(
    model_name=EMBEDDING_MODEL_NAME,
    model_kwargs={"trust_remote_code": True}
    )
    vectorstore = Chroma(persist_directory=VECTOR_INDEX_DIR, embedding_function=embedding_model)
    return vectorstore


def retrieve_chunks(vectorstore, query: str, k: int = 10, fetch_k: int = 30, score_threshold: float = 0.35) -> List[Document]:
    retriever = vectorstore.as_retriever(
        search_type="mmr",
        search_kwargs={"k": k, "fetch_k": fetch_k, "score_threshold": score_threshold}
    )
    context_docs = retriever.get_relevant_documents(query)

    if not context_docs:
        print("âš ï¸ æ²’æœ‰æŠ“åˆ°ä»»ä½•æ®µè½ï¼Œå»ºè­°æª¢æŸ¥ retriever æˆ–åµŒå…¥æ ¼å¼")
    else:
        print("ğŸ” Retriever æŠ“åˆ°çš„æ®µè½ï¼š")
        for i, doc in enumerate(context_docs, 1):
            meta = doc.metadata
            filename = meta.get("filename") or meta.get("source", "Unknown")
            page = meta.get("page_number") or meta.get("page", "?")
            preview = doc.page_content[:100].replace("\n", " ")
            print(f"--- Chunk {i} ---")
            print(f"ğŸ“„ {filename} | Page {page}")
            print(preview)
            print()

    return context_docs


def build_prompt(chunks: List[Document], df: pd.DataFrame, question: str) -> Tuple[str, List[Dict]]:
    context_text = ""
    citations = []
    citation_map = {}
    
    for i, doc in enumerate(chunks):
        metadata = doc.metadata
        title = metadata.get("title", "Untitled")
        filename = metadata.get("filename") or metadata.get("source", "Unknown")
        page = metadata.get("page_number") or metadata.get("page", "?")
        snippet = doc.page_content[:80].replace("\n", " ")

        label = f"[{i+1}]"
 
        if label not in citation_map.values():
            citations.append({
                "label": label,
                "title": title,
                "source": filename,
                "page": page,
                "snippet": snippet
            })
        citation_map[f"{filename}_p{page}"] = label

        context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    past_exp = df.to_string(index=False) if not df.empty else "ç„¡ç´€éŒ„"

    system_prompt = f"""
ä½ æ˜¯ä¸€ä½ç ”ç©¶åŠ©ç†ï¼Œåƒ…æ ¹æ“šä¸‹åˆ—æ–‡ç»æ®µè½èˆ‡å¯¦é©—ç´€éŒ„å›ç­”å•é¡Œã€‚
è«‹åœ¨å›ç­”ä¸­ä½¿ç”¨ [1], [2] ç­‰æ¨™è¨»æ®µè½å‡ºè™•ï¼Œä¸è¦åœ¨çµå°¾é‡è¤‡åˆ—å‡ºä¾†æºã€‚
å¦‚æ®µè½ä¸­æœ‰æåˆ°å…·é«”çš„å¯¦é©—æ¢ä»¶ï¼ˆæº«åº¦ã€æ™‚é–“ç­‰ï¼‰ï¼Œè«‹å‹™å¿…åŒ…å«åœ¨å›ç­”ä¸­ã€‚
--- æ–‡ç»æ‘˜è¦ ---
{context_text}

--- å¯¦é©—ç´€éŒ„ ---
{past_exp}

--- å•é¡Œ ---
{question}
"""
    return system_prompt.strip(), citations


def call_llm(prompt: str) -> str:
    llm = ChatOpenAI(model_name=LLM_MODEL_NAME, temperature=0)
    return llm.predict(prompt)

def build_inference_prompt(chunks: List[Document], df: pd.DataFrame, question: str) -> Tuple[str, List[Dict]]:
    context_text = ""
    citations = []
    for i, doc in enumerate(chunks):
        meta = doc.metadata
        title = meta.get("title", "Untitled")
        filename = meta.get("filename") or meta.get("source", "Unknown")
        page = meta.get("page_number") or meta.get("page", "?")
        snippet = doc.page_content[:80].replace("\n", " ")
        label = f"[{i+1}]"

        citations.append({
            "label": label,
            "title": title,
            "source": filename,
            "page": page,
            "snippet": snippet
        })

        context_text += f"{label} {title} | Page {page}\n{doc.page_content}\n\n"

    past_exp = df.to_string(index=False) if not df.empty else "ç„¡ç´€éŒ„"

    system_prompt = f"""
ä½ æ˜¯ä¸€ä½ææ–™åˆæˆé¡§å•ï¼Œå–„æ–¼é‡å°å°šæœªæœ‰æ˜ç¢ºæ–‡ç»çš„æƒ…å¢ƒï¼Œæ ¹æ“šç›¸ä¼¼æ¢ä»¶æ¨è«–å‡ºå‰µæ–°å»ºè­°ã€‚

è«‹æ ¹æ“šä»¥ä¸‹æ–‡ç»èˆ‡å¯¦é©—è³‡æ–™ï¼Œé€²è¡Œå»¶ä¼¸æ€è€ƒï¼š
- ä½ å¯ä»¥æå‡ºæ–°çš„çµ„åˆã€æº«åº¦ã€æ™‚é–“æˆ–è·¯å¾‘ã€‚
- å³ä½¿æ²’æœ‰ç›´æ¥è­‰æ“šï¼Œåªè¦æ¨ç†åˆç†ä¹Ÿå¯ä»¥å»ºè­°ã€‚
- åªè¦åˆç†ï¼Œå…è¨±æå‡ºå‰µæ–°æ§‹æƒ³ï¼Œå³ä½¿æ–‡ç»ä¸­å°šæœªè¨˜è¼‰
- æ¨è«–ã€å»¶ä¼¸æ€è€ƒçš„åŒæ™‚ï¼Œè«‹å„˜å¯èƒ½æåˆ°ã€Œé€™æ¨£çš„æƒ³æ³•æºæ–¼å“ªç¨®æ–‡ç»ç·šç´¢ã€ä¾†è¼”åŠ©è§£é‡‹ï¼Œè«‹åœ¨å›ç­”ä¸­ä½¿ç”¨ [1], [2] ç­‰æ¨™è¨»æ®µè½å‡ºè™•ï¼Œä¸è¦åœ¨çµå°¾é‡è¤‡åˆ—å‡ºä¾†æºã€‚


--- æ–‡ç»æ‘˜è¦ ---
{context_text}

--- å¯¦é©—ç´€éŒ„ ---
{past_exp}

--- å•é¡Œ ---
{question}
"""
    return system_prompt.strip(), citations
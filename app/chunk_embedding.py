"""
AI ç ”ç©¶åŠ©ç† - æ–‡æª”åˆ†å¡Šå’Œå‘é‡åµŒå…¥æ¨¡å¡Š
================================

é€™å€‹æ¨¡å¡Šè² è²¬å°‡æ–‡æª”è½‰æ›ç‚ºå‘é‡è¡¨ç¤ºï¼Œç‚ºRAGç³»çµ±æä¾›æª¢ç´¢åŸºç¤ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. æ–‡æª”åˆ†å¡Šå’Œé è™•ç†
2. æ–‡æœ¬å‘é‡åŒ–
3. å‘é‡æ•¸æ“šåº«å­˜å„²
4. æ‰¹é‡è™•ç†æ”¯æŒ

æ¶æ§‹èªªæ˜ï¼š
- ä½¿ç”¨LangChainçš„æ–‡æœ¬åˆ†å‰²å™¨
- é›†æˆHuggingFaceåµŒå…¥æ¨¡å‹
- ä½¿ç”¨Chromaä½œç‚ºå‘é‡æ•¸æ“šåº«
- æ”¯æŒGPUåŠ é€Ÿè¨ˆç®—

âš ï¸ æ³¨æ„ï¼šæ­¤æ¨¡å¡Šæ˜¯RAGç³»çµ±çš„åŸºç¤ï¼Œæ‰€æœ‰æ–‡æª”æª¢ç´¢éƒ½ä¾è³´æ–¼æ­¤æ¨¡å¡Š
"""

from config import VECTOR_INDEX_DIR, EMBEDDING_MODEL_NAME
from langchain.text_splitter import RecursiveCharacterTextSplitter
from pdf_read_and_chunk_page_get import load_and_parse_file, get_page_number_for_chunk
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from tqdm import tqdm
import os
from typing import List
import torch

# ==================== è¨­å‚™é…ç½® ====================
# è‡ªå‹•æª¢æ¸¬ä¸¦ä½¿ç”¨GPUæˆ–CPUé€²è¡Œå‘é‡è¨ˆç®—
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ åµŒå…¥æ¨¡å‹ä½¿ç”¨è¨­å‚™ï¼š{device.upper()}")


def embed_documents_from_metadata(metadata_list, status_callback=None):
    """
    æ ¹æ“šå…ƒæ•¸æ“šåˆ—è¡¨åµŒå…¥æ–‡æª”
    
    åŠŸèƒ½ï¼š
    1. è®€å–æ–‡æª”ä¸¦é€²è¡Œåˆ†å¡Šè™•ç†
    2. ç‚ºæ¯å€‹æ–‡æª”å¡Šæ·»åŠ å…ƒæ•¸æ“š
    3. å°‡æ–‡æª”å¡Šè½‰æ›ç‚ºå‘é‡ä¸¦å­˜å„²
    4. æä¾›é€²åº¦å›èª¿å’Œçµ±è¨ˆä¿¡æ¯
    
    åƒæ•¸ï¼š
        metadata_list: æ–‡æª”å…ƒæ•¸æ“šåˆ—è¡¨
        status_callback: é€²åº¦å›èª¿å‡½æ•¸
    
    è™•ç†æµç¨‹ï¼š
    1. æ–‡æœ¬åˆ†å‰²ï¼šå°‡æ–‡æª”åˆ†å‰²ç‚ºå°å¡Š
    2. å…ƒæ•¸æ“šæå–ï¼šç‚ºæ¯å€‹å¡Šæ·»åŠ æ¨™è­˜ä¿¡æ¯
    3. å‘é‡åŒ–ï¼šä½¿ç”¨åµŒå…¥æ¨¡å‹è½‰æ›ç‚ºå‘é‡
    4. å­˜å„²ï¼šä¿å­˜åˆ°Chromaå‘é‡æ•¸æ“šåº«
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨éæ­¸å­—ç¬¦åˆ†å‰²å™¨
    - æ”¯æŒå¤šç¨®åˆ†éš”ç¬¦
    - æ‰¹é‡è™•ç†æé«˜æ•ˆç‡
    - è‡ªå‹•æŒä¹…åŒ–å­˜å„²
    """
    # ==================== æ–‡æœ¬åˆ†å‰²å™¨é…ç½® ====================
    # é…ç½®æ–‡æœ¬åˆ†å‰²åƒæ•¸
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,        # æ¯å€‹å¡Šçš„æœ€å¤§å­—ç¬¦æ•¸
        chunk_overlap=50,      # å¡Šä¹‹é–“çš„é‡ç–Šå­—ç¬¦æ•¸
        separators=["\n\n", "\n", ".", "ã€‚", " ", ""]  # åˆ†å‰²ç¬¦è™Ÿå„ªå…ˆç´š
    )
    
    texts, metadatas = [], []

    # ==================== æ–‡æª”è™•ç†å¾ªç’° ====================
    # ä½¿ç”¨tqdmé¡¯ç¤ºé€²åº¦æ¢
    for metadata in tqdm(metadata_list, desc="ğŸ“š åˆ†å¡Šå’Œå…ƒæ•¸æ“šè™•ç†"):
        # æå–æ–‡æª”åŸºæœ¬ä¿¡æ¯
        doc_type = metadata.get("type", "")
        title = metadata.get("title", "")
        tracing_number = metadata.get("tracing_number", "")
        filename = metadata["new_filename"]
        file_path = metadata["new_path"]

        # è®€å–å’Œè§£ææ–‡æª”
        doc_chunks = load_and_parse_file(file_path)
        
        # å°æ–‡æª”é€²è¡Œåˆ†å¡Šè™•ç†
        for i, chunk in enumerate(splitter.split_text(doc_chunks)):
            # éæ¿¾éçŸ­çš„æ–‡æœ¬å¡Š
            if len(chunk.strip()) < 10:
                continue
                
            # ç²å–é ç¢¼ä¿¡æ¯
            page_num = get_page_number_for_chunk(file_path, chunk)
            
            # æ·»åŠ åˆ°è™•ç†åˆ—è¡¨
            texts.append(chunk)
            metadatas.append({
                "title": title,
                "type": doc_type,
                "tracing_number": tracing_number,
                "filename": filename,
                "chunk_index": i,
                "page_number": page_num
            })

    print("ğŸ“¡ é–‹å§‹å‘é‡åµŒå…¥...")
    
    # ==================== åµŒå…¥æ¨¡å‹åˆå§‹åŒ– ====================
    # ä½¿ç”¨HuggingFaceåµŒå…¥æ¨¡å‹
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={
            "trust_remote_code": True,
            "device": device,  # ä½¿ç”¨GPUæˆ–CPU
        }
    )
    
    # ==================== å‘é‡æ•¸æ“šåº«é…ç½® ====================
    # é…ç½®Chromaå‘é‡æ•¸æ“šåº«
    experiment_vector_dir = os.path.join(VECTOR_INDEX_DIR, "paper_vector")
    vectorstore = Chroma(
        persist_directory=experiment_vector_dir,
        embedding_function=embedding_model, 
        collection_name="paper"
    )

    # ==================== æ‰¹é‡å‘é‡åŒ–è™•ç† ====================
    # ä½¿ç”¨æ‰¹é‡è™•ç†æé«˜æ•ˆç‡
    BATCH_SIZE = 500
    for i in range(0, len(texts), BATCH_SIZE):
        batch_texts = texts[i:i+BATCH_SIZE]
        batch_metadatas = metadatas[i:i+BATCH_SIZE]
        vectorstore.add_texts(texts=batch_texts, metadatas=batch_metadatas)
    
    # ==================== æŒä¹…åŒ–å­˜å„² ====================
    # Chroma 0.4.x ç‰ˆæœ¬å¾Œæœƒè‡ªå‹•æŒä¹…åŒ–ï¼Œä¸éœ€è¦æ‰‹å‹•èª¿ç”¨ persist()
    # vectorstore.persist()  # å·²æ£„ç”¨ï¼Œè‡ªå‹•æŒä¹…åŒ–
    
    # ==================== çµ±è¨ˆä¿¡æ¯ ====================
    doc_stats = vectorstore.get(include=["documents"])
    print("ğŸ“¦ å‘é‡åº«ç›®å‰å…±åŒ…å«ï¼š", len(doc_stats["documents"]), "æ®µ")

    # ==================== é©—è­‰åµŒå…¥çµæœ ====================
    # é©—è­‰æ–°æ·»åŠ çš„æ–‡æª”æ˜¯å¦çœŸçš„è¢«å­˜å„²
    try:
        # å˜—è©¦æª¢ç´¢ä¸€å€‹æ–°æ·»åŠ çš„æ–‡æª”ä¾†é©—è­‰
        if texts:
            test_query = texts[0][:50]  # ä½¿ç”¨ç¬¬ä¸€å€‹æ–‡æª”çš„å‰50å€‹å­—ç¬¦ä½œç‚ºæ¸¬è©¦æŸ¥è©¢
            test_results = vectorstore.similarity_search(test_query, k=1)
            if test_results:
                print("âœ… åµŒå…¥é©—è­‰æˆåŠŸï¼šå¯ä»¥æª¢ç´¢åˆ°æ–°æ·»åŠ çš„æ–‡æª”")
            else:
                print("âš ï¸ åµŒå…¥é©—è­‰å¤±æ•—ï¼šç„¡æ³•æª¢ç´¢åˆ°æ–°æ·»åŠ çš„æ–‡æª”")
    except Exception as e:
        print(f"âš ï¸ åµŒå…¥é©—è­‰æ™‚å‡ºç¾éŒ¯èª¤ï¼š{e}")

    # ==================== é€²åº¦å›èª¿ ====================
    if status_callback:
        status_callback(f"âœ… åµŒå…¥å®Œæˆï¼Œå…±æ–°å¢ {len(texts)} æ®µ")

    # ==================== è©³ç´°çµ±è¨ˆ ====================
    print("ğŸ“Š åµŒå…¥æ®µè½çµ±è¨ˆï¼š")
    for i, text in enumerate(texts[:10]):
        preview = text[:80].replace("\n", " ")
        print(f"Chunk {i+1} | é•·åº¦: {len(text)} | é ­éƒ¨: {preview}")


def embed_experiment_txt_batch(txt_paths: List[str], status_callback=None):
    """
    æ‰¹é‡åµŒå…¥å¯¦é©—æ–‡æœ¬æ–‡ä»¶
    
    åŠŸèƒ½ï¼š
    1. è®€å–æŒ‡å®šçš„TXTæ–‡ä»¶åˆ—è¡¨
    2. å°‡æ¯å€‹æ–‡ä»¶ä½œç‚ºä¸€å€‹å®Œæ•´çš„æ–‡æª”å¡Š
    3. æå–å¯¦é©—IDä½œç‚ºæ¨™è­˜ç¬¦
    4. æ‰¹é‡å‘é‡åŒ–ä¸¦å­˜å„²
    
    åƒæ•¸ï¼š
        txt_paths (List[str]): TXTæ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        status_callback: é€²åº¦å›èª¿å‡½æ•¸
    
    ç‰¹é»ï¼š
    - æ¯å€‹TXTæ–‡ä»¶ä½œç‚ºä¸€å€‹å®Œæ•´çš„å¯¦é©—è¨˜éŒ„
    - ä½¿ç”¨æ–‡ä»¶åï¼ˆä¸å«æ“´å±•åï¼‰ä½œç‚ºå¯¦é©—ID
    - å°ˆé–€ç”¨æ–¼å¯¦é©—æ•¸æ“šçš„å‘é‡åŒ–
    - å­˜å„²åˆ°ç¨ç«‹çš„å¯¦é©—å‘é‡æ•¸æ“šåº«
    
    æŠ€è¡“ç´°ç¯€ï¼š
    - ä½¿ç”¨ç›¸åŒçš„åµŒå…¥æ¨¡å‹ç¢ºä¿ä¸€è‡´æ€§
    - å­˜å„²åˆ°experiment_vectorç›®éŒ„
    - é›†åˆåç¨±ç‚º"experiment"
    """
    
    # ==================== åµŒå…¥æ¨¡å‹åˆå§‹åŒ– ====================
    embedding_model = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL_NAME,
        model_kwargs={
            "trust_remote_code": True,
            "device": device
        }
    )
    
    # ==================== å¯¦é©—å‘é‡æ•¸æ“šåº«é…ç½® ====================
    # ä½¿ç”¨å°ˆé–€çš„å¯¦é©—å‘é‡å­˜å„²ç›®éŒ„
    experiment_vector_dir = os.path.join(VECTOR_INDEX_DIR, "experiment_vector")
    vectorstore = Chroma(
        persist_directory=experiment_vector_dir, 
        embedding_function=embedding_model, 
        collection_name="experiment"
    )

    texts, metadatas = [], []

    # ==================== æ–‡ä»¶è™•ç†å¾ªç’° ====================
    for path in txt_paths:
        # åªè™•ç†TXTæ–‡ä»¶
        if not path.endswith(".txt"):
            continue
            
        # æå–å¯¦é©—IDï¼ˆæ–‡ä»¶åä¸å«æ“´å±•åï¼‰
        exp_id = os.path.splitext(os.path.basename(path))[0]

        # è®€å–æ–‡ä»¶å…§å®¹
        with open(path, "r", encoding="utf-8") as f:
            content = f.read().strip()
            
        # éæ¿¾éçŸ­çš„å…§å®¹
        if len(content) < 10:
            continue

        # æ·»åŠ åˆ°è™•ç†åˆ—è¡¨
        texts.append(content)
        metadatas.append({
            "type": "experiment",
            "exp_id": exp_id,
            "filename": os.path.basename(path),
        })

    # ==================== é©—è­‰è™•ç†çµæœ ====================
    if not texts:
        if status_callback:
            status_callback("âš ï¸ æ²’æœ‰æ–°çš„å¯¦é©—æ‘˜è¦å¯åµŒå…¥")
        return

    # ==================== æ‰¹é‡å‘é‡åŒ– ====================
    vectorstore.add_texts(texts=texts, metadatas=metadatas)
    # vectorstore.persist()  # å·²æ£„ç”¨ï¼Œè‡ªå‹•æŒä¹…åŒ–

    # ==================== çµ±è¨ˆä¿¡æ¯ ====================
    docs = vectorstore.get(include=["documents"])
    print("ğŸ“¦ å‘é‡æ•¸é‡ï¼š", len(docs["documents"]))

    # ==================== é€²åº¦å›èª¿ ====================
    if status_callback:
        status_callback(f"âœ… åµŒå…¥å®Œæˆï¼Œå…± {len(texts)} ç­†å¯¦é©—æ‘˜è¦")

    # ==================== è©³ç´°é è¦½ ====================
    print("ğŸ“Š æœ¬æ¬¡åµŒå…¥é è¦½ï¼š")
    for i, t in enumerate(texts[:5]):
        print(f"#{i+1} | {metadatas[i]['exp_id']} | é ­ 80 å­—ï¼š{t[:80].replace(chr(10), ' ')}")


# ==================== è¼”åŠ©å‡½æ•¸ ====================

def validate_embedding_model():
    """
    é©—è­‰åµŒå…¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    
    åŠŸèƒ½ï¼š
    1. æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    2. æ¸¬è©¦æ¨¡å‹åŠ è¼‰
    3. é©—è­‰è¨­å‚™é…ç½®
    
    è¿”å›ï¼š
        bool: æ¨¡å‹æ˜¯å¦å¯ç”¨
    """
    try:
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"trust_remote_code": True, "device": device}
        )
        print(f"âœ… åµŒå…¥æ¨¡å‹é©—è­‰æˆåŠŸï¼š{EMBEDDING_MODEL_NAME}")
        return True
    except Exception as e:
        print(f"âŒ åµŒå…¥æ¨¡å‹é©—è­‰å¤±æ•—ï¼š{e}")
        return False


def get_vectorstore_stats(vectorstore_type: str = "paper"):
    """
    ç²å–å‘é‡æ•¸æ“šåº«çµ±è¨ˆä¿¡æ¯
    
    åŠŸèƒ½ï¼š
    1. é€£æ¥æŒ‡å®šçš„å‘é‡æ•¸æ“šåº«
    2. ç²å–æ–‡æª”æ•¸é‡çµ±è¨ˆ
    3. è¿”å›è©³ç´°çš„çµ±è¨ˆä¿¡æ¯
    
    åƒæ•¸ï¼š
        vectorstore_type (str): å‘é‡æ•¸æ“šåº«é¡å‹ï¼ˆ"paper" æˆ– "experiment"ï¼‰
    
    è¿”å›ï¼š
        Dict: çµ±è¨ˆä¿¡æ¯å­—å…¸
    """
    try:
        embedding_model = HuggingFaceEmbeddings(
            model_name=EMBEDDING_MODEL_NAME,
            model_kwargs={"trust_remote_code": True, "device": device}
        )
        
        if vectorstore_type == "paper":
            vector_dir = os.path.join(VECTOR_INDEX_DIR, "paper_vector")
            collection_name = "paper"
        else:
            vector_dir = os.path.join(VECTOR_INDEX_DIR, "experiment_vector")
            collection_name = "experiment"
            
        vectorstore = Chroma(
            persist_directory=vector_dir,
            embedding_function=embedding_model,
            collection_name=collection_name
        )
        
        docs = vectorstore.get(include=["documents", "metadatas"])
        
        return {
            "total_documents": len(docs["documents"]),
            "collection_name": collection_name,
            "vector_dir": vector_dir
        }
        
    except Exception as e:
        print(f"âŒ ç²å–çµ±è¨ˆä¿¡æ¯å¤±æ•—ï¼š{e}")
        return {"error": str(e)}


# ==================== æ¸¬è©¦ä»£ç¢¼ ====================
if __name__ == "__main__":
    """
    æ¸¬è©¦åµŒå…¥åŠŸèƒ½
    
    é€™å€‹æ¸¬è©¦ä»£ç¢¼ç”¨æ–¼é©—è­‰åµŒå…¥åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    print("ğŸ§ª é–‹å§‹æ¸¬è©¦åµŒå…¥åŠŸèƒ½...")
    
    # é©—è­‰åµŒå…¥æ¨¡å‹
    if validate_embedding_model():
        print("âœ… åµŒå…¥æ¨¡å‹é©—è­‰é€šé")
        
        # ç²å–çµ±è¨ˆä¿¡æ¯
        paper_stats = get_vectorstore_stats("paper")
        experiment_stats = get_vectorstore_stats("experiment")
        
        print("ğŸ“Š å‘é‡æ•¸æ“šåº«çµ±è¨ˆï¼š")
        print(f"  æ–‡ç»å‘é‡åº«ï¼š{paper_stats}")
        print(f"  å¯¦é©—å‘é‡åº«ï¼š{experiment_stats}")
    else:
        print("âŒ åµŒå…¥æ¨¡å‹é©—è­‰å¤±æ•—")


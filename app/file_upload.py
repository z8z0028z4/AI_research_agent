"""
AI ç ”ç©¶åŠ©ç† - æ–‡ä»¶ä¸Šå‚³è™•ç†æ¨¡å¡Š
============================

é€™å€‹æ¨¡å¡Šè² è²¬è™•ç†ç”¨æˆ¶ä¸Šå‚³çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡ä»¶æ ¼å¼é©—è­‰
2. å…ƒæ•¸æ“šæå–
3. æ–‡ä»¶é‡å‘½åå’Œè¤‡è£½
4. å…ƒæ•¸æ“šè¨»å†Šè¡¨æ›´æ–°

æ¶æ§‹èªªæ˜ï¼š
- æ”¯æŒPDFå’ŒDOCXæ ¼å¼æ–‡ä»¶
- é›†æˆå¤šå€‹å…ƒæ•¸æ“šæå–æº
- æä¾›é€²åº¦å›èª¿æ©Ÿåˆ¶
- è‡ªå‹•æ–‡ä»¶ç®¡ç†å’Œçµ„ç¹”
"""

import os
from typing import List, Dict, Optional, Callable
from metadata_extractor import extract_metadata
from semantic_lookup import lookup_semantic_scholar_metadata
from document_renamer import rename_and_copy_file
from metadata_registry import append_metadata_to_registry

def process_uploaded_files(file_paths: List[str], status_callback: Optional[Callable[[str], None]] = None) -> List[Dict]:
    """
    è™•ç†ä¸Šå‚³çš„æ–‡ä»¶ï¼Œæå–å…ƒæ•¸æ“šä¸¦çµ„ç¹”å­˜å„²
    
    åŠŸèƒ½æµç¨‹ï¼š
    1. é©—è­‰æ–‡ä»¶æ ¼å¼ï¼ˆåªæ”¯æŒPDFå’ŒDOCXï¼‰
    2. æå–æ–‡ä»¶å…ƒæ•¸æ“š
    3. å¾Semantic Scholarç²å–è£œå……ä¿¡æ¯
    4. é‡å‘½åä¸¦è¤‡è£½æ–‡ä»¶åˆ°papersç›®éŒ„
    5. æ›´æ–°å…ƒæ•¸æ“šè¨»å†Šè¡¨
    
    åƒæ•¸ï¼š
        file_paths (List[str]): æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        status_callback (Optional[Callable]): é€²åº¦å›èª¿å‡½æ•¸ï¼Œç”¨æ–¼æ›´æ–°UIç‹€æ…‹
    
    è¿”å›ï¼š
        List[Dict]: è™•ç†çµæœåˆ—è¡¨ï¼ŒåŒ…å«æ¯å€‹æ–‡ä»¶çš„å…ƒæ•¸æ“šä¿¡æ¯
    
    ç¤ºä¾‹ï¼š
        >>> results = process_uploaded_files(['paper1.pdf', 'paper2.docx'])
        >>> for result in results:
        >>>     print(f"è™•ç†å®Œæˆï¼š{result['new_filename']}")
    """
    
    # ==================== æ–‡ä»¶æ ¼å¼é©—è­‰ ====================
    # å®šç¾©æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    valid_exts = [".pdf", ".docx"]
    
    # éæ¿¾å‡ºæ”¯æŒæ ¼å¼çš„æ–‡ä»¶
    file_paths = [
        path for path in file_paths
        if os.path.splitext(path)[1].lower() in valid_exts
    ]
    
    print(f"ğŸ“ æ‰¾åˆ° {len(file_paths)} å€‹æœ‰æ•ˆæ–‡ä»¶")
    
    # ==================== æ–‡ä»¶è™•ç†å¾ªç’° ====================
    results = []
    
    for i, path in enumerate(file_paths, 1):
        filename = os.path.basename(path)
        print(f"ğŸ”„ è™•ç†ç¬¬ {i}/{len(file_paths)} å€‹æ–‡ä»¶ï¼š{filename}")
        
        # ==================== å…ƒæ•¸æ“šæå– ====================
        # é€šçŸ¥UIæ›´æ–°ç‹€æ…‹
        if status_callback:
            status_callback(f"ğŸ“„ æ­£åœ¨æå–æ–‡ä»¶ `{filename}` çš„å…ƒæ•¸æ“š...")
        
        # å¾æ–‡ä»¶ä¸­æå–åŸºæœ¬å…ƒæ•¸æ“šï¼ˆæ¨™é¡Œã€ä½œè€…ã€DOIç­‰ï¼‰
        metadata = extract_metadata(path)
        print(f"ğŸ“‹ æå–åˆ°å…ƒæ•¸æ“šï¼š{metadata.get('title', 'æœªçŸ¥æ¨™é¡Œ')}")
        
        # ==================== Semantic Scholar è£œå……ä¿¡æ¯ ====================
        # ä½¿ç”¨DOIæˆ–æ¨™é¡Œå¾Semantic Scholarç²å–æ›´è©³ç´°çš„ä¿¡æ¯
        semantic_data = lookup_semantic_scholar_metadata(
            doi=metadata.get("doi", "") or None,  # å¦‚æœæœ‰DOIå°±ç”¨DOIæŸ¥è©¢
            title=metadata.get("title", "") or None  # å¦å‰‡ç”¨æ¨™é¡ŒæŸ¥è©¢
        )
        
        # ==================== å…ƒæ•¸æ“šæ•´åˆ ====================
        # å°‡Semantic Scholarçš„ä¿¡æ¯èˆ‡æœ¬åœ°æå–çš„ä¿¡æ¯åˆä½µ
        # å„ªå…ˆä½¿ç”¨Semantic Scholarçš„ä¿¡æ¯ï¼Œå› ç‚ºé€šå¸¸æ›´æº–ç¢º
        metadata.update({
            "title": semantic_data.get("title", metadata.get("title", "")),
            "authors": "; ".join(a["name"] for a in semantic_data.get("authors", [])),
            "year": semantic_data.get("year", ""),
            "venue": semantic_data.get("venue", ""),  # æœŸåˆŠæˆ–æœƒè­°åç¨±
            "url": semantic_data.get("url", "")  # è«–æ–‡URL
        })
        
        # ==================== æ–‡ä»¶é‡å‘½åå’Œè¤‡è£½ ====================
        # é€šçŸ¥UIæ›´æ–°ç‹€æ…‹
        if status_callback:
            status_callback(f"ğŸ“¦ æ­£åœ¨è¤‡è£½æ–‡ä»¶ `{filename}`...")
        
        # é‡å‘½åæ–‡ä»¶ä¸¦è¤‡è£½åˆ°papersç›®éŒ„
        # æ–°æ–‡ä»¶åæ ¼å¼ï¼šä½œè€…_å¹´ä»½_æ¨™é¡Œ.pdf/docx
        metadata = rename_and_copy_file(path, metadata)
        
        if status_callback:
            status_callback(f"ğŸ“¦ å·²è¤‡è£½ `{filename}` è‡³ papers ç›®éŒ„ï¼Œæ–°æ–‡ä»¶åï¼š`{metadata['new_filename']}`")
        
        # ==================== å…ƒæ•¸æ“šè¨»å†Š ====================
        # å°‡å…ƒæ•¸æ“šä¿¡æ¯æ·»åŠ åˆ°è¨»å†Šè¡¨ä¸­
        append_metadata_to_registry(metadata)
        
        if status_callback:
            status_callback(f"âœ… å·²æ›´æ–°å…ƒæ•¸æ“šè¨»å†Šè¡¨ï¼š{metadata['new_filename']}")
        
        print(f"âœ… å®Œæˆè™•ç†ï¼š{metadata['new_filename']}")
        results.append(metadata)
    
    # ==================== è™•ç†å®Œæˆçµ±è¨ˆ ====================
    print(f"ğŸ¯ æ–‡ä»¶è™•ç†å®Œæˆï¼å…±è™•ç† {len(results)} å€‹æ–‡ä»¶")
    return results


def validate_file_format(file_path: str) -> bool:
    """
    é©—è­‰æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
    
    åƒæ•¸ï¼š
        file_path (str): æ–‡ä»¶è·¯å¾‘
    
    è¿”å›ï¼š
        bool: æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
    """
    valid_exts = [".pdf", ".docx"]
    file_ext = os.path.splitext(file_path)[1].lower()
    return file_ext in valid_exts


def get_file_info(file_path: str) -> Dict[str, any]:
    """
    ç²å–æ–‡ä»¶åŸºæœ¬ä¿¡æ¯
    
    åƒæ•¸ï¼š
        file_path (str): æ–‡ä»¶è·¯å¾‘
    
    è¿”å›ï¼š
        Dict[str, any]: æ–‡ä»¶ä¿¡æ¯å­—å…¸
    """
    if not os.path.exists(file_path):
        return {"error": "æ–‡ä»¶ä¸å­˜åœ¨"}
    
    file_info = {
        "filename": os.path.basename(file_path),
        "filepath": file_path,
        "size": os.path.getsize(file_path),
        "extension": os.path.splitext(file_path)[1].lower(),
        "is_valid": validate_file_format(file_path)
    }
    
    return file_info


def batch_process_files(file_paths: List[str], batch_size: int = 5) -> List[Dict]:
    """
    æ‰¹é‡è™•ç†æ–‡ä»¶ï¼Œæ”¯æŒåˆ†æ‰¹è™•ç†å¤§é‡æ–‡ä»¶
    
    åƒæ•¸ï¼š
        file_paths (List[str]): æ–‡ä»¶è·¯å¾‘åˆ—è¡¨
        batch_size (int): æ¯æ‰¹è™•ç†çš„æ–‡ä»¶æ•¸é‡
    
    è¿”å›ï¼š
        List[Dict]: æ‰€æœ‰è™•ç†çµæœ
    """
    all_results = []
    
    # åˆ†æ‰¹è™•ç†æ–‡ä»¶
    for i in range(0, len(file_paths), batch_size):
        batch = file_paths[i:i + batch_size]
        print(f"ğŸ“¦ è™•ç†æ‰¹æ¬¡ {i//batch_size + 1}/{(len(file_paths) + batch_size - 1)//batch_size}")
        
        try:
            batch_results = process_uploaded_files(batch)
            all_results.extend(batch_results)
        except Exception as e:
            print(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—ï¼š{e}")
            # ç¹¼çºŒè™•ç†ä¸‹ä¸€æ‰¹
    
    return all_results


# ==================== æ¸¬è©¦ä»£ç¢¼ ====================
if __name__ == "__main__":
    """
    æ¸¬è©¦æ–‡ä»¶ä¸Šå‚³è™•ç†åŠŸèƒ½
    
    é€™å€‹æ¸¬è©¦ä»£ç¢¼ç”¨æ–¼é©—è­‰æ–‡ä»¶è™•ç†æµç¨‹æ˜¯å¦æ­£å¸¸å·¥ä½œ
    """
    fake_test_file = "test_data/fake_paper.docx"
    
    try:
        print("ğŸ§ª é–‹å§‹æ¸¬è©¦æ–‡ä»¶ä¸Šå‚³è™•ç†...")
        
        # æ¸¬è©¦å–®å€‹æ–‡ä»¶è™•ç†
        result = process_uploaded_files([fake_test_file])
        
        print("âœ… æ¸¬è©¦å®Œæˆ")
        
        # è¼¸å‡ºè™•ç†çµæœ
        for r in result:
            print("ğŸ“ å…ƒæ•¸æ“šï¼š", r)
            
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—ï¼š{e}")
        print("ï¿½ï¿½ è«‹ç¢ºä¿æ¸¬è©¦æ–‡ä»¶å­˜åœ¨ä¸”æ ¼å¼æ­£ç¢º")

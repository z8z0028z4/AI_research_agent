import os
import pandas as pd
from dotenv import load_dotenv
from langchain.vectorstores import Chroma
from langchain.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI

# === ç’°å¢ƒèˆ‡è·¯å¾‘è¨­å®š ===
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise ValueError("âš ï¸ è«‹åœ¨ .env æª”ä¸­è¨­å®š OPENAI_API_KEY")

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
INDEX_DIR = os.path.join(BASE_DIR, "..", "experiment_data", "vector_index")
EXPERIMENT_DIR = os.path.join(BASE_DIR, "..", "experiment_data", "itri_experiment")

# === è¼‰å…¥æ‰€æœ‰å¯¦é©—ç´€éŒ„ CSV ===
def load_experiment_log():
    if not os.path.exists(EXPERIMENT_DIR):
        print(f"âš ï¸ æ‰¾ä¸åˆ°è³‡æ–™å¤¾ï¼š{EXPERIMENT_DIR}")
        return pd.DataFrame()

    csv_files = [f for f in os.listdir(EXPERIMENT_DIR) if f.endswith(".csv")]
    if not csv_files:
        print(f"âš ï¸ æ²’æœ‰æ‰¾åˆ°ä»»ä½• CSV æª”æ¡ˆæ–¼ï¼š{EXPERIMENT_DIR}")
        return pd.DataFrame()

    all_dfs = []
    for file in csv_files:
        file_path = os.path.join(EXPERIMENT_DIR, file)
        try:
            df = pd.read_csv(file_path)
            all_dfs.append(df)
            print(f"ğŸ“„ å·²è¼‰å…¥ï¼š{file}")
        except Exception as e:
            print(f"âŒ ç„¡æ³•è®€å– {file}ï¼š{e}")

    if all_dfs:
        combined_df = pd.concat(all_dfs, ignore_index=True)
        print(f"âœ… å·²åˆä½µ {len(all_dfs)} ä»½å¯¦é©—ç´€éŒ„ï¼Œå…± {len(combined_df)} ç­†è³‡æ–™ã€‚")
        return combined_df
    else:
        return pd.DataFrame()

# === çµ„åˆæç¤ºæ–‡å­— ===
def build_prompt(question, context, experiment_df):
    past_experiments = experiment_df.head(10).to_string(index=False) if not experiment_df.empty else "ï¼ˆç›®å‰ç„¡è³‡æ–™ï¼‰"

    return f"""ä½ æ˜¯ä¸€ä½ç ”ç©¶åŠ©ç†ï¼Œä»¥ä¸‹æ˜¯ç³»çµ±å½™æ•´çš„æ–‡ç»æ®µè½èˆ‡å¯¦é©—ç´€éŒ„æ‘˜è¦ï¼Œè«‹æ ¹æ“šæ­¤è³‡è¨Šå›ç­”ä¸‹åˆ—ç ”ç©¶å•é¡Œï¼š
--- æ–‡ç»æ‘˜è¦ ---
{context}

--- å¯¦é©—ç´€éŒ„ï¼ˆå‰å¹¾ç­†ï¼‰ ---
{past_experiments}

--- å•é¡Œ ---
{question}

è«‹æ¢åˆ—å¼å›æ‡‰å»ºè­°ï¼Œè‹¥è³‡æ–™ä¸­å‡ºç¾ç›¸ä¼¼æ¢ä»¶è«‹æŒ‡å‡ºï¼Œä¸¦çµ¦å‡ºå¯èƒ½çš„ä¸‹ä¸€æ­¥å¯¦é©—æ–¹å‘ã€‚
"""

# === å›ç­”ä¸»æµç¨‹ ===
def ask_agent(question, experiment_df):
    embeddings = OpenAIEmbeddings()
    db = Chroma(persist_directory=INDEX_DIR, embedding_function=embeddings)
    retriever = db.as_retriever(search_kwargs={"k": 5})
    context_docs = retriever.get_relevant_documents(question)
    context = "\n---\n".join([doc.page_content for doc in context_docs])
    prompt = build_prompt(question, context, experiment_df)
    llm = ChatOpenAI(model="gpt-4")
    response = llm.predict(prompt)
    return response

# === ä¸»åŸ·è¡Œå€ ===
if __name__ == "__main__":
    experiment_df = load_experiment_log()
    print("ğŸ¤– AI ç ”ç©¶åŠ©ç†å•Ÿå‹•ï¼Œè«‹è¼¸å…¥ä½ çš„ç ”ç©¶å•é¡Œï¼ˆè¼¸å…¥ exit é›¢é–‹ï¼‰ï¼š\n")
    while True:
        q = input("ğŸ” å•é¡Œï¼š")
        if q.strip().lower() == "exit":
            print("ğŸ‘‹ å·²é›¢é–‹åŠ©ç†ã€‚")
            break
        answer = ask_agent(q, experiment_df)
        print("\nğŸ“˜ å›ç­”ï¼š\n", answer)